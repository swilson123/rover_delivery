#!/usr/bin/env node
'use strict';

var require$$0 = require('node:url');
var vendor = require('./vendor.js');
var require$$9 = require('../external/@socketsecurity/registry/lib/debug');
var logger = require('../external/@socketsecurity/registry/lib/logger');
var utils = require('./utils.js');
var fs = require('node:fs/promises');
var require$$5 = require('node:module');
var constants = require('./constants.js');
var flags = require('./flags.js');
var path = require('node:path');
var words = require('../external/@socketsecurity/registry/lib/words');
var arrays = require('../external/@socketsecurity/registry/lib/arrays');
var prompts = require('../external/@socketsecurity/registry/lib/prompts');
var fs$1 = require('node:fs');
var spawn = require('../external/@socketsecurity/registry/lib/spawn');
var fs$2 = require('../external/@socketsecurity/registry/lib/fs');
var strings = require('../external/@socketsecurity/registry/lib/strings');
var path$1 = require('../external/@socketsecurity/registry/lib/path');
var require$$11 = require('../external/@socketsecurity/registry/lib/objects');
var registry = require('../external/@socketsecurity/registry');
var packages = require('../external/@socketsecurity/registry/lib/packages');
var require$$12 = require('../external/@socketsecurity/registry/lib/promises');
var regexps = require('../external/@socketsecurity/registry/lib/regexps');
var require$$0$1 = require('node:crypto');
var require$$1 = require('node:util');
var os = require('node:os');
var promises = require('node:stream/promises');

var _documentCurrentScript = typeof document !== 'undefined' ? document.currentScript : null;
async function fetchOrgAnalyticsData(time, options) {
  const {
    sdkOpts
  } = {
    __proto__: null,
    ...options
  };
  const sockSdkCResult = await utils.setupSdk(sdkOpts);
  if (!sockSdkCResult.ok) {
    return sockSdkCResult;
  }
  const sockSdk = sockSdkCResult.data;
  return await utils.handleApiCall(sockSdk.getOrgAnalytics(time.toString()), {
    description: 'analytics data'
  });
}

async function fetchRepoAnalyticsData(repo, time, options) {
  const {
    sdkOpts
  } = {
    __proto__: null,
    ...options
  };
  const sockSdkCResult = await utils.setupSdk(sdkOpts);
  if (!sockSdkCResult.ok) {
    return sockSdkCResult;
  }
  const sockSdk = sockSdkCResult.data;
  return await utils.handleApiCall(sockSdk.getRepoAnalytics(repo, time.toString()), {
    description: 'analytics data'
  });
}

// Note: Widgets does not seem to actually work as code :'(

const require$7 = require$$5.createRequire((typeof document === 'undefined' ? require$$0.pathToFileURL(__filename).href : (_documentCurrentScript && _documentCurrentScript.tagName.toUpperCase() === 'SCRIPT' && _documentCurrentScript.src || new URL('cli.js', document.baseURI).href)));
const METRICS = ['total_critical_alerts', 'total_high_alerts', 'total_medium_alerts', 'total_low_alerts', 'total_critical_added', 'total_medium_added', 'total_low_added', 'total_high_added', 'total_critical_prevented', 'total_high_prevented', 'total_medium_prevented', 'total_low_prevented'];

// Note: This maps `new Date(date).getMonth()` to English three letters
const Months = ['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', 'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec'];
async function outputAnalytics(result, {
  filepath,
  outputKind,
  repo,
  scope,
  time
}) {
  if (!result.ok) {
    process.exitCode = result.code ?? 1;
  }
  if (!result.ok) {
    if (outputKind === 'json') {
      logger.logger.log(utils.serializeResultJson(result));
      return;
    }
    logger.logger.fail(utils.failMsgWithBadge(result.message, result.cause));
    return;
  }
  if (outputKind === 'json') {
    const serialized = utils.serializeResultJson(result);
    if (filepath) {
      try {
        await fs.writeFile(filepath, serialized, 'utf8');
        utils.debugFileOp('write', filepath);
        logger.logger.success(`Data successfully written to ${utils.fileLink(filepath)}`);
      } catch (e) {
        utils.debugFileOp('write', filepath, e);
        process.exitCode = 1;
        logger.logger.log(utils.serializeResultJson({
          ok: false,
          message: 'File Write Failure',
          cause: 'There was an error trying to write the json to disk'
        }));
      }
    } else {
      logger.logger.log(serialized);
    }
    return;
  }
  const fdata = scope === 'org' ? formatDataOrg(result.data) : formatDataRepo(result.data);
  if (outputKind === 'markdown') {
    const serialized = renderMarkdown(fdata, time, repo);

    // TODO: Do we want to write to file even if there was an error...?
    if (filepath) {
      try {
        await fs.writeFile(filepath, serialized, 'utf8');
        utils.debugFileOp('write', filepath);
        logger.logger.success(`Data successfully written to ${utils.fileLink(filepath)}`);
      } catch (e) {
        utils.debugFileOp('write', filepath, e);
        logger.logger.error(e);
      }
    } else {
      logger.logger.log(serialized);
    }
  } else {
    displayAnalyticsScreen(fdata);
  }
}
function renderMarkdown(data, days, repoSlug) {
  return `
# Socket Alert Analytics

These are the Socket.dev analytics for the ${repoSlug ? `${repoSlug} repo` : 'org'} of the past ${days} days

${[['Total critical alerts', utils.mdTableStringNumber('Date', 'Counts', data['total_critical_alerts'])], ['Total high alerts', utils.mdTableStringNumber('Date', 'Counts', data['total_high_alerts'])], ['Total critical alerts added to the main branch', utils.mdTableStringNumber('Date', 'Counts', data['total_critical_added'])], ['Total high alerts added to the main branch', utils.mdTableStringNumber('Date', 'Counts', data['total_high_added'])], ['Total critical alerts prevented from the main branch', utils.mdTableStringNumber('Date', 'Counts', data['total_critical_prevented'])], ['Total high alerts prevented from the main branch', utils.mdTableStringNumber('Date', 'Counts', data['total_high_prevented'])], ['Total medium alerts prevented from the main branch', utils.mdTableStringNumber('Date', 'Counts', data['total_medium_prevented'])], ['Total low alerts prevented from the main branch', utils.mdTableStringNumber('Date', 'Counts', data['total_low_prevented'])]].map(([title, table]) => `
## ${title}

${table}
`.trim()).join('\n\n')}

## Top 5 alert types

${utils.mdTableStringNumber('Name', 'Counts', data['top_five_alert_types'])}
`.trim() + '\n';
}
function displayAnalyticsScreen(data) {
  const ScreenWidget = /*@__PURE__*/require$7('../external/blessed/lib/widgets/screen.js');
  const screen = new ScreenWidget({
    ...constants.default.blessedOptions
  });
  const GridLayout = /*@__PURE__*/require$7('../external/blessed-contrib/lib/layout/grid.js');
  const grid = new GridLayout({
    rows: 5,
    cols: 4,
    screen
  });
  renderLineCharts(grid, screen, 'Total critical alerts', [0, 0, 1, 2], data['total_critical_alerts']);
  renderLineCharts(grid, screen, 'Total high alerts', [0, 2, 1, 2], data['total_high_alerts']);
  renderLineCharts(grid, screen, 'Total critical alerts added to the main branch', [1, 0, 1, 2], data['total_critical_added']);
  renderLineCharts(grid, screen, 'Total high alerts added to the main branch', [1, 2, 1, 2], data['total_high_added']);
  renderLineCharts(grid, screen, 'Total critical alerts prevented from the main branch', [2, 0, 1, 2], data['total_critical_prevented']);
  renderLineCharts(grid, screen, 'Total high alerts prevented from the main branch', [2, 2, 1, 2], data['total_high_prevented']);
  renderLineCharts(grid, screen, 'Total medium alerts prevented from the main branch', [3, 0, 1, 2], data['total_medium_prevented']);
  renderLineCharts(grid, screen, 'Total low alerts prevented from the main branch', [3, 2, 1, 2], data['total_low_prevented']);
  const BarChart = /*@__PURE__*/require$7('../external/blessed-contrib/lib/widget/charts/bar.js');
  const bar = grid.set(4, 0, 1, 2, BarChart, {
    label: 'Top 5 alert types',
    barWidth: 10,
    barSpacing: 17,
    xOffset: 0,
    maxHeight: 9,
    barBgColor: 'magenta'
  });

  // Must append before setting data.
  screen.append(bar);
  bar.setData({
    titles: Object.keys(data.top_five_alert_types),
    data: Object.values(data.top_five_alert_types)
  });
  screen.render();
  // eslint-disable-next-line n/no-process-exit
  screen.key(['escape', 'q', 'C-c'], () => process.exit(0));
}
function formatDataRepo(data) {
  const sortedTopFiveAlerts = {};
  const totalTopAlerts = {};
  const formattedData = {};
  for (const metric of METRICS) {
    formattedData[metric] = {};
  }
  for (const entry of data) {
    const topFiveAlertTypes = entry['top_five_alert_types'];
    for (const type of Object.keys(topFiveAlertTypes)) {
      const count = topFiveAlertTypes[type] ?? 0;
      if (!totalTopAlerts[type]) {
        totalTopAlerts[type] = count;
      } else if (count > (totalTopAlerts[type] ?? 0)) {
        totalTopAlerts[type] = count;
      }
    }
  }
  for (const entry of data) {
    for (const metric of METRICS) {
      formattedData[metric][formatDate(entry['created_at'])] = entry[metric];
    }
  }
  const topFiveAlertEntries = Object.entries(totalTopAlerts).sort(([_keya, a], [_keyb, b]) => b - a).slice(0, 5);
  for (const {
    0: key,
    1: value
  } of topFiveAlertEntries) {
    sortedTopFiveAlerts[key] = value;
  }
  return {
    ...formattedData,
    top_five_alert_types: sortedTopFiveAlerts
  };
}
function formatDataOrg(data) {
  const sortedTopFiveAlerts = {};
  const totalTopAlerts = {};
  const formattedData = {};
  for (const metric of METRICS) {
    formattedData[metric] = {};
  }
  for (const entry of data) {
    const topFiveAlertTypes = entry['top_five_alert_types'];
    for (const type of Object.keys(topFiveAlertTypes)) {
      const count = topFiveAlertTypes[type] ?? 0;
      if (totalTopAlerts[type]) {
        totalTopAlerts[type] += count;
      } else {
        totalTopAlerts[type] = count;
      }
    }
  }
  for (const metric of METRICS) {
    const formatted = formattedData[metric];
    for (const entry of data) {
      const date = formatDate(entry['created_at']);
      if (formatted[date]) {
        formatted[date] += entry[metric];
      } else {
        formatted[date] = entry[metric];
      }
    }
  }
  const topFiveAlertEntries = Object.entries(totalTopAlerts).sort(([_keya, a], [_keyb, b]) => b - a).slice(0, 5);
  for (const {
    0: key,
    1: value
  } of topFiveAlertEntries) {
    sortedTopFiveAlerts[key] = value;
  }
  return {
    ...formattedData,
    top_five_alert_types: sortedTopFiveAlerts
  };
}
function formatDate(date) {
  return `${Months[new Date(date).getMonth()]} ${new Date(date).getDate()}`;
}
function renderLineCharts(grid, screen, title, coords, data) {
  const LineChart = /*@__PURE__*/require$7('../external/blessed-contrib/lib/widget/charts/line.js');
  const line = grid.set(...coords, LineChart, {
    style: {
      line: 'cyan',
      text: 'cyan',
      baseline: 'black'
    },
    xLabelPadding: 0,
    xPadding: 0,
    xOffset: 0,
    wholeNumbersOnly: true,
    legend: {
      width: 1
    },
    label: title
  });
  screen.append(line);
  const lineData = {
    x: Object.keys(data),
    y: Object.values(data)
  };
  line.setData([lineData]);
}

async function handleAnalytics({
  filepath,
  outputKind,
  repo,
  scope,
  time
}) {
  let result;
  if (scope === 'org') {
    result = await fetchOrgAnalyticsData(time);
  } else if (repo) {
    result = await fetchRepoAnalyticsData(repo, time);
  } else {
    result = {
      ok: false,
      message: 'Missing repository name in command'
    };
  }
  if (result.ok && !result.data.length) {
    result = {
      ok: true,
      message: `The analytics data for this ${scope === 'org' ? 'organization' : 'repository'} is not yet available.`,
      data: []
    };
  }
  await outputAnalytics(result, {
    filepath,
    outputKind,
    repo,
    scope,
    time
  });
}

const CMD_NAME$y = 'analytics';
const description$F = 'Look up analytics data';
const hidden$x = false;
const cmdAnalytics = {
  description: description$F,
  hidden: hidden$x,
  run: run$S
};
async function run$S(argv, importMeta, {
  parentName
}) {
  const config = {
    commandName: CMD_NAME$y,
    description: description$F,
    hidden: hidden$x,
    flags: {
      ...flags.commonFlags,
      ...flags.outputFlags,
      file: {
        type: 'string',
        default: '',
        description: 'Path to store result, only valid with --json/--markdown'
      }
    },
    help: (command, {
      flags
    }) => `
    Usage
      $ ${command} [options] [ "org" | "repo" <reponame>] [TIME]

    API Token Requirements
      ${utils.getFlagApiRequirementsOutput(`${parentName}:${CMD_NAME$y}`)}

    The scope is either org or repo level, defaults to org.

    When scope is repo, a repo slug must be given as well.

    The TIME argument must be number 7, 30, or 90 and defaults to 30.

    Options
      ${utils.getFlagListOutput(flags)}

    Examples
      $ ${command} org 7
      $ ${command} repo test-repo 30
      $ ${command} 90
  `
  };
  const cli = utils.meowOrExit({
    argv,
    config,
    parentName,
    importMeta
  });

  // Supported inputs:
  // - []        (no args)
  // - ['org']
  // - ['org', '30']
  // - ['repo', 'name']
  // - ['repo', 'name', '30']
  // - ['30']
  // Validate final values in the next step
  let scope = 'org';
  let time = '30';
  let repoName = '';
  if (cli.input[0] === 'org') {
    if (cli.input[1]) {
      time = cli.input[1];
    }
  } else if (cli.input[0] === 'repo') {
    scope = 'repo';
    if (cli.input[1]) {
      repoName = cli.input[1];
    }
    if (cli.input[2]) {
      time = cli.input[2];
    }
  } else if (cli.input[0]) {
    time = cli.input[0];
  }
  const {
    file: filepath,
    json,
    markdown
  } = cli.flags;
  const dryRun = !!cli.flags['dryRun'];
  const noLegacy = !cli.flags['scope'] && !cli.flags['repo'] && !cli.flags['time'];
  const hasApiToken = utils.hasDefaultApiToken();
  const outputKind = utils.getOutputKind(json, markdown);
  const wasValidInput = utils.checkCommandInput(outputKind, {
    nook: true,
    test: noLegacy,
    message: `Legacy flags are no longer supported. See the ${utils.webLink(constants.V1_MIGRATION_GUIDE_URL, 'v1 migration guide')}.`,
    fail: `received legacy flags`
  }, {
    nook: true,
    test: scope === 'org' || !!repoName,
    message: 'When scope=repo, repo name should be the second argument',
    fail: 'missing'
  }, {
    nook: true,
    test: scope === 'org' || repoName !== '7' && repoName !== '30' && repoName !== '90',
    message: 'When scope is repo, the second arg should be repo, not time',
    fail: 'missing'
  }, {
    test: time === '7' || time === '30' || time === '90',
    message: 'The time filter must either be 7, 30 or 90',
    fail: 'invalid range set, see --help for command arg details.'
  }, {
    nook: true,
    test: !filepath || !!json || !!markdown,
    message: `The \`--file\` flag is only valid when using \`${constants.FLAG_JSON}\` or \`${constants.FLAG_MARKDOWN}\``,
    fail: 'bad'
  }, {
    nook: true,
    test: !json || !markdown,
    message: `The \`${constants.FLAG_JSON}\` and \`${constants.FLAG_MARKDOWN}\` flags can not be used at the same time`,
    fail: 'bad'
  }, {
    nook: true,
    test: hasApiToken,
    message: 'This command requires a Socket API token for access',
    fail: 'try `socket login`'
  });
  if (!wasValidInput) {
    return;
  }
  if (dryRun) {
    logger.logger.log(constants.default.DRY_RUN_BAILING_NOW);
    return;
  }
  return await handleAnalytics({
    filepath,
    outputKind,
    repo: repoName,
    scope,
    time: time === '90' ? 90 : time === '30' ? 30 : 7
  });
}

async function fetchAuditLog(config, options) {
  const {
    sdkOpts
  } = {
    __proto__: null,
    ...options
  };
  const sockSdkCResult = await utils.setupSdk(sdkOpts);
  if (!sockSdkCResult.ok) {
    return sockSdkCResult;
  }
  const sockSdk = sockSdkCResult.data;
  const {
    logType,
    orgSlug,
    outputKind,
    page,
    perPage
  } = {
    __proto__: null,
    ...config
  };
  return await utils.handleApiCall(sockSdk.getAuditLogEvents(orgSlug, {
    // I'm not sure this is used at all.
    outputJson: String(outputKind === 'json'),
    // I'm not sure this is used at all.
    outputMarkdown: String(outputKind === 'markdown'),
    orgSlug,
    type: logType,
    page: String(page),
    per_page: String(perPage)
  }), {
    description: `audit log for ${orgSlug}`
  });
}

const require$6 = require$$5.createRequire((typeof document === 'undefined' ? require$$0.pathToFileURL(__filename).href : (_documentCurrentScript && _documentCurrentScript.tagName.toUpperCase() === 'SCRIPT' && _documentCurrentScript.src || new URL('cli.js', document.baseURI).href)));
async function outputAuditLog(result, {
  logType,
  orgSlug,
  outputKind,
  page,
  perPage
}) {
  if (!result.ok) {
    process.exitCode = result.code ?? 1;
  }
  if (outputKind === constants.OUTPUT_JSON) {
    logger.logger.log(await outputAsJson(result, {
      logType,
      orgSlug,
      page,
      perPage
    }));
  }
  if (!result.ok) {
    logger.logger.fail(utils.failMsgWithBadge(result.message, result.cause));
    return;
  }
  if (outputKind === constants.OUTPUT_MARKDOWN) {
    logger.logger.log(await outputAsMarkdown(result.data, {
      logType,
      orgSlug,
      page,
      perPage
    }));
    return;
  }
  await outputWithBlessed(result.data, orgSlug);
}
function formatResult(selectedRow, keepQuotes = false) {
  if (!selectedRow) {
    return '(none)';
  }
  // Format the object with spacing but keep the payload compact because
  // that can contain just about anything and spread many lines.
  const obj = {
    ...selectedRow,
    payload: 'REPLACEME'
  };
  const json = JSON.stringify(obj, null, 2).replace(/"payload": "REPLACEME"/, `"payload": ${JSON.stringify(selectedRow.payload ?? {})}`);
  if (keepQuotes) {
    return json;
  }
  return json.replace(/^\s*"([^"]+)?"/gm, '  $1');
}
async function outputAsJson(auditLogs, {
  logType,
  orgSlug,
  page,
  perPage
}) {
  if (!auditLogs.ok) {
    return utils.serializeResultJson(auditLogs);
  }
  return utils.serializeResultJson({
    ok: true,
    data: {
      desc: 'Audit logs for given query',
      generated: constants.default.ENV.VITEST ? constants.default.REDACTED : new Date().toISOString(),
      logType,
      nextPage: auditLogs.data.nextPage,
      org: orgSlug,
      page,
      perPage,
      logs: auditLogs.data.results.map(log => {
        // Note: The subset is pretty arbitrary
        const {
          created_at,
          event_id,
          ip_address,
          type,
          user_agent,
          user_email
        } = log;
        return {
          event_id,
          created_at,
          ip_address,
          type,
          user_agent,
          user_email
        };
      })
    }
  });
}
async function outputAsMarkdown(auditLogs, {
  logType,
  orgSlug,
  page,
  perPage
}) {
  try {
    const table = utils.mdTable(auditLogs.results, ['event_id', 'created_at', 'type', 'user_email', 'ip_address', 'user_agent']);
    return `
# Socket Audit Logs

These are the Socket.dev audit logs as per requested query.
- org: ${orgSlug}
- type filter: ${logType || '(none)'}
- page: ${page}
- next page: ${auditLogs.nextPage}
- per page: ${perPage}
- generated: ${constants.default.ENV.VITEST ? constants.default.REDACTED : new Date().toISOString()}

${table}
`;
  } catch (e) {
    process.exitCode = 1;
    logger.logger.fail(`There was a problem converting the logs to Markdown, please try the \`${constants.FLAG_JSON}\` flag`);
    require$$9.debugFn('error', 'Markdown conversion failed');
    require$$9.debugDir('error', e);
    return 'Failed to generate the markdown report';
  }
}
async function outputWithBlessed(data, orgSlug) {
  const filteredLogs = data.results;
  const formattedOutput = filteredLogs.map(logs => [logs.event_id ?? '', utils.msAtHome(logs.created_at ?? ''), logs.type ?? '', logs.user_email ?? '', logs.ip_address ?? '', logs.user_agent ?? '']);
  const headers = [' Event id', ' Created at', ' Event type', ' User email', ' IP address', ' User agent'];

  // Note: this temporarily takes over the terminal (just like `man` does).
  const ScreenWidget = /*@__PURE__*/require$6('../external/blessed/lib/widgets/screen.js');
  const screen = new ScreenWidget({
    ...constants.default.blessedOptions
  });
  // Register these keys first so you can always exit, even when it gets stuck
  // If we don't do this and the code crashes, the user must hard-kill the
  // node process just to exit it. That's very bad UX.
  // eslint-disable-next-line n/no-process-exit
  screen.key(['escape', 'q', 'C-c'], () => process.exit(0));
  const TableWidget = /*@__PURE__*/require$6('../external/blessed-contrib/lib/widget/table.js');
  const tipsBoxHeight = 1; // 1 row for tips box
  const detailsBoxHeight = 20; // bottom N rows for details box. 20 gives 4 lines for condensed payload before it scrolls out of view

  const maxWidths = headers.map(s => s.length + 1);
  formattedOutput.forEach(row => {
    row.forEach((str, i) => {
      maxWidths[i] = Math.max(str.length, maxWidths[i] ?? str.length);
    });
  });
  const table = new TableWidget({
    keys: 'true',
    fg: 'white',
    selectedFg: 'white',
    selectedBg: 'magenta',
    interactive: 'true',
    label: `Audit Logs for ${orgSlug}`,
    width: '100%',
    top: 0,
    bottom: detailsBoxHeight + tipsBoxHeight,
    border: {
      type: 'line',
      fg: 'cyan'
    },
    columnWidth: maxWidths,
    //[10, 30, 40, 25, 15, 200],
    // Note: spacing works as long as you don't reserve more than total width
    columnSpacing: 4,
    truncate: '_'
  });
  const BoxWidget = /*@__PURE__*/require$6('../external/blessed/lib/widgets/box.js');
  const tipsBox = new BoxWidget({
    bottom: detailsBoxHeight,
    // sits just above the details box
    height: tipsBoxHeight,
    width: '100%',
    style: {
      fg: 'yellow',
      bg: 'black'
    },
    tags: true,
    content: `↑/↓: Move    Enter: Select    q/ESC: Quit`
  });
  const detailsBox = new BoxWidget({
    bottom: 0,
    height: detailsBoxHeight,
    width: '100%',
    border: {
      type: 'line',
      fg: 'cyan'
    },
    label: 'Details',
    content: formatResult(filteredLogs[0], true),
    style: {
      fg: 'white'
    }
  });
  table.setData({
    headers: headers,
    data: formattedOutput
  });

  // allow control the table with the keyboard
  table.focus();

  // Stacking order: table (top), tipsBox (middle), detailsBox (bottom)
  screen.append(table);
  screen.append(tipsBox);
  screen.append(detailsBox);

  // Update details box when selection changes
  table.rows.on('select item', () => {
    const selectedIndex = table.rows.selected;
    if (selectedIndex !== undefined && selectedIndex >= 0) {
      const selectedRow = filteredLogs[selectedIndex];
      detailsBox.setContent(formatResult(selectedRow));
      screen.render();
    }
  });
  screen.render();
  screen.key(['return'], () => {
    const selectedIndex = table.rows.selected;
    screen.destroy();
    const selectedRow = formattedOutput[selectedIndex] ? formatResult(filteredLogs[selectedIndex], true) : '(none)';
    logger.logger.log(`Last selection:\n${selectedRow.trim()}`);
  });
}

async function handleAuditLog({
  logType,
  orgSlug,
  outputKind,
  page,
  perPage
}) {
  const auditLogs = await fetchAuditLog({
    logType,
    orgSlug,
    outputKind,
    page,
    perPage
  });
  await outputAuditLog(auditLogs, {
    logType,
    orgSlug,
    outputKind,
    page,
    perPage
  });
}

const CMD_NAME$x = 'audit-log';
const description$E = 'Look up the audit log for an organization';
const hidden$w = false;
const cmdAuditLog = {
  description: description$E,
  hidden: hidden$w,
  run: run$R
};
async function run$R(argv, importMeta, {
  parentName
}) {
  const config = {
    commandName: CMD_NAME$x,
    description: description$E,
    hidden: hidden$w,
    flags: {
      ...flags.commonFlags,
      ...flags.outputFlags,
      interactive: {
        type: 'boolean',
        default: true,
        description: 'Allow for interactive elements, asking for input.\nUse --no-interactive to prevent any input questions, defaulting them to cancel/no.'
      },
      org: {
        type: 'string',
        description: 'Force override the organization slug, overrides the default org from config'
      },
      page: {
        type: 'number',
        description: 'Result page to fetch'
      },
      perPage: {
        type: 'number',
        default: 30,
        description: 'Results per page - default is 30'
      }
    },
    help: (command, config) => `
    Usage
      $ ${command} [options] [FILTER]

    API Token Requirements
      ${utils.getFlagApiRequirementsOutput(`${parentName}:${CMD_NAME$x}`)}

    This feature requires an Enterprise Plan. To learn more about getting access
    to this feature and many more, please visit the ${utils.webLink(`${constants.default.SOCKET_WEBSITE_URL}/pricing`, 'Socket pricing page')}.

    The type FILTER arg is an enum. Defaults to any. It should be one of these:
      associateLabel, cancelInvitation, changeMemberRole, changePlanSubscriptionSeats,
      createApiToken, createLabel, deleteLabel, deleteLabelSetting, deleteReport,
      deleteRepository, disassociateLabel, joinOrganization, removeMember,
      resetInvitationLink, resetOrganizationSettingToDefault, rotateApiToken,
      sendInvitation, setLabelSettingToDefault, syncOrganization, transferOwnership,
      updateAlertTriage, updateApiTokenCommitter, updateApiTokenMaxQuota,
      updateApiTokenName', updateApiTokenScopes, updateApiTokenVisibility,
      updateLabelSetting, updateOrganizationSetting, upgradeOrganizationPlan

    The page arg should be a positive integer, offset 1. Defaults to 1.

    Options
      ${utils.getFlagListOutput(config.flags)}

    Examples
      $ ${command}
      $ ${command} deleteReport --page 2 --per-page 10
  `
  };
  const cli = utils.meowOrExit({
    argv,
    config,
    parentName,
    importMeta
  });
  const {
    interactive,
    json,
    markdown,
    org: orgFlag,
    page,
    perPage
  } = cli.flags;
  const dryRun = !!cli.flags['dryRun'];
  const noLegacy = !cli.flags['type'];
  let [typeFilter = ''] = cli.input;
  typeFilter = String(typeFilter);
  const hasApiToken = utils.hasDefaultApiToken();
  const {
    0: orgSlug
  } = await utils.determineOrgSlug(String(orgFlag || ''), interactive, dryRun);
  const outputKind = utils.getOutputKind(json, markdown);
  const wasValidInput = utils.checkCommandInput(outputKind, {
    nook: true,
    test: noLegacy,
    message: `Legacy flags are no longer supported. See the ${utils.webLink(constants.V1_MIGRATION_GUIDE_URL, 'v1 migration guide')}.`,
    fail: `received legacy flags`
  }, {
    nook: true,
    test: !!orgSlug,
    message: 'Org name by default setting, --org, or auto-discovered',
    fail: 'missing'
  }, {
    nook: true,
    test: hasApiToken,
    message: 'This command requires a Socket API token for access',
    fail: 'try `socket login`'
  }, {
    nook: true,
    test: !json || !markdown,
    message: `The \`${constants.FLAG_JSON}\` and \`${constants.FLAG_MARKDOWN}\` flags can not be used at the same time`,
    fail: 'bad'
  }, {
    nook: true,
    test: /^[a-zA-Z]*$/.test(typeFilter),
    message: 'The filter must be an a-zA-Z string, it is an enum',
    fail: 'it was given but not a-zA-Z'
  });
  if (!wasValidInput) {
    return;
  }
  if (dryRun) {
    logger.logger.log(constants.default.DRY_RUN_BAILING_NOW);
    return;
  }
  await handleAuditLog({
    orgSlug,
    outputKind,
    page: Number(page || 0),
    perPage: Number(perPage || 0),
    logType: typeFilter.charAt(0).toUpperCase() + typeFilter.slice(1)
  });
}

async function fetchCreateOrgFullScan(packagePaths, orgSlug, config, options) {
  const {
    branchName,
    commitHash,
    commitMessage,
    committers,
    pullRequest,
    repoName
  } = {
    __proto__: null,
    ...config
  };
  const {
    cwd = process.cwd(),
    defaultBranch,
    pendingHead,
    sdkOpts,
    tmp
  } = {
    __proto__: null,
    ...options
  };
  const sockSdkCResult = await utils.setupSdk(sdkOpts);
  if (!sockSdkCResult.ok) {
    return sockSdkCResult;
  }
  const sockSdk = sockSdkCResult.data;
  return await utils.handleApiCall(sockSdk.createOrgFullScan(orgSlug, packagePaths, cwd, {
    ...(branchName ? {
      branch: branchName
    } : {}),
    ...(commitHash ? {
      commit_hash: commitHash
    } : {}),
    ...(commitMessage ? {
      commit_message: commitMessage
    } : {}),
    ...(committers ? {
      committers
    } : {}),
    make_default_branch: String(defaultBranch),
    ...(pullRequest ? {
      pull_request: String(pullRequest)
    } : {}),
    repo: repoName,
    set_as_pending_head: String(pendingHead),
    tmp: String(tmp)
  }), {
    description: 'to create a scan'
  });
}

async function fetchSupportedScanFileNames(options) {
  const {
    sdkOpts,
    spinner
  } = {
    __proto__: null,
    ...options
  };
  const sockSdkCResult = await utils.setupSdk(sdkOpts);
  if (!sockSdkCResult.ok) {
    return sockSdkCResult;
  }
  const sockSdk = sockSdkCResult.data;
  return await utils.handleApiCall(sockSdk.getSupportedScanFiles(), {
    description: 'supported scan file types',
    spinner
  });
}

/**
 * Finalize a tier1 reachability scan.
 *  - Associates the tier1 reachability scan metadata with the full scan.
 *  - Sets the tier1 reachability scan to "finalized" state.
 */
async function finalizeTier1Scan(tier1ReachabilityScanId, scanId) {
  // we do not use the SDK here because the tier1-reachability-scan/finalize is a hidden
  // endpoint that is not part of the OpenAPI specification.
  return await utils.sendApiRequest('tier1-reachability-scan/finalize', {
    method: 'POST',
    body: {
      tier1_reachability_scan_id: tier1ReachabilityScanId,
      report_run_id: scanId
    }
  });
}

/**
 * This fetches all the relevant pieces of data to generate a report, given a
 * full scan ID.
 */
async function fetchScanData(orgSlug, scanId, options) {
  const {
    includeLicensePolicy,
    sdkOpts
  } = {
    __proto__: null,
    ...options
  };
  const sockSdkCResult = await utils.setupSdk(sdkOpts);
  if (!sockSdkCResult.ok) {
    return sockSdkCResult;
  }
  const sockSdk = sockSdkCResult.data;
  let policyStatus = 'requested...';
  let scanStatus = 'requested...';
  let finishedFetching = false;
  const {
    spinner
  } = constants.default;
  function updateScan(status) {
    scanStatus = status;
    updateProgress();
  }
  function updatePolicy(status) {
    policyStatus = status;
    updateProgress();
  }
  function updateProgress() {
    if (finishedFetching) {
      spinner.stop();
      logger.logger.info(`Scan result: ${scanStatus}. Security policy: ${policyStatus}.`);
    } else {
      spinner.start(`Scan result: ${scanStatus}. Security policy: ${policyStatus}.`);
    }
  }
  async function fetchScanResult() {
    const result = await utils.queryApiSafeText(`orgs/${orgSlug}/full-scans/${encodeURIComponent(scanId)}${includeLicensePolicy ? '?include_license_details=true' : ''}`);
    updateScan(`response received`);
    if (!result.ok) {
      return result;
    }
    const ndJsonString = result.data;

    // This is nd-json; each line is a json object.
    const lines = ndJsonString.split('\n').filter(Boolean);
    let ok = true;
    const data = lines.map(line => {
      try {
        return JSON.parse(line);
      } catch (e) {
        ok = false;
        require$$9.debugFn('error', 'Failed to parse report data line as JSON');
        require$$9.debugDir('error', {
          error: e,
          line
        });
        return;
      }
    });
    if (ok) {
      updateScan('success');
      return {
        ok: true,
        data
      };
    }
    updateScan('received invalid JSON response');
    return {
      ok: false,
      message: 'Invalid Socket API response',
      cause: 'The Socket API responded with at least one line that was not valid JSON. Please report if this persists.'
    };
  }
  async function fetchSecurityPolicy() {
    const result = await utils.handleApiCallNoSpinner(sockSdk.getOrgSecurityPolicy(orgSlug), 'GetOrgSecurityPolicy');
    updatePolicy('received policy');
    return result;
  }
  updateProgress();
  const [scan, securityPolicy] = await Promise.all([fetchScanResult().catch(e => {
    updateScan('failure; unknown blocking error occurred');
    return {
      ok: false,
      message: 'Socket API error',
      cause: utils.formatErrorWithDetail('Error requesting scan', e) || 'Error requesting scan: (no error message found)'
    };
  }), fetchSecurityPolicy().catch(e => {
    updatePolicy('failure; unknown blocking error occurred');
    return {
      ok: false,
      message: 'Socket API error',
      cause: utils.formatErrorWithDetail('Error requesting policy', e) || 'Error requesting policy: (no error message found)'
    };
  })]).finally(() => {
    finishedFetching = true;
    updateProgress();
  });
  if (!scan.ok) {
    return scan;
  }
  if (!securityPolicy.ok) {
    return securityPolicy;
  }
  if (!Array.isArray(scan.data)) {
    return {
      ok: false,
      message: 'Failed to fetch',
      cause: 'Was unable to fetch scan result, bailing'
    };
  }
  return {
    ok: true,
    data: {
      scan: scan.data,
      securityPolicy: securityPolicy.data
    }
  };
}

// Note: The returned cResult will only be ok:false when the generation
//       failed. It won't reflect the healthy state.
function generateReport(scan, securityPolicy, {
  fold,
  orgSlug,
  reportLevel,
  scanId,
  short,
  spinner
}) {
  const now = Date.now();
  spinner?.start('Generating report...');

  // Create an object that includes:
  //   healthy: boolean
  //   worst violation level;
  //   per eco
  //     per package
  //       per version
  //         per offending file
  //           reported issue -> policy action

  // In the context of a report;
  // - the alert.severity is irrelevant
  // - the securityPolicyDefault is irrelevant
  // - the report defaults to healthy:true with no alerts
  // - the appearance of an alert will trigger the policy action;
  //   - error: healthy will end up as false, add alerts to report
  //   - warn: healthy unchanged, add alerts to report
  //   - monitor/ignore: no action
  //   - defer: unknown (no action)

  // Note: the server will emit alerts for license policy violations but
  //       those are only included if you set the flag when requesting the scan
  //       data. The alerts map to a single security policy key that determines
  //       what to do with any violation, regardless of the concrete license.
  //       That rule is called "License Policy Violation".
  // The license policy part is implicitly handled here. Either they are
  // included and may show up, or they are not and won't show up.

  const violations = new Map();
  let healthy = true;
  const securityRules = securityPolicy.securityPolicyRules;
  if (securityRules) {
    // Note: reportLevel: error > warn > monitor > ignore > defer
    scan.forEach(artifact => {
      const {
        alerts,
        name: pkgName = constants.UNKNOWN_VALUE,
        type: ecosystem,
        version = constants.UNKNOWN_VALUE
      } = artifact;
      alerts?.forEach(alert => {
        const alertName = alert.type; // => policy[type]
        const action = securityRules[alertName]?.action || '';
        switch (action) {
          case constants.default.REPORT_LEVEL_ERROR:
            {
              healthy = false;
              if (!short) {
                addAlert(artifact, violations, fold, ecosystem, pkgName, version, alert, action);
              }
              break;
            }
          case constants.default.REPORT_LEVEL_WARN:
            {
              if (!short && reportLevel !== constants.default.REPORT_LEVEL_ERROR) {
                addAlert(artifact, violations, fold, ecosystem, pkgName, version, alert, action);
              }
              break;
            }
          case constants.default.REPORT_LEVEL_MONITOR:
            {
              if (!short && reportLevel !== constants.default.REPORT_LEVEL_WARN && reportLevel !== constants.default.REPORT_LEVEL_ERROR) {
                addAlert(artifact, violations, fold, ecosystem, pkgName, version, alert, action);
              }
              break;
            }
          case constants.default.REPORT_LEVEL_IGNORE:
            {
              if (!short && reportLevel !== constants.default.REPORT_LEVEL_MONITOR && reportLevel !== constants.default.REPORT_LEVEL_WARN && reportLevel !== constants.default.REPORT_LEVEL_ERROR) {
                addAlert(artifact, violations, fold, ecosystem, pkgName, version, alert, action);
              }
              break;
            }
          case constants.default.REPORT_LEVEL_DEFER:
            {
              // Not sure but ignore for now. Defer to later ;)
              if (!short && reportLevel === constants.default.REPORT_LEVEL_DEFER) {
                addAlert(artifact, violations, fold, ecosystem, pkgName, version, alert, action);
              }
              break;
            }
        }
      });
    });
  }
  spinner?.successAndStop(`Generated reported in ${Date.now() - now} ms`);
  if (short) {
    return {
      ok: true,
      data: {
        healthy
      }
    };
  }
  const report = {
    healthy,
    orgSlug,
    scanId,
    options: {
      fold,
      reportLevel
    },
    alerts: violations
  };
  if (!healthy) {
    return {
      ok: true,
      message: 'The report contains at least one alert that violates the policies set by your organization',
      data: report
    };
  }
  return {
    ok: true,
    data: report
  };
}
function createLeaf(art, alert, policyAction) {
  const leaf = {
    type: alert.type,
    policy: policyAction,
    url: utils.getSocketDevPackageOverviewUrlFromPurl(art),
    manifest: art.manifestFiles?.map(o => o.file) ?? []
  };
  return leaf;
}
function addAlert(art, violations, fold, ecosystem, pkgName, version, alert, policyAction) {
  if (!violations.has(ecosystem)) {
    violations.set(ecosystem, new Map());
  }
  const ecoMap = violations.get(ecosystem);
  if (fold === constants.default.FOLD_SETTING_PKG) {
    const existing = ecoMap.get(pkgName);
    if (!existing || isStricterPolicy(existing.policy, policyAction)) {
      ecoMap.set(pkgName, createLeaf(art, alert, policyAction));
    }
  } else {
    if (!ecoMap.has(pkgName)) {
      ecoMap.set(pkgName, new Map());
    }
    const pkgMap = ecoMap.get(pkgName);
    if (fold === constants.default.FOLD_SETTING_VERSION) {
      const existing = pkgMap.get(version);
      if (!existing || isStricterPolicy(existing.policy, policyAction)) {
        pkgMap.set(version, createLeaf(art, alert, policyAction));
      }
    } else {
      if (!pkgMap.has(version)) {
        pkgMap.set(version, new Map());
      }
      const file = alert.file || constants.UNKNOWN_VALUE;
      const verMap = pkgMap.get(version);
      if (fold === constants.default.FOLD_SETTING_FILE) {
        const existing = verMap.get(file);
        if (!existing || isStricterPolicy(existing.policy, policyAction)) {
          verMap.set(file, createLeaf(art, alert, policyAction));
        }
      } else {
        if (!verMap.has(file)) {
          verMap.set(file, new Map());
        }
        const key = `${alert.type} at ${alert.start}:${alert.end}`;
        const fileMap = verMap.get(file);
        const existing = fileMap.get(key);
        if (!existing || isStricterPolicy(existing.policy, policyAction)) {
          fileMap.set(key, createLeaf(art, alert, policyAction));
        }
      }
    }
  }
}
function isStricterPolicy(was, is) {
  // error > warn > monitor > ignore > defer > {unknown}
  if (was === constants.default.REPORT_LEVEL_ERROR) {
    return false;
  }
  if (is === constants.default.REPORT_LEVEL_ERROR) {
    return true;
  }
  if (was === constants.default.REPORT_LEVEL_WARN) {
    return false;
  }
  if (is === constants.default.REPORT_LEVEL_WARN) {
    return false;
  }
  if (was === constants.default.REPORT_LEVEL_MONITOR) {
    return false;
  }
  if (is === constants.default.REPORT_LEVEL_MONITOR) {
    return false;
  }
  if (was === constants.default.REPORT_LEVEL_IGNORE) {
    return false;
  }
  if (is === constants.default.REPORT_LEVEL_IGNORE) {
    return false;
  }
  if (was === constants.default.REPORT_LEVEL_DEFER) {
    return false;
  }
  if (is === constants.default.REPORT_LEVEL_DEFER) {
    return false;
  }
  // unreachable?
  return false;
}

async function outputScanReport(result, {
  filepath,
  fold,
  includeLicensePolicy,
  orgSlug,
  outputKind,
  reportLevel,
  scanId,
  short
}) {
  if (!result.ok) {
    process.exitCode = result.code ?? 1;
  }
  if (!result.ok) {
    if (outputKind === constants.OUTPUT_JSON) {
      logger.logger.log(utils.serializeResultJson(result));
      return;
    }
    logger.logger.fail(utils.failMsgWithBadge(result.message, result.cause));
    return;
  }
  const scanReport = generateReport(result.data.scan, result.data.securityPolicy, {
    orgSlug,
    scanId,
    fold,
    reportLevel,
    short,
    spinner: constants.default.spinner
  });
  if (!scanReport.ok) {
    // Note: This means generation failed, it does not reflect the healthy state.
    process.exitCode = scanReport.code ?? 1;

    // If report generation somehow failed then .data should not be set.
    if (outputKind === constants.OUTPUT_JSON) {
      logger.logger.log(utils.serializeResultJson(scanReport));
      return;
    }
    logger.logger.fail(utils.failMsgWithBadge(scanReport.message, scanReport.cause));
    return;
  }

  // I don't think we emit the default error message with banner for an unhealthy report, do we?
  // if (!scanReport.data.healthy) {
  //   logger.fail(failMsgWithBadge(scanReport.message, scanReport.cause))
  //   return
  // }

  if (outputKind === constants.OUTPUT_JSON || outputKind === constants.OUTPUT_TEXT && filepath && filepath.endsWith(constants.EXT_JSON)) {
    const json = short ? utils.serializeResultJson(scanReport) : toJsonReport(scanReport.data, includeLicensePolicy);
    if (filepath && filepath !== '-') {
      logger.logger.log('Writing json report to', filepath);
      return await fs.writeFile(filepath, json);
    }
    logger.logger.log(json);
    return;
  }
  if (outputKind === 'markdown' || filepath && filepath.endsWith('.md')) {
    const md = short ? `healthy = ${scanReport.data.healthy}` : toMarkdownReport(
    // Not short so must be a regular report.
    scanReport.data, includeLicensePolicy);
    if (filepath && filepath !== '-') {
      logger.logger.log('Writing markdown report to', filepath);
      return await fs.writeFile(filepath, md);
    }
    logger.logger.log(md);
    logger.logger.log('');
    return;
  }
  if (short) {
    logger.logger.log(scanReport.data.healthy ? 'OK' : 'ERR');
  } else {
    logger.logger.dir(scanReport.data, {
      depth: null
    });
  }
}
function toJsonReport(report, includeLicensePolicy) {
  const obj = utils.mapToObject(report.alerts);
  const newReport = {
    includeLicensePolicy,
    ...report,
    alerts: obj
  };
  return utils.serializeResultJson({
    ok: true,
    data: newReport
  });
}
function toMarkdownReport(report, includeLicensePolicy) {
  const reportLevel = report.options.reportLevel;
  const alertFolding = report.options.fold === constants.default.FOLD_SETTING_NONE ? 'none' : `up to ${report.options.fold}`;
  const flatData = Array.from(utils.walkNestedMap(report.alerts)).map(({
    keys,
    value
  }) => {
    const {
      manifest,
      policy,
      type,
      url
    } = value;
    return {
      'Alert Type': type,
      Package: keys[1] || '<unknown>',
      'Introduced by': keys[2] || '<unknown>',
      url,
      'Manifest file': arrays.joinAnd(manifest),
      Policy: policy
    };
  });
  const minPolicyLevel = reportLevel === constants.default.REPORT_LEVEL_DEFER ? 'everything' : reportLevel;
  const md = `
# Scan Policy Report

This report tells you whether the results of a Socket scan results violate the
security${includeLicensePolicy ? ' or license' : ''} policy set by your organization.

## Health status

${report.healthy ? `The scan *PASSES* all requirements set by your security${includeLicensePolicy ? ' and license' : ''} policy.` : 'The scan *VIOLATES* one or more policies set to the "error" level.'}

## Settings

Configuration used to generate this report:

- Organization: ${report.orgSlug}
- Scan ID: ${report.scanId}
- Alert folding: ${alertFolding}
- Minimal policy level for alert to be included in report: ${minPolicyLevel}
- Include license alerts: ${includeLicensePolicy ? 'yes' : 'no'}

## Alerts

${report.alerts.size ? `All the alerts from the scan with a policy set to at least "${reportLevel}".` : `The scan contained no alerts with a policy set to at least "${reportLevel}".`}

${!report.alerts.size ? '' : utils.mdTable(flatData, ['Policy', 'Alert Type', 'Package', 'Introduced by', 'url', 'Manifest file'])}
  `.trim() + '\n';
  return md;
}

async function handleScanReport({
  filepath,
  fold,
  includeLicensePolicy,
  orgSlug,
  outputKind,
  reportLevel,
  scanId,
  short
}) {
  const scanDataCResult = await fetchScanData(orgSlug, scanId, {
    includeLicensePolicy
  });
  await outputScanReport(scanDataCResult, {
    filepath,
    fold,
    scanId: scanId,
    includeLicensePolicy,
    orgSlug,
    outputKind,
    reportLevel,
    short
  });
}

async function outputCreateNewScan(result, options) {
  const {
    interactive = false,
    outputKind = 'text',
    spinner = constants.default.spinner
  } = {
    __proto__: null,
    ...options
  };
  if (!result.ok) {
    process.exitCode = result.code ?? 1;
  }
  const wasSpinning = !!spinner?.isSpinning;
  spinner?.stop();
  if (outputKind === 'json') {
    logger.logger.log(utils.serializeResultJson(result));
    if (wasSpinning) {
      spinner.start();
    }
    return;
  }
  if (!result.ok) {
    logger.logger.fail(utils.failMsgWithBadge(result.message, result.cause));
    if (wasSpinning) {
      spinner.start();
    }
    return;
  }
  if (!result.data.id) {
    logger.logger.fail('Did not receive a scan ID from the API.');
    process.exitCode = 1;
  }
  if (outputKind === 'markdown') {
    logger.logger.log('# Create New Scan');
    logger.logger.log('');
    if (result.data.id) {
      logger.logger.log(`A [new Scan](${result.data.html_report_url}) was created with ID: ${result.data.id}`);
      logger.logger.log('');
    } else {
      logger.logger.log(`The server did not return a Scan ID while trying to create a new Scan. This could be an indication something went wrong.`);
    }
    logger.logger.log('');
    if (wasSpinning) {
      spinner.start();
    }
    return;
  }
  logger.logger.log('');
  logger.logger.success('Scan completed successfully!');
  const htmlReportUrl = result.data.html_report_url;
  if (htmlReportUrl) {
    logger.logger.log(`View report at: ${vendor.terminalLinkExports(htmlReportUrl, htmlReportUrl)}`);
  } else {
    logger.logger.log('No report available.');
  }
  if (interactive && (await prompts.confirm({
    message: 'Would you like to open it in your browser?',
    default: false
  }, {
    spinner
  }))) {
    await vendor.open(`${result.data.html_report_url}`);
  }
  if (wasSpinning) {
    spinner.start();
  }
}

async function performReachabilityAnalysis(options) {
  const {
    branchName,
    cwd = process.cwd(),
    orgSlug,
    packagePaths,
    reachabilityOptions,
    repoName,
    spinner,
    uploadManifests = true
  } = {
    __proto__: null,
    ...options
  };

  // Check if user has enterprise plan for reachability analysis.
  const orgsCResult = await utils.fetchOrganization();
  if (!orgsCResult.ok) {
    return {
      ok: false,
      message: 'Unable to verify plan permissions',
      cause: 'Failed to fetch organization information to verify enterprise plan access'
    };
  }
  const {
    organizations
  } = orgsCResult.data;
  if (!utils.hasEnterpriseOrgPlan(organizations)) {
    return {
      ok: false,
      message: 'Tier 1 Reachability analysis requires an enterprise plan',
      cause: `Please ${utils.socketDevLink('upgrade your plan', '/pricing')}. This feature is only available for organizations with an enterprise plan.`
    };
  }
  const wasSpinning = !!spinner?.isSpinning;
  let tarHash;
  if (uploadManifests && orgSlug && packagePaths) {
    // Setup SDK for uploading manifests
    const sockSdkCResult = await utils.setupSdk();
    if (!sockSdkCResult.ok) {
      return sockSdkCResult;
    }
    const sockSdk = sockSdkCResult.data;

    // Exclude any .socket.facts.json files that happen to be in the scan
    // folder before the analysis was run.
    const filepathsToUpload = packagePaths.filter(p => path.basename(p).toLowerCase() !== constants.default.DOT_SOCKET_DOT_FACTS_JSON);
    spinner?.start('Uploading manifests for reachability analysis...');
    const uploadCResult = await utils.handleApiCall(sockSdk.uploadManifestFiles(orgSlug, filepathsToUpload), {
      description: 'upload manifests',
      spinner
    });
    spinner?.stop();
    if (!uploadCResult.ok) {
      if (wasSpinning) {
        spinner.start();
      }
      return uploadCResult;
    }
    tarHash = uploadCResult.data?.tarHash;
    if (!tarHash) {
      if (wasSpinning) {
        spinner.start();
      }
      return {
        ok: false,
        message: 'Failed to get manifest tar hash',
        cause: 'Server did not return a tar hash for the uploaded manifests'
      };
    }
    spinner?.start();
    spinner?.success(`Manifests uploaded successfully. Tar hash: ${tarHash}`);
  }
  spinner?.start();
  spinner?.infoAndStop('Running reachability analysis with Coana...');

  // Build Coana arguments.
  const coanaArgs = ['run', cwd, '--output-dir', cwd, '--socket-mode', constants.default.DOT_SOCKET_DOT_FACTS_JSON, '--disable-report-submission', ...(reachabilityOptions.reachAnalysisTimeout ? ['--analysis-timeout', `${reachabilityOptions.reachAnalysisTimeout}`] : []), ...(reachabilityOptions.reachAnalysisMemoryLimit ? ['--memory-limit', `${reachabilityOptions.reachAnalysisMemoryLimit}`] : []), ...(reachabilityOptions.reachDisableAnalytics ? ['--disable-analytics-sharing'] : []), ...(tarHash ? ['--run-without-docker', '--manifests-tar-hash', tarHash] : []),
  // Empty reachEcosystems implies scanning all ecosystems.
  ...(reachabilityOptions.reachEcosystems.length ? ['--purl-types', ...reachabilityOptions.reachEcosystems] : []), ...(reachabilityOptions.reachExcludePaths.length ? ['--exclude-dirs', ...reachabilityOptions.reachExcludePaths] : []), ...(reachabilityOptions.reachSkipCache ? ['--skip-cache-usage'] : [])];

  // Build environment variables.
  const coanaEnv = {};
  // do not pass default repo and branch name to coana to avoid mixing
  // buckets (cached configuration) from projects that are likely very different.
  if (repoName && repoName !== constants.default.SOCKET_DEFAULT_REPOSITORY) {
    coanaEnv['SOCKET_REPO_NAME'] = repoName;
  }
  if (branchName && branchName !== constants.default.SOCKET_DEFAULT_BRANCH) {
    coanaEnv['SOCKET_BRANCH_NAME'] = branchName;
  }

  // Run Coana with the manifests tar hash.
  const coanaResult = await utils.spawnCoanaDlx(coanaArgs, orgSlug, {
    cwd,
    env: coanaEnv,
    spinner,
    stdio: 'inherit'
  });
  if (wasSpinning) {
    spinner.start();
  }
  return coanaResult.ok ? {
    ok: true,
    data: {
      // Use the DOT_SOCKET_DOT_FACTS_JSON file for the scan.
      reachabilityReport: constants.default.DOT_SOCKET_DOT_FACTS_JSON,
      tier1ReachabilityScanId: utils.extractTier1ReachabilityScanId(constants.default.DOT_SOCKET_DOT_FACTS_JSON)
    }
  } : coanaResult;
}

// The point here is to attempt to detect the various supported manifest files
// the CLI can generate. This would be environments that we can't do server side

async function detectManifestActions(
// Passing in null means we attempt detection for every supported language
// regardless of local socket.json status. Sometimes we want that.
sockJson, cwd = process.cwd()) {
  const output = {
    cdxgen: false,
    // TODO
    count: 0,
    conda: false,
    gradle: false,
    sbt: false
  };
  if (sockJson?.defaults?.manifest?.sbt?.disabled) {
    require$$9.debugLog('notice', `[DEBUG] - sbt auto-detection is disabled in ${constants.SOCKET_JSON}`);
  } else if (fs$1.existsSync(path.join(cwd, 'build.sbt'))) {
    require$$9.debugLog('notice', '[DEBUG] - Detected a Scala sbt build file');
    output.sbt = true;
    output.count += 1;
  }
  if (sockJson?.defaults?.manifest?.gradle?.disabled) {
    require$$9.debugLog('notice', `[DEBUG] - gradle auto-detection is disabled in ${constants.SOCKET_JSON}`);
  } else if (fs$1.existsSync(path.join(cwd, 'gradlew'))) {
    require$$9.debugLog('notice', '[DEBUG] - Detected a gradle build file');
    output.gradle = true;
    output.count += 1;
  }
  if (sockJson?.defaults?.manifest?.conda?.disabled) {
    require$$9.debugLog('notice', `[DEBUG] - conda auto-detection is disabled in ${constants.SOCKET_JSON}`);
  } else {
    const envyml = path.join(cwd, constants.ENVIRONMENT_YML);
    const hasEnvyml = fs$1.existsSync(envyml);
    const envyaml = path.join(cwd, constants.ENVIRONMENT_YAML);
    const hasEnvyaml = !hasEnvyml && fs$1.existsSync(envyaml);
    if (hasEnvyml || hasEnvyaml) {
      require$$9.debugLog('notice', '[DEBUG] - Detected an environment.yml Conda file');
      output.conda = true;
      output.count += 1;
    }
  }
  return output;
}

async function convertGradleToMaven({
  bin,
  cwd,
  gradleOpts,
  verbose
}) {
  // TODO: Implement json/md.

  // Note: use resolve because the bin could be an absolute path, away from cwd
  // TODO: what about $PATH resolved commands? (`gradlew` without dir prefix)
  const rBin = path.resolve(cwd, bin);
  const binExists = fs$1.existsSync(rBin);
  const cwdExists = fs$1.existsSync(cwd);
  logger.logger.group('gradle2maven:');
  logger.logger.info(`- executing: \`${rBin}\``);
  if (!binExists) {
    logger.logger.warn(`Warning: It appears the executable could not be found. An error might be printed later because of that.`);
  }
  logger.logger.info(`- src dir: \`${cwd}\``);
  if (!cwdExists) {
    logger.logger.warn(`Warning: It appears the src dir could not be found. An error might be printed later because of that.`);
  }
  logger.logger.groupEnd();
  try {
    // Run gradlew with the init script we provide which should yield zero or more
    // pom files. We have to figure out where to store those pom files such that
    // we can upload them and predict them through the GitHub API. We could do a
    // .socket folder. We could do a socket.pom.gz with all the poms, although
    // I'd prefer something plain-text if it is to be committed.
    // Note: init.gradle will be exported by .config/rollup.dist.config.mjs
    const initLocation = path.join(constants.default.distPath, 'init.gradle');
    const commandArgs = ['--init-script', initLocation, ...gradleOpts, 'pom'];
    if (verbose) {
      logger.logger.log('[VERBOSE] Executing:', [bin], ', args:', commandArgs);
    }
    logger.logger.log(`Converting gradle to maven from \`${bin}\` on \`${cwd}\` ...`);
    const output = await execGradleWithSpinner(rBin, commandArgs, cwd);
    if (verbose) {
      logger.logger.group('[VERBOSE] gradle stdout:');
      logger.logger.log(output);
      logger.logger.groupEnd();
    }
    if (output.code) {
      process.exitCode = 1;
      logger.logger.fail(`Gradle exited with exit code ${output.code}`);
      // (In verbose mode, stderr was printed above, no need to repeat it)
      if (!verbose) {
        logger.logger.group('stderr:');
        logger.logger.error(output.stderr);
        logger.logger.groupEnd();
      }
      return;
    }
    logger.logger.success('Executed gradle successfully');
    logger.logger.log('Reported exports:');
    output.stdout.replace(/^POM file copied to: (.*)/gm, (_all, fn) => {
      logger.logger.log('- ', fn);
      return fn;
    });
    logger.logger.log('');
    logger.logger.log('Next step is to generate a Scan by running the `socket scan create` command on the same directory');
  } catch (e) {
    process.exitCode = 1;
    logger.logger.fail('There was an unexpected error while generating manifests' + (verbose ? '' : '  (use --verbose for details)'));
    if (verbose) {
      logger.logger.group('[VERBOSE] error:');
      logger.logger.log(e);
      logger.logger.groupEnd();
    }
  }
}
async function execGradleWithSpinner(bin, commandArgs, cwd) {
  const {
    spinner
  } = constants.default;
  let pass = false;
  try {
    logger.logger.info('(Running gradle can take a while, it depends on how long gradlew has to run)');
    logger.logger.info('(It will show no output, you can use --verbose to see its output)');
    spinner.start(`Running gradlew...`);
    const output = await spawn.spawn(bin, commandArgs, {
      // We can pipe the output through to have the user see the result
      // of running gradlew, but then we can't (easily) gather the output
      // to discover the generated files... probably a flag we should allow?
      // stdio: isDebug() ? 'inherit' : undefined,
      cwd
    });
    pass = true;
    const {
      code,
      stderr,
      stdout
    } = output;
    return {
      code,
      stdout,
      stderr
    };
  } finally {
    if (pass) {
      spinner.successAndStop('Gracefully completed gradlew execution.');
    } else {
      spinner.failAndStop('There was an error while trying to run gradlew.');
    }
  }
}

async function convertSbtToMaven({
  bin,
  cwd,
  out,
  sbtOpts,
  verbose
}) {
  // TODO: Implement json/md.

  const {
    spinner
  } = constants.default;
  logger.logger.group('sbt2maven:');
  logger.logger.info(`- executing: \`${bin}\``);
  logger.logger.info(`- src dir: \`${cwd}\``);
  logger.logger.groupEnd();
  try {
    spinner.start(`Converting sbt to maven from \`${bin}\` on \`${cwd}\`...`);

    // Run sbt with the init script we provide which should yield zero or more
    // pom files. We have to figure out where to store those pom files such that
    // we can upload them and predict them through the GitHub API. We could do a
    // .socket folder. We could do a socket.pom.gz with all the poms, although
    // I'd prefer something plain-text if it is to be committed.
    const output = await spawn.spawn(bin, ['makePom', ...sbtOpts], {
      cwd
    });
    spinner.stop();
    if (verbose) {
      logger.logger.group('[VERBOSE] sbt stdout:');
      logger.logger.log(output);
      logger.logger.groupEnd();
    }
    if (output.stderr) {
      process.exitCode = 1;
      logger.logger.fail('There were errors while running sbt');
      // (In verbose mode, stderr was printed above, no need to repeat it)
      if (!verbose) {
        logger.logger.group('[VERBOSE] stderr:');
        logger.logger.error(output.stderr);
        logger.logger.groupEnd();
      }
      return;
    }
    const poms = [];
    output.stdout.replace(/Wrote (.*?.pom)\n/g, (_all, fn) => {
      poms.push(fn);
      return fn;
    });
    if (!poms.length) {
      process.exitCode = 1;
      logger.logger.fail('There were no errors from sbt but it seems to not have generated any poms either');
      return;
    }
    // Move the pom file to ...? initial cwd? loc will be an absolute path, or dump to stdout
    // TODO: What do we do with multiple output files? Do we want to dump them to stdout? Raw or with separators or ?
    // TODO: Maybe we can add an option to target a specific file to dump to stdout.
    if (out === '-' && poms.length === 1) {
      logger.logger.log('Result:\n```');
      logger.logger.log(await fs$2.safeReadFile(poms[0]));
      logger.logger.log('```');
      logger.logger.success(`OK`);
    } else if (out === '-') {
      process.exitCode = 1;
      logger.logger.error('');
      logger.logger.fail('Requested output target was stdout but there are multiple generated files');
      logger.logger.error('');
      poms.forEach(fn => logger.logger.info('-', fn));
      if (poms.length > 10) {
        logger.logger.error('');
        logger.logger.fail('Requested output target was stdout but there are multiple generated files');
      }
      logger.logger.error('');
      logger.logger.info('Exiting now...');
      return;
    } else {
      // if (verbose) {
      //   logger.log(
      //     `Moving manifest file from \`${loc.replace(/^\/home\/[^/]*?\//, '~/')}\` to \`${out}\``
      //   )
      // } else {
      //   logger.log('Moving output pom file')
      // }
      // TODO: Do we prefer fs-extra? Renaming can be gnarly on windows and fs-extra's version is better.
      // await renamep(loc, out)
      logger.logger.success(`Generated ${poms.length} pom files`);
      poms.forEach(fn => logger.logger.log('-', fn));
      logger.logger.success(`OK`);
    }
  } catch (e) {
    process.exitCode = 1;
    spinner.stop();
    logger.logger.fail('There was an unexpected error while running this' + (verbose ? '' : ' (use --verbose for details)'));
    if (verbose) {
      logger.logger.group('[VERBOSE] error:');
      logger.logger.log(e);
      logger.logger.groupEnd();
    }
  }
}

function prepareContent(content) {
  return strings.stripAnsi(content.trim());
}
async function convertCondaToRequirements(filename, cwd, verbose) {
  let content;
  if (filename === '-') {
    if (verbose) {
      logger.logger.info(`[VERBOSE] reading input from stdin`);
    }
    const strings = [];
    content = await new Promise((resolve, reject) => {
      process.stdin.on('data', chunk => {
        const input = chunk.toString();
        strings.push(input);
      });
      process.stdin.on('end', () => {
        resolve(prepareContent(strings.join('')));
      });
      process.stdin.on('error', e => {
        if (verbose) {
          logger.logger.error('Unexpected error while reading from stdin:', e);
        }
        reject(e);
      });
      process.stdin.on('close', () => {
        if (strings.length) {
          if (verbose) {
            logger.logger.error('warning: stdin closed explicitly with some data received');
          }
          resolve(prepareContent(strings.join('')));
        } else {
          if (verbose) {
            logger.logger.error('stdin closed explicitly without data received');
          }
          reject(new Error('No data received from stdin'));
        }
      });
    });
    if (!content) {
      return {
        ok: false,
        message: 'Manifest Generation Failed',
        cause: 'No data received from stdin'
      };
    }
  } else {
    const filepath = path.join(cwd, filename);
    if (verbose) {
      logger.logger.info(`[VERBOSE] target: ${filepath}`);
    }
    if (!fs$1.existsSync(filepath)) {
      return {
        ok: false,
        message: 'Manifest Generation Failed',
        cause: `The file was not found at ${filepath}`
      };
    }
    content = fs$1.readFileSync(filepath, 'utf8');
    if (!content) {
      return {
        ok: false,
        message: 'Manifest Generation Failed',
        cause: `File at ${filepath} is empty`
      };
    }
  }
  return {
    ok: true,
    data: {
      content,
      pip: convertCondaToRequirementsFromInput(content)
    }
  };
}

// Just extract the first pip block, if one exists at all.
function convertCondaToRequirementsFromInput(input) {
  let collecting = false;
  let delim = '-';
  let indent = '';
  const keeping = [];
  for (const line of input.split('\n')) {
    const trimmed = line.trim();
    if (!trimmed) {
      // Ignore empty lines.
      continue;
    }
    if (collecting) {
      if (line.startsWith('#')) {
        // Ignore comment lines (keep?).
        continue;
      }
      if (line.startsWith(delim)) {
        // In this case we have a line with the same indentation as the
        // `- pip:` line, so we have reached the end of the pip block.
        break;
      }
      if (!indent) {
        // Store the indentation of the block.
        if (trimmed.startsWith('-')) {
          indent = line.split('-')[0] + '-';
          if (indent.length <= delim.length) {
            // The first line after the `pip:` line does not indent further
            // than that so the block is empty?
            break;
          }
        }
      }
      if (line.startsWith(indent)) {
        keeping.push(line.slice(indent.length).trim());
      } else {
        // Unexpected input. bail.
        break;
      }
    }
    // Note: the line may end with a line comment so don't === it.
    else if (trimmed.startsWith('- pip:')) {
      delim = line.split('-')[0] + '-';
      collecting = true;
    }
  }
  return prepareContent(keeping.join('\n'));
}

async function outputRequirements(result, outputKind, out) {
  if (!result.ok) {
    process.exitCode = result.code ?? 1;
  }
  if (!result.ok) {
    if (outputKind === 'json') {
      logger.logger.log(utils.serializeResultJson(result));
      return;
    }
    logger.logger.fail(utils.failMsgWithBadge(result.message, result.cause));
    return;
  }
  if (outputKind === 'json') {
    const json = utils.serializeResultJson(result);
    if (out === '-') {
      logger.logger.log(json);
    } else {
      fs$1.writeFileSync(out, json, 'utf8');
    }
    return;
  }
  if (outputKind === 'markdown') {
    const arr = [];
    arr.push('# Converted Conda file');
    arr.push('');
    arr.push(`This is the Conda \`environment.yml\` file converted to python \`${constants.REQUIREMENTS_TXT}\`:`);
    arr.push('');
    arr.push(`\`\`\`file=${constants.REQUIREMENTS_TXT}`);
    arr.push(result.data.pip);
    arr.push('```');
    arr.push('');
    const md = arr.join('\n');
    if (out === '-') {
      logger.logger.log(md);
    } else {
      fs$1.writeFileSync(out, md, 'utf8');
    }
    return;
  }
  if (out === '-') {
    logger.logger.log(result.data.pip);
    logger.logger.log('');
  } else {
    fs$1.writeFileSync(out, result.data.pip, 'utf8');
  }
}

async function handleManifestConda({
  cwd,
  filename,
  out,
  outputKind,
  verbose
}) {
  const data = await convertCondaToRequirements(filename, cwd, verbose);
  await outputRequirements(data, outputKind, out);
}

async function generateAutoManifest({
  cwd,
  detected,
  outputKind,
  verbose
}) {
  const sockJson = utils.readOrDefaultSocketJson(cwd);
  if (verbose) {
    logger.logger.info(`Using this ${constants.SOCKET_JSON} for defaults:`, sockJson);
  }
  if (!sockJson?.defaults?.manifest?.sbt?.disabled && detected.sbt) {
    logger.logger.log('Detected a Scala sbt build, generating pom files with sbt...');
    await convertSbtToMaven({
      // Note: `sbt` is more likely to be resolved against PATH env
      bin: sockJson.defaults?.manifest?.sbt?.bin ?? 'sbt',
      cwd,
      out: sockJson.defaults?.manifest?.sbt?.outfile ?? './socket.sbt.pom.xml',
      sbtOpts: sockJson.defaults?.manifest?.sbt?.sbtOpts?.split(' ').map(s => s.trim()).filter(Boolean) ?? [],
      verbose: Boolean(sockJson.defaults?.manifest?.sbt?.verbose)
    });
  }
  if (!sockJson?.defaults?.manifest?.gradle?.disabled && detected.gradle) {
    logger.logger.log('Detected a gradle build (Gradle, Kotlin, Scala), running default gradle generator...');
    await convertGradleToMaven({
      // Note: `gradlew` is more likely to be resolved against cwd.
      // Note: .resolve() won't butcher an absolute path.
      // TODO: `gradlew` (or anything else given) may want to resolve against PATH.
      bin: sockJson.defaults?.manifest?.gradle?.bin ? path.resolve(cwd, sockJson.defaults.manifest.gradle.bin) : path.join(cwd, 'gradlew'),
      cwd,
      verbose: Boolean(sockJson.defaults?.manifest?.gradle?.verbose),
      gradleOpts: sockJson.defaults?.manifest?.gradle?.gradleOpts?.split(' ').map(s => s.trim()).filter(Boolean) ?? []
    });
  }
  if (!sockJson?.defaults?.manifest?.conda?.disabled && detected.conda) {
    logger.logger.log('Detected an environment.yml file, running default Conda generator...');
    await handleManifestConda({
      cwd,
      filename: sockJson.defaults?.manifest?.conda?.infile ?? 'environment.yml',
      outputKind,
      out: sockJson.defaults?.manifest?.conda?.outfile ?? constants.REQUIREMENTS_TXT,
      verbose: Boolean(sockJson.defaults?.manifest?.conda?.verbose)
    });
  }
}

async function handleCreateNewScan({
  autoManifest,
  branchName,
  commitHash,
  commitMessage,
  committers,
  cwd,
  defaultBranch,
  interactive,
  orgSlug,
  outputKind,
  pendingHead,
  pullRequest,
  reach,
  readOnly,
  repoName,
  report,
  reportLevel,
  targets,
  tmp
}) {
  require$$9.debugFn('notice', `Creating new scan for ${orgSlug}/${repoName}`);
  require$$9.debugDir('inspect', {
    autoManifest,
    branchName,
    commitHash,
    defaultBranch,
    interactive,
    pendingHead,
    pullRequest,
    readOnly,
    report,
    reportLevel,
    targets,
    tmp
  });
  if (autoManifest) {
    logger.logger.info('Auto-generating manifest files ...');
    require$$9.debugFn('notice', 'Auto-manifest mode enabled');
    const sockJson = utils.readOrDefaultSocketJson(cwd);
    const detected = await detectManifestActions(sockJson, cwd);
    require$$9.debugDir('inspect', {
      detected
    });
    await generateAutoManifest({
      detected,
      cwd,
      outputKind,
      verbose: false
    });
    logger.logger.info('Auto-generation finished. Proceeding with Scan creation.');
  }
  const {
    spinner
  } = constants.default;
  const supportedFilesCResult = await fetchSupportedScanFileNames({
    spinner
  });
  if (!supportedFilesCResult.ok) {
    require$$9.debugFn('warn', 'Failed to fetch supported scan file names');
    require$$9.debugDir('inspect', {
      supportedFilesCResult
    });
    await outputCreateNewScan(supportedFilesCResult, {
      interactive,
      outputKind
    });
    return;
  }
  require$$9.debugFn('notice', `Fetched ${supportedFilesCResult.data['size']} supported file types`);
  spinner.start('Searching for local files to include in scan...');
  const supportedFiles = supportedFilesCResult.data;
  const packagePaths = await utils.getPackageFilesForScan(targets, supportedFiles, {
    cwd
  });
  spinner.successAndStop(`Found ${packagePaths.length} ${words.pluralize('file', packagePaths.length)} to include in scan.`);
  const wasValidInput = utils.checkCommandInput(outputKind, {
    nook: true,
    test: packagePaths.length > 0,
    fail: `found no eligible files to scan. See supported manifest files at ${utils.socketDocsLink('/docs/manifest-file-detection-in-socket', 'docs.socket.dev')}`,
    message: 'TARGET (file/dir) must contain matching / supported file types for a scan'
  });
  if (!wasValidInput) {
    require$$9.debugFn('warn', 'No eligible files found to scan');
    return;
  }
  logger.logger.success(`Found ${packagePaths.length} local ${words.pluralize('file', packagePaths.length)}`);
  require$$9.debugDir('inspect', {
    packagePaths
  });
  if (readOnly) {
    logger.logger.log('[ReadOnly] Bailing now');
    require$$9.debugFn('notice', 'Read-only mode, exiting early');
    return;
  }
  let scanPaths = packagePaths;
  let tier1ReachabilityScanId;

  // If reachability is enabled, perform reachability analysis.
  if (reach.runReachabilityAnalysis) {
    logger.logger.error('');
    logger.logger.info('Starting reachability analysis...');
    require$$9.debugFn('notice', 'Reachability analysis enabled');
    require$$9.debugDir('inspect', {
      reachabilityOptions: reach
    });
    spinner.start();
    const reachResult = await performReachabilityAnalysis({
      branchName,
      cwd,
      orgSlug,
      packagePaths,
      reachabilityOptions: reach,
      repoName,
      spinner
    });
    spinner.stop();
    if (!reachResult.ok) {
      await outputCreateNewScan(reachResult, {
        interactive,
        outputKind
      });
      return;
    }
    logger.logger.success('Reachability analysis completed successfully');
    const reachabilityReport = reachResult.data?.reachabilityReport;
    scanPaths = [...packagePaths.filter(
    // Ensure the .socket.facts.json isn't duplicated in case it happened
    // to be in the scan folder before the analysis was run.
    p => path.basename(p).toLowerCase() !== constants.default.DOT_SOCKET_DOT_FACTS_JSON), ...(reachabilityReport ? [reachabilityReport] : [])];
    tier1ReachabilityScanId = reachResult.data?.tier1ReachabilityScanId;
  }
  const fullScanCResult = await fetchCreateOrgFullScan(scanPaths, orgSlug, {
    commitHash,
    commitMessage,
    committers,
    pullRequest,
    repoName,
    branchName
  }, {
    cwd,
    defaultBranch,
    pendingHead,
    tmp
  });
  const scanId = fullScanCResult.ok ? fullScanCResult.data?.id : undefined;
  if (reach && scanId && tier1ReachabilityScanId) {
    await finalizeTier1Scan(tier1ReachabilityScanId, scanId);
  }
  if (report && fullScanCResult.ok) {
    if (scanId) {
      await handleScanReport({
        filepath: '-',
        fold: constants.default.FOLD_SETTING_VERSION,
        includeLicensePolicy: true,
        orgSlug,
        outputKind,
        reportLevel,
        scanId,
        short: false
      });
    } else {
      await outputCreateNewScan({
        ok: false,
        message: 'Missing Scan ID',
        cause: 'Server did not respond with a scan ID',
        data: fullScanCResult.data
      }, {
        interactive,
        outputKind
      });
    }
  } else {
    spinner.stop();
    await outputCreateNewScan(fullScanCResult, {
      interactive,
      outputKind
    });
  }
}

async function handleCi(autoManifest) {
  require$$9.debugFn('notice', 'Starting CI scan');
  require$$9.debugDir('inspect', {
    autoManifest
  });
  const orgSlugCResult = await utils.getDefaultOrgSlug();
  if (!orgSlugCResult.ok) {
    require$$9.debugFn('warn', 'Failed to get default org slug');
    require$$9.debugDir('inspect', {
      orgSlugCResult
    });
    process.exitCode = orgSlugCResult.code ?? 1;
    // Always assume json mode.
    logger.logger.log(utils.serializeResultJson(orgSlugCResult));
    return;
  }
  const orgSlug = orgSlugCResult.data;
  const cwd = process.cwd();
  const branchName = (await utils.gitBranch(cwd)) || (await utils.detectDefaultBranch(cwd));
  const repoName = await utils.getRepoName(cwd);
  require$$9.debugFn('notice', `CI scan for ${orgSlug}/${repoName} on branch ${branchName}`);
  require$$9.debugDir('inspect', {
    orgSlug,
    cwd,
    branchName,
    repoName
  });
  await handleCreateNewScan({
    autoManifest,
    branchName,
    commitMessage: '',
    commitHash: '',
    committers: '',
    cwd,
    defaultBranch: false,
    interactive: false,
    orgSlug,
    outputKind: 'json',
    // When 'pendingHead' is true, it requires 'branchName' set and 'tmp' false.
    pendingHead: true,
    pullRequest: 0,
    reach: {
      reachAnalysisTimeout: 0,
      reachAnalysisMemoryLimit: 0,
      reachDisableAnalytics: false,
      reachEcosystems: [],
      reachExcludePaths: [],
      reachSkipCache: false,
      runReachabilityAnalysis: false
    },
    repoName,
    readOnly: false,
    report: true,
    reportLevel: constants.default.REPORT_LEVEL_ERROR,
    targets: ['.'],
    // Don't set 'tmp' when 'pendingHead' is true.
    tmp: false
  });
}

const config$k = {
  commandName: 'ci',
  description: 'Alias for `socket scan create --report` (creates report and exits with error if unhealthy)',
  hidden: false,
  flags: {
    ...flags.commonFlags,
    autoManifest: {
      type: 'boolean',
      // Dev tools in CI environments are not likely to be set up, so this is safer.
      default: false,
      description: 'Auto generate manifest files where detected? See autoManifest flag in `socket scan create`'
    }
  },
  help: (command, _config) => `
    Usage
      $ ${command} [options]

    Options
      ${utils.getFlagListOutput(config$k.flags)}

    This command is intended to use in CI runs to allow automated systems to
    accept or reject a current build. It will use the default org of the
    Socket API token. The exit code will be non-zero when the scan does not pass
    your security policy.

    The --auto-manifest flag does the same as the one from \`socket scan create\`
    but is not enabled by default since the CI is less likely to be set up with
    all the necessary dev tooling. Enable it if you want the scan to include
    locally generated manifests like for gradle and sbt.

    Examples
      $ ${command}
      $ ${command} --auto-manifest
  `
};
const cmdCI = {
  description: config$k.description,
  hidden: config$k.hidden,
  run: run$Q
};
async function run$Q(argv, importMeta, {
  parentName
}) {
  const cli = utils.meowOrExit({
    argv,
    config: config$k,
    parentName,
    importMeta
  });
  const dryRun = !!cli.flags['dryRun'];
  if (dryRun) {
    logger.logger.log(constants.default.DRY_RUN_BAILING_NOW);
    return;
  }
  await handleCi(Boolean(cli.flags['autoManifest']));
}

async function discoverConfigValue(key) {
  // This will have to be a specific implementation per key because certain
  // keys should request information from particular API endpoints while
  // others should simply return their default value, like endpoint URL.

  if (key !== 'test' && !utils.isSupportedConfigKey(key)) {
    return {
      ok: false,
      message: 'Auto discover failed',
      cause: 'Requested key is not a valid config key.'
    };
  }
  if (key === 'apiBaseUrl') {
    // Return the default value
    return {
      ok: false,
      message: 'Auto discover failed',
      cause: "If you're unsure about the base endpoint URL then simply unset it."
    };
  }
  if (key === 'apiProxy') {
    // I don't think we can auto-discover this with any order of reliability..?
    return {
      ok: false,
      message: 'Auto discover failed',
      cause: 'When uncertain, unset this key. Otherwise ask your network administrator'
    };
  }
  if (key === 'apiToken') {
    return {
      ok: false,
      message: 'Auto discover failed',
      cause: 'You can find/create your API token in your Socket dashboard > settings > API tokens.\nYou should then use `socket login` to login instead of this command.'
    };
  }
  if (key === 'defaultOrg') {
    const hasApiToken = utils.hasDefaultApiToken();
    if (!hasApiToken) {
      return {
        ok: false,
        message: 'Auto discover failed',
        cause: 'No API token set, must have a token to resolve its default org.'
      };
    }
    const org = await getDefaultOrgFromToken();
    if (!org?.length) {
      return {
        ok: false,
        message: 'Auto discover failed',
        cause: 'Was unable to determine default org for the current API token.'
      };
    }
    if (Array.isArray(org)) {
      return {
        ok: true,
        data: org,
        message: 'These are the orgs that the current API token can access.'
      };
    }
    return {
      ok: true,
      data: org,
      message: 'This is the org that belongs to the current API token.'
    };
  }
  if (key === 'enforcedOrgs') {
    const hasApiToken = utils.hasDefaultApiToken();
    if (!hasApiToken) {
      return {
        ok: false,
        message: 'Auto discover failed',
        cause: 'No API token set, must have a token to resolve orgs to enforce.'
      };
    }
    const orgs = await getEnforceableOrgsFromToken();
    if (!orgs?.length) {
      return {
        ok: false,
        message: 'Auto discover failed',
        cause: 'Was unable to determine any orgs to enforce for the current API token.'
      };
    }
    return {
      ok: true,
      data: orgs,
      message: 'These are the orgs whose security policy you can enforce.'
    };
  }
  if (key === 'test') {
    return {
      ok: false,
      message: 'Auto discover failed',
      cause: 'congrats, you found the test key'
    };
  }

  // Mostly to please TS, because we're not telling it `key` is keyof LocalConfig
  return {
    ok: false,
    message: 'Auto discover failed',
    cause: 'unreachable?'
  };
}
async function getDefaultOrgFromToken() {
  const orgsCResult = await utils.fetchOrganization();
  if (!orgsCResult.ok) {
    return undefined;
  }
  const {
    organizations
  } = orgsCResult.data;
  if (organizations.length === 0) {
    return undefined;
  }
  const slugs = utils.getOrgSlugs(organizations);
  if (slugs.length === 1) {
    return slugs[0];
  }
  return slugs;
}
async function getEnforceableOrgsFromToken() {
  const orgsCResult = await utils.fetchOrganization();
  if (!orgsCResult.ok) {
    return undefined;
  }
  const {
    organizations
  } = orgsCResult.data;
  return organizations.length ? utils.getOrgSlugs(organizations) : undefined;
}

async function outputConfigAuto(key, result, outputKind) {
  if (!result.ok) {
    process.exitCode = result.code ?? 1;
  }
  if (outputKind === 'json') {
    logger.logger.log(utils.serializeResultJson(result));
    return;
  }
  if (!result.ok) {
    logger.logger.fail(utils.failMsgWithBadge(result.message, result.cause));
    return;
  }
  if (outputKind === 'markdown') {
    logger.logger.log(`# Auto discover config value`);
    logger.logger.log('');
    logger.logger.log(`Attempted to automatically discover the value for config key: "${key}"`);
    logger.logger.log('');
    if (result.ok) {
      logger.logger.log(`The discovered value is: "${result.data}"`);
      if (result.message) {
        logger.logger.log('');
        logger.logger.log(result.message);
      }
    }
    logger.logger.log('');
  } else {
    if (result.message) {
      logger.logger.log(result.message);
      logger.logger.log('');
    }
    logger.logger.log(`- ${key}: ${result.data}`);
    logger.logger.log('');
    if (utils.isConfigFromFlag()) {
      logger.logger.log('(Unable to persist this value because the config is in read-only mode, meaning it was overridden through env or flag.)');
    } else if (key === 'defaultOrg') {
      const proceed = await prompts.select({
        message: 'Would you like to update the default org in local config to this value?',
        choices: (Array.isArray(result.data) ? result.data : [result.data]).map(slug => ({
          name: 'Yes [' + slug + ']',
          value: slug,
          description: `Use "${slug}" as the default organization`
        })).concat({
          name: 'No',
          value: '',
          description: 'Do not use any of these organizations'
        })
      });
      if (proceed) {
        logger.logger.log(`Setting defaultOrg to "${proceed}"...`);
        const updateResult = utils.updateConfigValue('defaultOrg', proceed);
        if (updateResult.ok) {
          logger.logger.log(`OK. Updated defaultOrg to "${proceed}".\nYou should no longer need to add the org to commands that normally require it.`);
        } else {
          logger.logger.log(utils.failMsgWithBadge(updateResult.message, updateResult.cause));
        }
      } else {
        logger.logger.log('OK. No changes made.');
      }
    } else if (key === 'enforcedOrgs') {
      const proceed = await prompts.select({
        message: 'Would you like to update the enforced orgs in local config to this value?',
        choices: (Array.isArray(result.data) ? result.data : [result.data]).map(slug => ({
          name: 'Yes [' + slug + ']',
          value: slug,
          description: `Enforce the security policy of "${slug}" on this machine`
        })).concat({
          name: 'No',
          value: '',
          description: 'Do not use any of these organizations'
        })
      });
      if (proceed) {
        logger.logger.log(`Setting enforcedOrgs key to "${proceed}"...`);
        const updateResult = utils.updateConfigValue('defaultOrg', proceed);
        if (updateResult.ok) {
          logger.logger.log(`OK. Updated enforcedOrgs to "${proceed}".`);
        } else {
          logger.logger.log(utils.failMsgWithBadge(updateResult.message, updateResult.cause));
        }
      } else {
        logger.logger.log('OK. No changes made.');
      }
    }
  }
}

async function handleConfigAuto({
  key,
  outputKind
}) {
  const result = await discoverConfigValue(key);
  await outputConfigAuto(key, result, outputKind);
}

const CMD_NAME$w = 'auto';
const description$D = 'Automatically discover and set the correct value config item';
const hidden$v = false;
const cmdConfigAuto = {
  description: description$D,
  hidden: hidden$v,
  run: run$P
};
async function run$P(argv, importMeta, {
  parentName
}) {
  const config = {
    commandName: CMD_NAME$w,
    description: description$D,
    hidden: hidden$v,
    flags: {
      ...flags.commonFlags,
      ...flags.outputFlags
    },
    help: (command, config) => `
    Usage
      $ ${command} [options] KEY

    Options
      ${utils.getFlagListOutput(config.flags)}

    Attempt to automatically discover the correct value for a given config KEY.

    Examples
      $ ${command} defaultOrg

    Keys:
${utils.getSupportedConfigEntries().map(({
      0: key,
      1: description
    }) => `     - ${key} -- ${description}`).join('\n')}
  `
  };
  const cli = utils.meowOrExit({
    argv,
    config,
    importMeta,
    parentName
  });
  const {
    json,
    markdown
  } = cli.flags;
  const dryRun = !!cli.flags['dryRun'];
  const [key = ''] = cli.input;
  const outputKind = utils.getOutputKind(json, markdown);
  const wasValidInput = utils.checkCommandInput(outputKind, {
    test: key !== 'test' && utils.isSupportedConfigKey(key),
    message: 'Config key should be the first arg',
    fail: key ? 'invalid config key' : 'missing'
  }, {
    nook: true,
    test: !json || !markdown,
    message: `The \`${constants.FLAG_JSON}\` and \`${constants.FLAG_MARKDOWN}\` flags can not be used at the same time`,
    fail: 'bad'
  });
  if (!wasValidInput) {
    return;
  }
  if (dryRun) {
    logger.logger.log(constants.default.DRY_RUN_BAILING_NOW);
    return;
  }
  await handleConfigAuto({
    key: key,
    outputKind
  });
}

async function outputConfigGet(key, result, outputKind) {
  if (!result.ok) {
    process.exitCode = result.code ?? 1;
  }
  if (outputKind === 'json') {
    logger.logger.log(utils.serializeResultJson(result));
    return;
  }
  if (!result.ok) {
    logger.logger.fail(utils.failMsgWithBadge(result.message, result.cause));
    return;
  }
  const readOnly = utils.isConfigFromFlag();
  if (outputKind === 'markdown') {
    logger.logger.log(`# Config Value`);
    logger.logger.log('');
    logger.logger.log(`Config key '${key}' has value '${result.data}`);
    if (readOnly) {
      logger.logger.log('');
      logger.logger.log('Note: the config is in read-only mode, meaning at least one key was temporarily\n      overridden from an env var or command flag.');
    }
  } else {
    logger.logger.log(`${key}: ${result.data}`);
    if (readOnly) {
      logger.logger.log('');
      logger.logger.log('Note: the config is in read-only mode, meaning at least one key was temporarily overridden from an env var or command flag.');
    }
  }
}

async function handleConfigGet({
  key,
  outputKind
}) {
  const result = utils.getConfigValue(key);
  await outputConfigGet(key, result, outputKind);
}

const config$j = {
  commandName: 'get',
  description: 'Get the value of a local CLI config item',
  hidden: false,
  flags: {
    ...flags.commonFlags,
    ...flags.outputFlags
  },
  help: (command, config) => `
    Usage
      $ ${command} [options] KEY

    Retrieve the value for given KEY at this time. If you have overridden the
    config then the value will come from that override.

    Options
      ${utils.getFlagListOutput(config.flags)}

    KEY is an enum. Valid keys:

${utils.getSupportedConfigEntries().map(({
    0: key,
    1: description
  }) => `     - ${key} -- ${description}`).join('\n')}

    Examples
      $ ${command} defaultOrg
  `
};
const cmdConfigGet = {
  description: config$j.description,
  hidden: config$j.hidden,
  run: run$O
};
async function run$O(argv, importMeta, {
  parentName
}) {
  const cli = utils.meowOrExit({
    argv,
    config: config$j,
    importMeta,
    parentName
  });
  const {
    json,
    markdown
  } = cli.flags;
  const dryRun = !!cli.flags['dryRun'];
  const [key = ''] = cli.input;
  const outputKind = utils.getOutputKind(json, markdown);
  const wasValidInput = utils.checkCommandInput(outputKind, {
    test: key === 'test' || utils.isSupportedConfigKey(key),
    message: 'Config key should be the first arg',
    fail: key ? 'invalid config key' : 'missing'
  }, {
    nook: true,
    test: !json || !markdown,
    message: `The \`${constants.FLAG_JSON}\` and \`${constants.FLAG_MARKDOWN}\` flags can not be used at the same time`,
    fail: 'bad'
  });
  if (!wasValidInput) {
    return;
  }
  if (dryRun) {
    logger.logger.log(constants.default.DRY_RUN_BAILING_NOW);
    return;
  }
  await handleConfigGet({
    key: key,
    outputKind
  });
}

async function outputConfigList({
  full,
  outputKind
}) {
  const readOnly = utils.isConfigFromFlag();
  const supportedConfigKeys = utils.getSupportedConfigKeys();
  if (outputKind === 'json') {
    let failed = false;
    const obj = {};
    for (const key of supportedConfigKeys) {
      const result = utils.getConfigValue(key);
      let value = result.data;
      if (!result.ok) {
        value = `Failed to retrieve: ${result.message}`;
        failed = true;
      } else if (!full && utils.isSensitiveConfigKey(key)) {
        value = '********';
      }
      if (full || value !== undefined) {
        obj[key] = value ?? '<none>';
      }
    }
    if (failed) {
      process.exitCode = 1;
    }
    logger.logger.log(utils.serializeResultJson(failed ? {
      ok: false,
      message: 'At least one config key failed to be fetched...',
      data: JSON.stringify({
        full,
        config: obj,
        readOnly
      })
    } : {
      ok: true,
      data: {
        full,
        config: obj,
        readOnly
      }
    }));
  } else {
    const maxWidth = supportedConfigKeys.reduce((a, b) => Math.max(a, b.length), 0);
    logger.logger.log('# Local CLI Config');
    logger.logger.log('');
    logger.logger.log(`This is the local CLI config (full=${!!full}):`);
    logger.logger.log('');
    for (const key of supportedConfigKeys) {
      const result = utils.getConfigValue(key);
      if (!result.ok) {
        logger.logger.log(`- ${key}: failed to read: ${result.message}`);
      } else {
        let value = result.data;
        if (!full && utils.isSensitiveConfigKey(key)) {
          value = '********';
        }
        if (full || value !== undefined) {
          logger.logger.log(`- ${key}:${' '.repeat(Math.max(0, maxWidth - key.length + 3))} ${Array.isArray(value) ? value.join(', ') || '<none>' : value ?? '<none>'}`);
        }
      }
    }
    if (readOnly) {
      logger.logger.log('');
      logger.logger.log('Note: the config is in read-only mode, meaning at least one key was temporarily\n      overridden from an env var or command flag.');
    }
  }
}

const config$i = {
  commandName: 'list',
  description: 'Show all local CLI config items and their values',
  hidden: false,
  flags: {
    ...flags.commonFlags,
    ...flags.outputFlags,
    full: {
      type: 'boolean',
      default: false,
      description: 'Show full tokens in plaintext (unsafe)'
    }
  },
  help: (command, config) => `
    Usage
      $ ${command} [options]

    Options
      ${utils.getFlagListOutput(config.flags)}

    Examples
      $ ${command}
  `
};
const cmdConfigList = {
  description: config$i.description,
  hidden: config$i.hidden,
  run: run$N
};
async function run$N(argv, importMeta, {
  parentName
}) {
  const cli = utils.meowOrExit({
    argv,
    config: config$i,
    importMeta,
    parentName
  });
  const {
    full,
    json,
    markdown
  } = cli.flags;
  const dryRun = !!cli.flags['dryRun'];
  const outputKind = utils.getOutputKind(json, markdown);
  const wasValidInput = utils.checkCommandInput(outputKind, {
    nook: true,
    test: !json || !markdown,
    message: `The \`${constants.FLAG_JSON}\` and \`${constants.FLAG_MARKDOWN}\` flags can not be used at the same time`,
    fail: 'bad'
  });
  if (!wasValidInput) {
    return;
  }
  if (dryRun) {
    logger.logger.log(constants.default.DRY_RUN_BAILING_NOW);
    return;
  }
  await outputConfigList({
    full: !!full,
    outputKind
  });
}

async function outputConfigSet(result, outputKind) {
  if (!result.ok) {
    process.exitCode = result.code ?? 1;
  }
  if (outputKind === 'json') {
    logger.logger.log(utils.serializeResultJson(result));
    return;
  }
  if (!result.ok) {
    logger.logger.fail(utils.failMsgWithBadge(result.message, result.cause));
    return;
  }
  if (outputKind === 'markdown') {
    logger.logger.log(`# Update config`);
    logger.logger.log('');
    logger.logger.log(result.message);
    if (result.data) {
      logger.logger.log('');
      logger.logger.log(result.data);
    }
  } else {
    logger.logger.log(`OK`);
    logger.logger.log(result.message);
    if (result.data) {
      logger.logger.log('');
      logger.logger.log(result.data);
    }
  }
}

async function handleConfigSet({
  key,
  outputKind,
  value
}) {
  require$$9.debugFn('notice', `Setting config ${key} = ${value}`);
  require$$9.debugDir('inspect', {
    key,
    value,
    outputKind
  });
  const result = utils.updateConfigValue(key, value);
  require$$9.debugFn('notice', `Config update ${result.ok ? 'succeeded' : 'failed'}`);
  require$$9.debugDir('inspect', {
    result
  });
  await outputConfigSet(result, outputKind);
}

const CMD_NAME$v = 'set';
const description$C = 'Update the value of a local CLI config item';
const hidden$u = false;
const cmdConfigSet = {
  description: description$C,
  hidden: hidden$u,
  run: run$M
};
async function run$M(argv, importMeta, {
  parentName
}) {
  const config = {
    commandName: CMD_NAME$v,
    description: description$C,
    hidden: hidden$u,
    flags: {
      ...flags.commonFlags,
      ...flags.outputFlags
    },
    help: (command, config) => `
    Usage
      $ ${command} [options] <KEY> <VALUE>

    Options
      ${utils.getFlagListOutput(config.flags)}

    This is a crude way of updating the local configuration for this CLI tool.

    Note that updating a value here is nothing more than updating a key/value
    store entry. No validation is happening. The server may reject your values
    in some cases. Use at your own risk.

    Note: use \`socket config unset\` to restore to defaults. Setting a key
    to \`undefined\` will not allow default values to be set on it.

    Keys:

${utils.getSupportedConfigEntries().map(({
      0: key,
      1: description
    }) => `     - ${key} -- ${description}`).join('\n')}

    Examples
      $ ${command} apiProxy https://example.com
  `
  };
  const cli = utils.meowOrExit({
    argv,
    config,
    importMeta,
    parentName
  });
  const {
    json,
    markdown
  } = cli.flags;
  const dryRun = !!cli.flags['dryRun'];
  const [key = '', ...rest] = cli.input;
  const value = rest.join(' ');
  const outputKind = utils.getOutputKind(json, markdown);
  const wasValidInput = utils.checkCommandInput(outputKind, {
    test: key === 'test' || utils.isSupportedConfigKey(key),
    message: 'Config key should be the first arg',
    fail: key ? 'invalid config key' : 'missing'
  }, {
    test: !!value,
    // This is a string, empty string is not ok
    message: 'Key value should be the remaining args (use `unset` to unset a value)',
    fail: 'missing'
  }, {
    nook: true,
    test: !json || !markdown,
    message: `The \`${constants.FLAG_JSON}\` and \`${constants.FLAG_MARKDOWN}\` flags can not be used at the same time`,
    fail: 'bad'
  });
  if (!wasValidInput) {
    return;
  }
  if (dryRun) {
    logger.logger.log(constants.default.DRY_RUN_BAILING_NOW);
    return;
  }
  await handleConfigSet({
    key: key,
    outputKind,
    value
  });
}

async function outputConfigUnset(updateResult, outputKind) {
  if (!updateResult.ok) {
    process.exitCode = updateResult.code ?? 1;
  }
  if (outputKind === 'json') {
    logger.logger.log(utils.serializeResultJson(updateResult));
    return;
  }
  if (!updateResult.ok) {
    logger.logger.fail(utils.failMsgWithBadge(updateResult.message, updateResult.cause));
    return;
  }
  if (outputKind === 'markdown') {
    logger.logger.log(`# Update config`);
    logger.logger.log('');
    logger.logger.log(updateResult.message);
    if (updateResult.data) {
      logger.logger.log('');
      logger.logger.log(updateResult.data);
    }
  } else {
    logger.logger.log(`OK`);
    logger.logger.log(updateResult.message);
    if (updateResult.data) {
      logger.logger.log('');
      logger.logger.log(updateResult.data);
    }
  }
}

async function handleConfigUnset({
  key,
  outputKind
}) {
  const updateResult = utils.updateConfigValue(key, undefined);
  await outputConfigUnset(updateResult, outputKind);
}

const CMD_NAME$u = 'unset';
const description$B = 'Clear the value of a local CLI config item';
const hidden$t = false;
const cmdConfigUnset = {
  description: description$B,
  hidden: hidden$t,
  run: run$L
};
async function run$L(argv, importMeta, {
  parentName
}) {
  const config = {
    commandName: CMD_NAME$u,
    description: description$B,
    hidden: hidden$t,
    flags: {
      ...flags.commonFlags,
      ...flags.outputFlags
    },
    help: (command, config) => `
    Usage
      $ ${command} [options] <KEY> <VALUE>

    Options
      ${utils.getFlagListOutput(config.flags)}

    Removes a value from a config key, allowing the default value to be used
    for it instead.

    Keys:

${utils.getSupportedConfigEntries().map(({
      0: key,
      1: description
    }) => `     - ${key} -- ${description}`).join('\n')}

    Examples
      $ ${command} defaultOrg
  `
  };
  const cli = utils.meowOrExit({
    argv,
    config,
    importMeta,
    parentName
  });
  const {
    json,
    markdown
  } = cli.flags;
  const dryRun = !!cli.flags['dryRun'];
  const [key = ''] = cli.input;
  const outputKind = utils.getOutputKind(json, markdown);
  const wasValidInput = utils.checkCommandInput(outputKind, {
    test: key === 'test' || utils.isSupportedConfigKey(key),
    message: 'Config key should be the first arg',
    fail: key ? 'invalid config key' : 'missing'
  }, {
    nook: true,
    test: !json || !markdown,
    message: `The \`${constants.FLAG_JSON}\` and \`${constants.FLAG_MARKDOWN}\` flags can not be used at the same time`,
    fail: 'bad'
  });
  if (!wasValidInput) {
    return;
  }
  if (dryRun) {
    logger.logger.log(constants.default.DRY_RUN_BAILING_NOW);
    return;
  }
  await handleConfigUnset({
    key: key,
    outputKind
  });
}

const description$A = 'Manage Socket CLI configuration';
const cmdConfig = {
  description: description$A,
  hidden: false,
  async run(argv, importMeta, {
    parentName
  }) {
    await utils.meowWithSubcommands({
      argv,
      name: `${parentName} config`,
      importMeta,
      subcommands: {
        auto: cmdConfigAuto,
        get: cmdConfigGet,
        list: cmdConfigList,
        set: cmdConfigSet,
        unset: cmdConfigUnset
      }
    }, {
      description: description$A
    });
  }
};

const GITHUB_ADVISORIES_URL = 'https://github.com/advisories';
function getSocketFixBranchName(ghsaId) {
  return `socket/fix/${ghsaId}`;
}
function getSocketFixBranchPattern(ghsaId) {
  return new RegExp(`^socket/fix/(${ghsaId ?? '.+'})$`);
}
function getSocketFixCommitMessage(ghsaId, details) {
  const summary = details?.summary;
  return `fix: ${ghsaId}${summary ? ` - ${summary}` : ''}`;
}
function getSocketFixPullRequestBody(ghsaIds, ghsaDetails) {
  const vulnCount = ghsaIds.length;
  if (vulnCount === 1) {
    const ghsaId = ghsaIds[0];
    const details = ghsaDetails?.get(ghsaId);
    const body = `[Socket](${constants.default.SOCKET_WEBSITE_URL}) fix for [${ghsaId}](${GITHUB_ADVISORIES_URL}/${ghsaId}).`;
    if (!details) {
      return body;
    }
    const packages = details.vulnerabilities.nodes.map(v => `${v.package.name} (${v.package.ecosystem})`);
    return [body, '', '', `**Vulnerability Summary:** ${details.summary}`, '', `**Severity:** ${details.severity}`, '', `**Affected Packages:** ${arrays.joinAnd(packages)}`].join('\n');
  }
  return [`[Socket](${constants.default.SOCKET_WEBSITE_URL}) fixes for ${vulnCount} GHSAs.`, '', '**Fixed Vulnerabilities:**', ...ghsaIds.map(id => {
    const details = ghsaDetails?.get(id);
    const item = `- [${id}](${GITHUB_ADVISORIES_URL}/${id})`;
    if (details) {
      const packages = details.vulnerabilities.nodes.map(v => `${v.package.name}`);
      return `${item} - ${details.summary} (${arrays.joinAnd(packages)})`;
    }
    return item;
  })].join('\n');
}
function getSocketFixPullRequestTitle(ghsaIds) {
  const vulnCount = ghsaIds.length;
  return vulnCount === 1 ? `Fix for ${ghsaIds[0]}` : `Fixes for ${vulnCount} GHSAs`;
}

async function openSocketFixPr(owner, repo, branch, ghsaIds, options) {
  const {
    baseBranch = 'main',
    ghsaDetails
  } = {
    __proto__: null,
    ...options
  };
  const octokit = utils.getOctokit();
  try {
    const octokitPullsCreateParams = {
      owner,
      repo,
      title: getSocketFixPullRequestTitle(ghsaIds),
      head: branch,
      base: baseBranch,
      body: getSocketFixPullRequestBody(ghsaIds, ghsaDetails)
    };
    require$$9.debugDir('inspect', {
      octokitPullsCreateParams
    });
    return await octokit.pulls.create(octokitPullsCreateParams);
  } catch (e) {
    let message = `Failed to open pull request`;
    const errors = e instanceof vendor.RequestError ? e.response?.data?.['errors'] : undefined;
    if (Array.isArray(errors) && errors.length) {
      const details = errors.map(d => `- ${d.message?.trim() ?? `${d.resource}.${d.field} (${d.code})`}`).join('\n');
      message += `:\n${details}`;
    }
    require$$9.debugFn('error', message);
  }
  return undefined;
}
async function getSocketFixPrs(owner, repo, options) {
  return (await getSocketFixPrsWithContext(owner, repo, options)).map(d => d.match);
}
async function getSocketFixPrsWithContext(owner, repo, options) {
  const {
    author,
    ghsaId,
    states: statesValue = 'all'
  } = {
    __proto__: null,
    ...options
  };
  const branchPattern = getSocketFixBranchPattern(ghsaId);
  const checkAuthor = strings.isNonEmptyString(author);
  const octokitGraphql = utils.getOctokitGraphql();
  const contextualMatches = [];
  const states = (typeof statesValue === 'string' ? statesValue.toLowerCase() === 'all' ? [constants.GQL_PR_STATE_OPEN, constants.GQL_PR_STATE_CLOSED, constants.GQL_PR_STATE_MERGED] : [statesValue] : statesValue).map(s => s.toUpperCase());
  try {
    let hasNextPage = true;
    let cursor = null;
    let pageIndex = 0;
    const gqlCacheKey = `${repo}-pr-graphql-snapshot-${states.join('-').toLowerCase()}`;
    while (hasNextPage) {
      // eslint-disable-next-line no-await-in-loop
      const gqlResp = await utils.cacheFetch(`${gqlCacheKey}-page-${pageIndex}`, () => octokitGraphql(`
              query($owner: String!, $repo: String!, $states: [PullRequestState!], $after: String) {
                repository(owner: $owner, name: $repo) {
                  pullRequests(first: 100, states: $states, after: $after, orderBy: {field: CREATED_AT, direction: DESC}) {
                    pageInfo {
                      hasNextPage
                      endCursor
                    }
                    nodes {
                      author {
                        login
                      }
                      baseRefName
                      headRefName
                      mergeStateStatus
                      number
                      state
                      title
                    }
                  }
                }
              }
              `, {
        owner,
        repo,
        states,
        after: cursor
      }));
      const {
        nodes,
        pageInfo
      } = gqlResp?.repository?.pullRequests ?? {
        nodes: [],
        pageInfo: {
          hasNextPage: false,
          endCursor: null
        }
      };
      for (let i = 0, {
          length
        } = nodes; i < length; i += 1) {
        const node = nodes[i];
        const login = node.author?.login;
        const matchesAuthor = checkAuthor ? login === author : true;
        const matchesBranch = branchPattern.test(node.headRefName);
        if (matchesAuthor && matchesBranch) {
          contextualMatches.push({
            context: {
              apiType: 'graphql',
              cacheKey: `${gqlCacheKey}-page-${pageIndex}`,
              data: gqlResp,
              entry: node,
              index: i,
              parent: nodes
            },
            match: {
              ...node,
              author: login ?? constants.UNKNOWN_VALUE
            }
          });
        }
      }

      // Continue to next page.
      hasNextPage = pageInfo.hasNextPage;
      cursor = pageInfo.endCursor;
      pageIndex += 1;

      // Safety limit to prevent infinite loops.
      if (pageIndex === constants.GQL_PAGE_SENTINEL) {
        require$$9.debugFn('warn', `GraphQL pagination reached safety limit (${constants.GQL_PAGE_SENTINEL} pages) for ${owner}/${repo}`);
        break;
      }

      // Early exit optimization: if we found matches and only looking for specific GHSA,
      // we can stop pagination since we likely found what we need.
      if (contextualMatches.length > 0 && ghsaId) {
        break;
      }
    }
  } catch (e) {
    require$$9.debugFn('error', `GraphQL pagination failed for ${owner}/${repo}`);
    require$$9.debugDir('error', e);
  }
  return contextualMatches;
}

function ciRepoInfo() {
  const {
    GITHUB_REPOSITORY
  } = constants.default.ENV;
  if (!GITHUB_REPOSITORY) {
    require$$9.debugFn('notice', 'miss: GITHUB_REPOSITORY env var');
  }
  const ownerSlashRepo = GITHUB_REPOSITORY;
  const slashIndex = ownerSlashRepo.indexOf('/');
  if (slashIndex === -1) {
    return undefined;
  }
  return {
    owner: ownerSlashRepo.slice(0, slashIndex),
    repo: ownerSlashRepo.slice(slashIndex + 1)
  };
}
/**
 * Get formatted instructions for setting CI environment variables.
 */
function getCiEnvInstructions() {
  return 'To enable automatic pull request creation, run in CI with these environment variables:\n' + '  - CI=1\n' + '  - SOCKET_CLI_GITHUB_TOKEN=<your-github-token>\n' + '  - SOCKET_CLI_GIT_USER_NAME=<git-username>\n' + '  - SOCKET_CLI_GIT_USER_EMAIL=<git-email>';
}

/**
 * Check which required CI environment variables are missing.
 * Returns lists of missing and present variables.
 */
function checkCiEnvVars() {
  const {
    CI,
    SOCKET_CLI_GIT_USER_EMAIL,
    SOCKET_CLI_GIT_USER_NAME,
    SOCKET_CLI_GITHUB_TOKEN
  } = constants.default.ENV;
  const missing = [];
  const present = [];
  if (CI) {
    present.push('CI');
  } else {
    missing.push('CI');
  }
  if (SOCKET_CLI_GIT_USER_EMAIL) {
    present.push('SOCKET_CLI_GIT_USER_EMAIL');
  } else {
    missing.push('SOCKET_CLI_GIT_USER_EMAIL');
  }
  if (SOCKET_CLI_GIT_USER_NAME) {
    present.push('SOCKET_CLI_GIT_USER_NAME');
  } else {
    missing.push('SOCKET_CLI_GIT_USER_NAME');
  }
  if (SOCKET_CLI_GITHUB_TOKEN) {
    present.push('SOCKET_CLI_GITHUB_TOKEN');
  } else {
    missing.push('SOCKET_CLI_GITHUB_TOKEN (or GITHUB_TOKEN)');
  }
  return {
    missing,
    present
  };
}
async function getFixEnv() {
  const baseBranch = await utils.getBaseBranch();
  const gitEmail = constants.default.ENV.SOCKET_CLI_GIT_USER_EMAIL;
  const gitUser = constants.default.ENV.SOCKET_CLI_GIT_USER_NAME;
  const githubToken = constants.default.ENV.SOCKET_CLI_GITHUB_TOKEN;
  const isCi = !!(constants.default.ENV.CI && gitEmail && gitUser && githubToken);
  const envCheck = checkCiEnvVars();

  // Provide clear feedback about missing environment variables.
  if (constants.default.ENV.CI && envCheck.missing.length > 1) {
    // CI is set but other required vars are missing.
    const missingExceptCi = envCheck.missing.filter(v => v !== 'CI');
    if (missingExceptCi.length) {
      logger.logger.warn(`CI mode detected, but pull request creation is disabled due to missing environment variables:\n` + `  Missing: ${arrays.joinAnd(missingExceptCi)}\n` + `  Set these variables to enable automatic pull request creation.`);
    }
  } else if (
  // If not in CI but some CI-related env vars are set.
  !constants.default.ENV.CI && envCheck.present.length &&
  // then log about it when in debug mode.
  require$$9.isDebug('notice')) {
    require$$9.debugFn('notice', `miss: fixEnv.isCi is false, expected ${arrays.joinAnd(envCheck.missing)} to be set`);
  }
  let repoInfo;
  if (isCi) {
    repoInfo = ciRepoInfo();
  }
  if (!repoInfo) {
    if (isCi) {
      require$$9.debugFn('notice', 'falling back to `git remote get-url origin`');
    }
    repoInfo = await utils.getRepoInfo();
  }
  const prs = isCi && repoInfo ? await getSocketFixPrs(repoInfo.owner, repoInfo.repo, {
    author: gitUser,
    states: 'all'
  }) : [];
  return {
    baseBranch,
    gitEmail,
    githubToken,
    gitUser,
    isCi,
    prs,
    repoInfo
  };
}

async function coanaFix(fixConfig) {
  const {
    applyFixes,
    autopilot,
    cwd,
    ghsas,
    glob,
    limit,
    orgSlug,
    outputFile,
    spinner
  } = fixConfig;
  const fixEnv = await getFixEnv();
  require$$9.debugDir('inspect', {
    fixEnv
  });
  spinner?.start();
  const sockSdkCResult = await utils.setupSdk();
  if (!sockSdkCResult.ok) {
    return sockSdkCResult;
  }
  const sockSdk = sockSdkCResult.data;
  const supportedFilesCResult = await fetchSupportedScanFileNames({
    spinner
  });
  if (!supportedFilesCResult.ok) {
    return supportedFilesCResult;
  }
  const supportedFiles = supportedFilesCResult.data;
  const scanFilepaths = await utils.getPackageFilesForScan(['.'], supportedFiles, {
    cwd
  });
  const uploadCResult = await utils.handleApiCall(sockSdk.uploadManifestFiles(orgSlug, scanFilepaths), {
    description: 'upload manifests',
    spinner
  });
  if (!uploadCResult.ok) {
    return uploadCResult;
  }
  const tarHash = uploadCResult.data.tarHash;
  if (!tarHash) {
    spinner?.stop();
    return {
      ok: false,
      message: 'No tar hash returned from Socket API upload-manifest-files endpoint',
      data: uploadCResult.data
    };
  }
  const isAll = !ghsas.length || ghsas.length === 1 && (ghsas[0] === 'all' || ghsas[0] === 'auto');
  const shouldOpenPrs = fixEnv.isCi && fixEnv.repoInfo;
  if (!shouldOpenPrs) {
    // Inform user about local mode when fixes will be applied.
    if (applyFixes && ghsas.length) {
      const envCheck = checkCiEnvVars();
      if (envCheck.present.length) {
        // Some CI vars are set but not all - show what's missing.
        if (envCheck.missing.length) {
          logger.logger.info('Running in local mode - fixes will be applied directly to your working directory.\n' + `Missing environment variables for PR creation: ${arrays.joinAnd(envCheck.missing)}`);
        }
      } else {
        // No CI vars are present - show general local mode message.
        logger.logger.info('Running in local mode - fixes will be applied directly to your working directory.\n' + getCiEnvInstructions());
      }
    }
    const ids = isAll ? ['all'] : ghsas.slice(0, limit);
    if (!ids.length) {
      spinner?.stop();
      return {
        ok: true,
        data: {
          fixed: false
        }
      };
    }
    const fixCResult = await utils.spawnCoanaDlx(['compute-fixes-and-upgrade-purls', cwd, '--manifests-tar-hash', tarHash, '--apply-fixes-to', ...(isAll ? ['all'] : ghsas), ...(fixConfig.rangeStyle ? ['--range-style', fixConfig.rangeStyle] : []), ...(glob ? ['--glob', glob] : []), ...(!applyFixes ? [constants.FLAG_DRY_RUN] : []), ...(outputFile ? ['--output-file', outputFile] : []), ...fixConfig.unknownFlags], fixConfig.orgSlug, {
      cwd,
      spinner,
      stdio: 'inherit'
    });
    spinner?.stop();
    return fixCResult.ok ? {
      ok: true,
      data: {
        fixed: true
      }
    } : fixCResult;
  }

  // Adjust limit based on open Socket Fix PRs.
  let adjustedLimit = limit;
  if (shouldOpenPrs && fixEnv.repoInfo) {
    try {
      const openPrs = await getSocketFixPrs(fixEnv.repoInfo.owner, fixEnv.repoInfo.repo, {
        states: constants.GQL_PR_STATE_OPEN
      });
      const openPrCount = openPrs.length;
      // Reduce limit by number of open PRs to avoid creating too many.
      adjustedLimit = Math.max(0, limit - openPrCount);
      if (openPrCount > 0) {
        require$$9.debugFn('notice', `limit: adjusted from ${limit} to ${adjustedLimit} (${openPrCount} open Socket Fix ${words.pluralize('PR', openPrCount)}`);
      }
    } catch (e) {
      require$$9.debugFn('warn', 'Failed to count open PRs, using original limit');
      require$$9.debugDir('error', e);
    }
  }
  const shouldSpawnCoana = adjustedLimit > 0;
  let ids;
  if (shouldSpawnCoana && isAll) {
    const foundCResult = await utils.spawnCoanaDlx(['compute-fixes-and-upgrade-purls', cwd, '--manifests-tar-hash', tarHash, ...(fixConfig.rangeStyle ? ['--range-style', fixConfig.rangeStyle] : []), ...(glob ? ['--glob', glob] : []), ...fixConfig.unknownFlags], fixConfig.orgSlug, {
      cwd,
      spinner
    });
    if (foundCResult.ok) {
      const foundIds = utils.cmdFlagValueToArray(/(?<=Vulnerabilities found:).*/.exec(foundCResult.data));
      ids = foundIds.slice(0, adjustedLimit);
    }
  } else if (shouldSpawnCoana) {
    ids = ghsas.slice(0, adjustedLimit);
  }
  if (!ids?.length) {
    require$$9.debugFn('notice', 'miss: no GHSA IDs to process');
  }
  if (!fixEnv.repoInfo) {
    require$$9.debugFn('notice', 'miss: no repo info detected');
  }
  if (!ids?.length || !fixEnv.repoInfo) {
    spinner?.stop();
    return {
      ok: true,
      data: {
        fixed: false
      }
    };
  }
  require$$9.debugFn('notice', `fetch: ${ids.length} GHSA details for ${arrays.joinAnd(ids)}`);
  const ghsaDetails = await utils.fetchGhsaDetails(ids);
  const scanBaseNames = new Set(scanFilepaths.map(p => path.basename(p)));
  require$$9.debugFn('notice', `found: ${ghsaDetails.size} GHSA details`);
  let count = 0;
  let overallFixed = false;

  // Process each GHSA ID individually.
  ghsaLoop: for (let i = 0, {
      length
    } = ids; i < length; i += 1) {
    const ghsaId = ids[i];
    require$$9.debugFn('notice', `check: ${ghsaId}`);

    // Apply fix for single GHSA ID.
    // eslint-disable-next-line no-await-in-loop
    const fixCResult = await utils.spawnCoanaDlx(['compute-fixes-and-upgrade-purls', cwd, '--manifests-tar-hash', tarHash, '--apply-fixes-to', ghsaId, ...(fixConfig.rangeStyle ? ['--range-style', fixConfig.rangeStyle] : []), ...(glob ? ['--glob', glob] : []), ...fixConfig.unknownFlags], fixConfig.orgSlug, {
      cwd,
      spinner,
      stdio: 'inherit'
    });
    if (!fixCResult.ok) {
      logger.logger.error(`Update failed for ${ghsaId}: ${utils.getErrorCause(fixCResult)}`);
      continue ghsaLoop;
    }

    // Check for modified files after applying the fix.
    // eslint-disable-next-line no-await-in-loop
    const unstagedCResult = await utils.gitUnstagedModifiedFiles(cwd);
    const modifiedFiles = unstagedCResult.ok ? unstagedCResult.data.filter(relPath => scanBaseNames.has(path.basename(relPath))) : [];
    if (!modifiedFiles.length) {
      require$$9.debugFn('notice', `skip: no changes for ${ghsaId}`);
      continue ghsaLoop;
    }
    overallFixed = true;
    const branch = getSocketFixBranchName(ghsaId);
    try {
      // Check if branch already exists.
      // eslint-disable-next-line no-await-in-loop
      if (await utils.gitRemoteBranchExists(branch, cwd)) {
        require$$9.debugFn('notice', `skip: remote branch "${branch}" exists`);
        continue ghsaLoop;
      }
      require$$9.debugFn('notice', `pr: creating for ${ghsaId}`);
      const details = ghsaDetails.get(ghsaId);
      require$$9.debugFn('notice', `ghsa: ${ghsaId} details ${details ? 'found' : 'missing'}`);
      const pushed =
      // eslint-disable-next-line no-await-in-loop
      (await utils.gitCreateBranch(branch, cwd)) && (
      // eslint-disable-next-line no-await-in-loop
      await utils.gitCheckoutBranch(branch, cwd)) && (
      // eslint-disable-next-line no-await-in-loop
      await utils.gitCommit(getSocketFixCommitMessage(ghsaId, details), modifiedFiles, {
        cwd,
        email: fixEnv.gitEmail,
        user: fixEnv.gitUser
      })) && (
      // eslint-disable-next-line no-await-in-loop
      await utils.gitPushBranch(branch, cwd));
      if (!pushed) {
        logger.logger.warn(`Push failed for ${ghsaId}, skipping PR creation.`);
        // eslint-disable-next-line no-await-in-loop
        await utils.gitResetAndClean(fixEnv.baseBranch, cwd);
        // eslint-disable-next-line no-await-in-loop
        await utils.gitCheckoutBranch(fixEnv.baseBranch, cwd);
        // eslint-disable-next-line no-await-in-loop
        await utils.gitDeleteBranch(branch, cwd);
        continue ghsaLoop;
      }

      // Set up git remote.
      if (!fixEnv.githubToken) {
        logger.logger.error('Cannot create pull request: SOCKET_CLI_GITHUB_TOKEN environment variable is not set.\n' + 'Set SOCKET_CLI_GITHUB_TOKEN or GITHUB_TOKEN to enable PR creation.');
        // eslint-disable-next-line no-await-in-loop
        await utils.gitResetAndClean(fixEnv.baseBranch, cwd);
        // eslint-disable-next-line no-await-in-loop
        await utils.gitCheckoutBranch(fixEnv.baseBranch, cwd);
        // eslint-disable-next-line no-await-in-loop
        await utils.gitDeleteBranch(branch, cwd);
        continue ghsaLoop;
      }
      // eslint-disable-next-line no-await-in-loop
      await utils.setGitRemoteGithubRepoUrl(fixEnv.repoInfo.owner, fixEnv.repoInfo.repo, fixEnv.githubToken, cwd);

      // eslint-disable-next-line no-await-in-loop
      const prResponse = await openSocketFixPr(fixEnv.repoInfo.owner, fixEnv.repoInfo.repo, branch,
      // Single GHSA ID.
      [ghsaId], {
        baseBranch: fixEnv.baseBranch,
        cwd,
        ghsaDetails
      });
      if (prResponse) {
        const {
          data
        } = prResponse;
        const prRef = `PR #${data.number}`;
        logger.logger.success(`Opened ${prRef} for ${ghsaId}.`);
        if (autopilot) {
          logger.logger.indent();
          spinner?.indent();
          // eslint-disable-next-line no-await-in-loop
          const {
            details,
            enabled
          } = await utils.enablePrAutoMerge(data);
          if (enabled) {
            logger.logger.info(`Auto-merge enabled for ${prRef}.`);
          } else {
            const message = `Failed to enable auto-merge for ${prRef}${details ? `:\n${details.map(d => ` - ${d}`).join('\n')}` : '.'}`;
            logger.logger.error(message);
          }
          logger.logger.dedent();
          spinner?.dedent();
        }
      }

      // Reset back to base branch for next iteration.
      // eslint-disable-next-line no-await-in-loop
      await utils.gitResetAndClean(branch, cwd);
      // eslint-disable-next-line no-await-in-loop
      await utils.gitCheckoutBranch(fixEnv.baseBranch, cwd);
    } catch (e) {
      logger.logger.warn(`Unexpected condition: Push failed for ${ghsaId}, skipping PR creation.`);
      require$$9.debugDir('error', e);
      // eslint-disable-next-line no-await-in-loop
      await utils.gitResetAndClean(fixEnv.baseBranch, cwd);
      // eslint-disable-next-line no-await-in-loop
      await utils.gitCheckoutBranch(fixEnv.baseBranch, cwd);
    }
    count += 1;
    require$$9.debugFn('notice', `increment: count ${count}/${Math.min(adjustedLimit, ids.length)}`);
    if (count >= adjustedLimit) {
      break ghsaLoop;
    }
  }
  spinner?.stop();
  return {
    ok: true,
    data: {
      fixed: overallFixed
    }
  };
}

async function outputFixResult(result, outputKind) {
  if (!result.ok) {
    process.exitCode = result.code ?? 1;
  }
  if (outputKind === 'json') {
    logger.logger.log(utils.serializeResultJson(result));
    return;
  }
  if (!result.ok) {
    logger.logger.fail(utils.failMsgWithBadge(result.message, result.cause));
    return;
  }
  logger.logger.log('');
  logger.logger.success('Finished!');
}

const GHSA_FORMAT_REGEXP = /^GHSA-[a-z0-9]{4}-[a-z0-9]{4}-[a-z0-9]{4}$/;
const CVE_FORMAT_REGEXP = /^CVE-\d{4}-\d{4,}$/;
/**
 * Converts mixed CVE/GHSA/PURL IDs to GHSA IDs only.
 * Filters out invalid IDs and logs conversion results.
 */
async function convertIdsToGhsas(ids) {
  require$$9.debugFn('notice', `Converting ${ids.length} IDs to GHSA format`);
  require$$9.debugDir('inspect', {
    ids
  });
  const validGhsas = [];
  const errors = [];
  for (const id of ids) {
    const trimmedId = id.trim();
    if (trimmedId.startsWith('GHSA-')) {
      // Already a GHSA ID, validate format
      if (GHSA_FORMAT_REGEXP.test(trimmedId)) {
        validGhsas.push(trimmedId);
      } else {
        errors.push(`Invalid GHSA format: ${trimmedId}`);
      }
    } else if (trimmedId.startsWith('CVE-')) {
      // Convert CVE to GHSA
      if (!CVE_FORMAT_REGEXP.test(trimmedId)) {
        errors.push(`Invalid CVE format: ${trimmedId}`);
        continue;
      }

      // eslint-disable-next-line no-await-in-loop
      const conversionResult = await utils.convertCveToGhsa(trimmedId);
      if (conversionResult.ok) {
        validGhsas.push(conversionResult.data);
        logger.logger.info(`Converted ${trimmedId} to ${conversionResult.data}`);
      } else {
        errors.push(`${trimmedId}: ${conversionResult.message}`);
      }
    } else if (trimmedId.startsWith('pkg:')) {
      // Convert PURL to GHSAs
      // eslint-disable-next-line no-await-in-loop
      const conversionResult = await utils.convertPurlToGhsas(trimmedId);
      if (conversionResult.ok && conversionResult.data.length) {
        validGhsas.push(...conversionResult.data);
        logger.logger.info(`Converted ${trimmedId} to ${conversionResult.data.length} GHSA(s): ${arrays.joinAnd(conversionResult.data)}`);
      } else {
        errors.push(`${trimmedId}: ${conversionResult.message || 'No GHSAs found'}`);
      }
    } else {
      // Neither CVE, GHSA, nor PURL, skip
      errors.push(`Unsupported ID format (expected CVE, GHSA, or PURL): ${trimmedId}`);
    }
  }
  if (errors.length) {
    logger.logger.warn(`Skipped ${errors.length} invalid IDs:\n${errors.map(e => `  - ${e}`).join('\n')}`);
    require$$9.debugDir('inspect', {
      errors
    });
  }
  require$$9.debugFn('notice', `Converted to ${validGhsas.length} valid GHSA IDs`);
  require$$9.debugDir('inspect', {
    validGhsas
  });
  return validGhsas;
}
async function handleFix({
  applyFixes,
  autopilot,
  cwd,
  ghsas,
  glob,
  limit,
  minSatisfying,
  orgSlug,
  outputFile,
  outputKind,
  prCheck,
  rangeStyle,
  spinner,
  unknownFlags
}) {
  require$$9.debugFn('notice', `Starting fix command for ${orgSlug}`);
  require$$9.debugDir('inspect', {
    autopilot,
    cwd,
    ghsas,
    glob,
    limit,
    minSatisfying,
    applyFixes,
    outputFile,
    outputKind,
    prCheck,
    rangeStyle,
    unknownFlags
  });
  await outputFixResult(await coanaFix({
    autopilot,
    applyFixes,
    cwd,
    // Convert mixed CVE/GHSA/PURL inputs to GHSA IDs only
    ghsas: await convertIdsToGhsas(ghsas),
    glob,
    limit,
    orgSlug,
    rangeStyle,
    spinner,
    unknownFlags,
    outputFile
  }), outputKind);
}

const CMD_NAME$t = 'fix';
const DEFAULT_LIMIT = 10;
const description$z = 'Fix CVEs in dependencies';
const hidden$s = false;
const cmdFix = {
  description: description$z,
  hidden: hidden$s,
  run: run$K
};
const generalFlags$2 = {
  autopilot: {
    type: 'boolean',
    default: false,
    description: `Enable auto-merge for pull requests that Socket opens.\nSee ${vendor.terminalLinkExports('GitHub documentation', 'https://docs.github.com/en/repositories/configuring-branches-and-merges-in-your-repository/configuring-pull-request-merges/managing-auto-merge-for-pull-requests-in-your-repository')} for managing auto-merge for pull requests in your repository.`
  },
  applyFixes: {
    aliases: ['onlyCompute'],
    type: 'boolean',
    default: true,
    description: 'Compute fixes only, do not apply them. Logs what upgrades would be applied. If combined with --output-file, the output file will contain the upgrades that would be applied.',
    // Hidden to allow custom documenting of the negated `--no-apply-fixes` variant.
    hidden: true
  },
  id: {
    type: 'string',
    default: [],
    description: `Provide a list of vulnerability identifiers to compute fixes for:
    - ${vendor.terminalLinkExports('GHSA IDs', 'https://docs.github.com/en/code-security/security-advisories/working-with-global-security-advisories-from-the-github-advisory-database/about-the-github-advisory-database#about-ghsa-ids')} (e.g., GHSA-xxxx-xxxx-xxxx)
    - ${vendor.terminalLinkExports('CVE IDs', 'https://cve.mitre.org/cve/identifiers/')} (e.g., CVE-${new Date().getFullYear()}-1234) - automatically converted to GHSA
    - ${vendor.terminalLinkExports('PURLs', 'https://github.com/package-url/purl-spec')} (e.g., pkg:npm/package@1.0.0) - automatically converted to GHSA
    Can be provided as comma separated values or as multiple flags`,
    isMultiple: true
  },
  limit: {
    type: 'number',
    default: DEFAULT_LIMIT,
    description: `The number of fixes to attempt at a time (default ${DEFAULT_LIMIT})`
  },
  rangeStyle: {
    type: 'string',
    default: 'preserve',
    description: `
Define how dependency version ranges are updated in package.json (default 'preserve').
Available styles:
  * pin - Use the exact version (e.g. 1.2.3)
  * preserve - Retain the existing version range style as-is
      `.trim()
  },
  outputFile: {
    type: 'string',
    default: '',
    description: 'Path to store upgrades as a JSON file at this path.'
  }
};
const hiddenFlags = {
  autoMerge: {
    ...generalFlags$2['autopilot'],
    hidden: true
  },
  ghsa: {
    ...generalFlags$2['id'],
    hidden: true
  },
  glob: {
    type: 'string',
    default: '',
    description: 'Glob pattern to filter workspaces by',
    hidden: true
  },
  maxSatisfying: {
    type: 'boolean',
    default: true,
    description: 'Use the maximum satisfying version for dependency updates',
    hidden: true
  },
  minSatisfying: {
    type: 'boolean',
    default: false,
    description: 'Constrain dependency updates to the minimum satisfying version',
    hidden: true
  },
  prCheck: {
    type: 'boolean',
    default: true,
    description: 'Check for an existing PR before attempting a fix',
    hidden: true
  },
  purl: {
    type: 'string',
    default: [],
    description: `Provide a list of ${vendor.terminalLinkExports('PURLs', 'https://github.com/package-url/purl-spec?tab=readme-ov-file#purl')} to compute fixes for, as either a comma separated value or as\nmultiple flags`,
    isMultiple: true,
    shortFlag: 'p',
    hidden: true
  },
  test: {
    type: 'boolean',
    default: false,
    description: 'Verify the fix by running unit tests',
    hidden: true
  },
  testScript: {
    type: 'string',
    default: 'test',
    description: "The test script to run for fix attempts (default 'test')",
    hidden: true
  }
};
async function run$K(argv, importMeta, {
  parentName
}) {
  const config = {
    commandName: CMD_NAME$t,
    description: description$z,
    hidden: hidden$s,
    flags: {
      ...flags.commonFlags,
      ...flags.outputFlags,
      ...generalFlags$2,
      ...hiddenFlags
    },
    help: (command, config) => `
    Usage
      $ ${command} [options] [CWD=.]

    API Token Requirements
      ${utils.getFlagApiRequirementsOutput(`${parentName}:${CMD_NAME$t}`)}

    Options
      ${utils.getFlagListOutput({
      ...config.flags,
      // Explicitly document the negated --no-apply-fixes variant.
      noApplyFixes: {
        ...config.flags['applyFixes'],
        hidden: false
      }
    })}

    Environment Variables (for CI/PR mode)
      CI                          Set to enable CI mode
      SOCKET_CLI_GITHUB_TOKEN     GitHub token for PR creation (or GITHUB_TOKEN)
      SOCKET_CLI_GIT_USER_NAME    Git username for commits
      SOCKET_CLI_GIT_USER_EMAIL   Git email for commits

    Examples
      $ ${command}
      $ ${command} ${constants.FLAG_ID} CVE-2021-23337
      $ ${command} ./path/to/project --range-style pin
    `
  };
  const cli = utils.meowOrExit({
    argv,
    config,
    parentName,
    importMeta
  }, {
    allowUnknownFlags: false
  });
  const {
    applyFixes,
    autopilot,
    glob,
    json,
    limit,
    markdown,
    maxSatisfying,
    outputFile,
    prCheck,
    rangeStyle,
    // We patched in this feature with `npx custompatch meow` at
    // socket-cli/patches/meow#13.2.0.patch.
    unknownFlags = []
  } = cli.flags;
  const dryRun = !!cli.flags['dryRun'];
  const minSatisfying = cli.flags['minSatisfying'] || !maxSatisfying;
  const outputKind = utils.getOutputKind(json, markdown);
  const wasValidInput = utils.checkCommandInput(outputKind, {
    test: utils.RangeStyles.includes(rangeStyle),
    message: `Expecting range style of ${arrays.joinOr(utils.RangeStyles)}`,
    fail: 'invalid'
  }, {
    nook: true,
    test: !json || !markdown,
    message: 'The json and markdown flags cannot be both set, pick one',
    fail: 'omit one'
  });
  if (!wasValidInput) {
    return;
  }
  if (dryRun) {
    logger.logger.log(constants.default.DRY_RUN_NOT_SAVING);
    return;
  }
  const orgSlugCResult = await utils.getDefaultOrgSlug();
  if (!orgSlugCResult.ok) {
    process.exitCode = orgSlugCResult.code ?? 1;
    logger.logger.fail(`${constants.ERROR_UNABLE_RESOLVE_ORG}.\nEnsure a Socket API token is specified for the organization using the SOCKET_CLI_API_TOKEN environment variable.`);
    return;
  }
  const orgSlug = orgSlugCResult.data;
  let [cwd = '.'] = cli.input;
  // Note: path.resolve vs .join:
  // If given path is absolute then cwd should not affect it.
  cwd = path.resolve(process.cwd(), cwd);
  const {
    spinner
  } = constants.default;
  const ghsas = arrays.arrayUnique([...utils.cmdFlagValueToArray(cli.flags['id']), ...utils.cmdFlagValueToArray(cli.flags['ghsa']), ...utils.cmdFlagValueToArray(cli.flags['purl'])]);
  await handleFix({
    autopilot,
    applyFixes,
    cwd,
    ghsas,
    glob,
    limit,
    minSatisfying,
    prCheck,
    orgSlug,
    outputKind,
    rangeStyle,
    spinner,
    unknownFlags,
    outputFile
  });
}

async function outputInstallCompletion(result) {
  if (!result.ok) {
    process.exitCode = result.code ?? 1;
    logger.logger.fail(utils.failMsgWithBadge(result.message, result.cause));
    return;
  }
  logger.logger.log('');
  logger.logger.log(`Installation of tab completion for "${result.data.targetName}" finished!`);
  logger.logger.log('');
  result.data.actions.forEach(action => {
    logger.logger.log(`  - ${action}`);
  });
  logger.logger.log('');
  logger.logger.log('Socket tab completion works automatically in new terminals.');
  logger.logger.log('');
  logger.logger.log('Due to a bash limitation, tab completion cannot be enabled in the');
  logger.logger.log('current shell (bash instance) through NodeJS. You must either:');
  logger.logger.log('');
  logger.logger.log('1. Reload your .bashrc script (best):');
  logger.logger.log('');
  logger.logger.log(`   source ~/.bashrc`);
  logger.logger.log('');
  logger.logger.log('2. Run these commands to load the completion script:');
  logger.logger.log('');
  logger.logger.log(`   source ${result.data.targetPath}`);
  logger.logger.log(`   ${result.data.completionCommand}`);
  logger.logger.log('');
  logger.logger.log('3. Or restart bash somehow (restart terminal or run `bash`)');
  logger.logger.log('');
}

async function setupTabCompletion(targetName) {
  const result = utils.getBashrcDetails(targetName);
  if (!result.ok) {
    return result;
  }
  const {
    completionCommand,
    sourcingCommand,
    targetPath,
    toAddToBashrc
  } = result.data;

  // Target dir is something like ~/.local/share/socket/settings/completion (linux)
  const targetDir = path.dirname(targetPath);
  require$$9.debugFn('notice', 'target: path + dir', targetPath, targetDir);
  if (!fs$1.existsSync(targetDir)) {
    require$$9.debugFn('notice', 'create: target dir');
    fs$1.mkdirSync(targetDir, {
      recursive: true
    });
  }
  updateInstalledTabCompletionScript(targetPath);
  let bashrcUpdated = false;

  // Add to ~/.bashrc if not already there
  const bashrcPath = constants.default.homePath ? path.join(constants.default.homePath, '.bashrc') : '';
  const foundBashrc = Boolean(bashrcPath && fs$1.existsSync(bashrcPath));
  if (foundBashrc) {
    const content = fs$1.readFileSync(bashrcPath, 'utf8');
    if (!content.includes(sourcingCommand)) {
      fs$1.appendFileSync(bashrcPath, toAddToBashrc);
      bashrcUpdated = true;
    }
  }
  return {
    ok: true,
    data: {
      actions: [`Installed the tab completion script in ${targetPath}`, bashrcUpdated ? 'Added tab completion loader to ~/.bashrc' : foundBashrc ? 'Tab completion already found in ~/.bashrc' : 'No ~/.bashrc found so tab completion was not completely installed'],
      bashrcPath,
      bashrcUpdated,
      completionCommand,
      foundBashrc,
      sourcingCommand,
      targetName,
      targetPath
    }
  };
}
function getTabCompletionScriptRaw() {
  const sourceDir = path.dirname(require$$0.fileURLToPath((typeof document === 'undefined' ? require$$0.pathToFileURL(__filename).href : (_documentCurrentScript && _documentCurrentScript.tagName.toUpperCase() === 'SCRIPT' && _documentCurrentScript.src || new URL('cli.js', document.baseURI).href))));
  const sourcePath = path.join(sourceDir, 'socket-completion.bash');
  if (!fs$1.existsSync(sourcePath)) {
    return {
      ok: false,
      message: 'Source not found.',
      cause: `Unable to find the source tab completion bash script that Socket should ship. Expected to find it in \`${sourcePath}\` but it was not there.`
    };
  }
  return {
    ok: true,
    data: fs$1.readFileSync(sourcePath, 'utf8')
  };
}
function updateInstalledTabCompletionScript(targetPath) {
  const content = getTabCompletionScriptRaw();
  if (!content.ok) {
    return content;
  }

  // When installing set the current package.json version.
  // Later, we can call _socket_completion_version to get the installed version.
  fs$1.writeFileSync(targetPath, content.data.replaceAll('%SOCKET_VERSION_TOKEN%', constants.default.ENV.INLINED_SOCKET_CLI_VERSION_HASH), 'utf8');
  return {
    ok: true,
    data: undefined
  };
}

async function handleInstallCompletion(targetName) {
  const result = await setupTabCompletion(targetName);
  await outputInstallCompletion(result);
}

const config$h = {
  commandName: 'completion',
  description: 'Install bash completion for Socket CLI',
  hidden: false,
  flags: {
    ...flags.commonFlags
  },
  help: (command, config) => `
    Usage
      $ ${command} [options] [NAME=socket]

    Installs bash completion for the Socket CLI. This will:
    1. Source the completion script in your current shell
    2. Add the source command to your ~/.bashrc if it's not already there

    This command will only setup tab completion, nothing else.

    Afterwards you should be able to type \`socket \` and then press tab to
    have bash auto-complete/suggest the sub/command or flags.

    Currently only supports bash.

    The optional name argument allows you to enable tab completion on a command
    name other than "socket". Mostly for debugging but also useful if you use a
    different alias for socket on your system.

    Options
      ${utils.getFlagListOutput(config.flags)}

    Examples

      $ ${command}
      $ ${command} sd
      $ ${command} ./sd
  `
};
const cmdInstallCompletion = {
  description: config$h.description,
  hidden: config$h.hidden,
  run: run$J
};
async function run$J(argv, importMeta, {
  parentName
}) {
  const cli = utils.meowOrExit({
    argv,
    config: config$h,
    parentName,
    importMeta
  });
  const dryRun = !!cli.flags['dryRun'];
  if (dryRun) {
    logger.logger.log(constants.default.DRY_RUN_BAILING_NOW);
    return;
  }
  const targetName = cli.input[0] || 'socket';
  await handleInstallCompletion(String(targetName));
}

const description$y = 'Install Socket CLI tab completion';
const cmdInstall = {
  description: description$y,
  hidden: false,
  async run(argv, importMeta, {
    parentName
  }) {
    await utils.meowWithSubcommands({
      argv,
      name: `${parentName} install`,
      importMeta,
      subcommands: {
        completion: cmdInstallCompletion
      }
    }, {
      description: description$y
    });
  }
};

async function outputCmdJson(cwd) {
  logger.logger.info('Target cwd:', constants.default.ENV.VITEST ? constants.REDACTED : utils.tildify(cwd));
  const sockJsonPath = path.join(cwd, constants.SOCKET_JSON);
  const tildeSockJsonPath = constants.default.ENV.VITEST ? constants.REDACTED : utils.tildify(sockJsonPath);
  if (!fs$1.existsSync(sockJsonPath)) {
    logger.logger.fail(`Not found: ${tildeSockJsonPath}`);
    process.exitCode = 1;
    return;
  }
  if (!fs$2.safeStatsSync(sockJsonPath)?.isFile()) {
    logger.logger.fail(`This is not a regular file (maybe a directory?): ${tildeSockJsonPath}`);
    process.exitCode = 1;
    return;
  }
  logger.logger.success(`This is the contents of ${tildeSockJsonPath}:`);
  logger.logger.error('');
  const data = fs$2.safeReadFileSync(sockJsonPath);
  logger.logger.log(data);
}

async function handleCmdJson(cwd) {
  await outputCmdJson(cwd);
}

const config$g = {
  commandName: 'json',
  description: `Display the \`${constants.SOCKET_JSON}\` that would be applied for target folder`,
  hidden: true,
  flags: {
    ...flags.commonFlags
  },
  help: command => `
    Usage
      $ ${command} [options] [CWD=.]

    Display the \`${constants.SOCKET_JSON}\` file that would apply when running relevant commands
    in the target directory.

    Examples
      $ ${command}
  `
};
const cmdJson = {
  description: config$g.description,
  hidden: config$g.hidden,
  run: run$I
};
async function run$I(argv, importMeta, {
  parentName
}) {
  const cli = utils.meowOrExit({
    argv,
    config: config$g,
    parentName,
    importMeta
  });
  let [cwd = '.'] = cli.input;
  // Note: path.resolve vs .join:
  // If given path is absolute then cwd should not affect it.
  cwd = path.resolve(process.cwd(), cwd);
  await handleCmdJson(cwd);
}

function applyLogin(apiToken, enforcedOrgs, apiBaseUrl, apiProxy) {
  utils.updateConfigValue(constants.CONFIG_KEY_ENFORCED_ORGS, enforcedOrgs);
  utils.updateConfigValue(constants.CONFIG_KEY_API_TOKEN, apiToken);
  utils.updateConfigValue(constants.CONFIG_KEY_API_BASE_URL, apiBaseUrl);
  utils.updateConfigValue(constants.CONFIG_KEY_API_PROXY, apiProxy);
}

async function attemptLogin(apiBaseUrl, apiProxy) {
  apiBaseUrl ??= utils.getConfigValueOrUndef(constants.CONFIG_KEY_API_BASE_URL) ?? undefined;
  apiProxy ??= utils.getConfigValueOrUndef(constants.CONFIG_KEY_API_PROXY) ?? undefined;
  const apiTokenInput = await prompts.password({
    message: `Enter your ${utils.socketDocsLink('/docs/api-keys', 'Socket.dev API token')} (leave blank to use a limited public token)`
  });
  if (apiTokenInput === undefined) {
    logger.logger.fail('Canceled by user');
    return {
      ok: false,
      message: 'Canceled',
      cause: 'Canceled by user'
    };
  }
  const apiToken = apiTokenInput || constants.default.SOCKET_PUBLIC_API_TOKEN;
  const sockSdkCResult = await utils.setupSdk({
    apiBaseUrl,
    apiProxy,
    apiToken
  });
  if (!sockSdkCResult.ok) {
    process.exitCode = 1;
    logger.logger.fail(utils.failMsgWithBadge(sockSdkCResult.message, sockSdkCResult.cause));
    return;
  }
  const sockSdk = sockSdkCResult.data;
  const orgsCResult = await utils.fetchOrganization({
    description: 'token verification',
    sdk: sockSdk
  });
  if (!orgsCResult.ok) {
    process.exitCode = 1;
    logger.logger.fail(utils.failMsgWithBadge(orgsCResult.message, orgsCResult.cause));
    return;
  }
  const {
    organizations
  } = orgsCResult.data;
  const orgSlugs = utils.getOrgSlugs(organizations);
  logger.logger.success(`API token verified: ${arrays.joinAnd(orgSlugs)}`);
  const enterpriseOrgs = utils.getEnterpriseOrgs(organizations);
  const enforcedChoices = enterpriseOrgs.map(org => ({
    name: org.name ?? 'undefined',
    value: org.id
  }));
  let enforcedOrgs = [];
  if (enforcedChoices.length > 1) {
    const id = await prompts.select({
      message: "Which organization's policies should Socket enforce system-wide?",
      choices: [...enforcedChoices, {
        name: 'None',
        value: '',
        description: 'Pick "None" if this is a personal device'
      }]
    });
    if (id === undefined) {
      logger.logger.fail('Canceled by user');
      return {
        ok: false,
        message: 'Canceled',
        cause: 'Canceled by user'
      };
    }
    if (id) {
      enforcedOrgs = [id];
    }
  } else if (enforcedChoices.length) {
    const shouldEnforce = await prompts.confirm({
      message: `Should Socket enforce ${enforcedChoices[0]?.name}'s security policies system-wide?`,
      default: true
    });
    if (shouldEnforce === undefined) {
      logger.logger.fail('Canceled by user');
      return {
        ok: false,
        message: 'Canceled',
        cause: 'Canceled by user'
      };
    }
    if (shouldEnforce) {
      const existing = enforcedChoices[0];
      if (existing) {
        enforcedOrgs = [existing.value];
      }
    }
  }
  const wantToComplete = await prompts.select({
    message: 'Would you like to install bash tab completion?',
    choices: [{
      name: 'Yes',
      value: true,
      description: 'Sets up tab completion for "socket" in your bash env. If you\'re unsure, this is probably what you want.'
    }, {
      name: 'No',
      value: false,
      description: 'Will skip tab completion setup. Does not change how Socket works.'
    }]
  });
  if (wantToComplete === undefined) {
    logger.logger.fail('Canceled by user');
    return {
      ok: false,
      message: 'Canceled',
      cause: 'Canceled by user'
    };
  }
  if (wantToComplete) {
    logger.logger.log('');
    logger.logger.log('Setting up tab completion...');
    const setupCResult = await setupTabCompletion('socket');
    if (setupCResult.ok) {
      logger.logger.success('Tab completion will be enabled after restarting your terminal');
    } else {
      logger.logger.fail('Failed to install tab completion script. Try `socket install completion` later.');
    }
  }
  utils.updateConfigValue(constants.CONFIG_KEY_DEFAULT_ORG, orgSlugs[0]);
  const previousPersistedToken = utils.getConfigValueOrUndef(constants.CONFIG_KEY_API_TOKEN);
  try {
    applyLogin(apiToken, enforcedOrgs, apiBaseUrl, apiProxy);
    logger.logger.success(`API credentials ${previousPersistedToken === apiToken ? 'refreshed' : previousPersistedToken ? 'updated' : 'set'}`);
    if (utils.isConfigFromFlag()) {
      logger.logger.log('');
      logger.logger.warn('Note: config is in read-only mode, at least one key was overridden through flag/env, so the login was not persisted!');
    }
  } catch {
    process.exitCode = 1;
    logger.logger.fail(`API login failed`);
  }
}

const CMD_NAME$s = 'login';
const description$x = 'Setup Socket CLI with an API token and defaults';
const hidden$r = false;
const cmdLogin = {
  description: description$x,
  hidden: hidden$r,
  run: run$H
};
async function run$H(argv, importMeta, {
  parentName
}) {
  const config = {
    commandName: CMD_NAME$s,
    description: description$x,
    hidden: hidden$r,
    flags: {
      ...flags.commonFlags,
      apiBaseUrl: {
        type: 'string',
        default: '',
        description: 'API server to connect to for login'
      },
      apiProxy: {
        type: 'string',
        default: '',
        description: 'Proxy to use when making connection to API server'
      }
    },
    help: (command, config) => `
    Usage
      $ ${command} [options]

    API Token Requirements
      ${utils.getFlagApiRequirementsOutput(`${parentName}:${CMD_NAME$s}`)}

    Logs into the Socket API by prompting for an API token

    Options
      ${utils.getFlagListOutput(config.flags)}

    Examples
      $ ${command}
      $ ${command} --api-proxy=http://localhost:1234
  `
  };
  const cli = utils.meowOrExit({
    argv,
    config,
    parentName,
    importMeta
  });
  const dryRun = !!cli.flags['dryRun'];
  if (dryRun) {
    logger.logger.log(constants.default.DRY_RUN_BAILING_NOW);
    return;
  }
  if (!vendor.isInteractiveExports()) {
    throw new utils.InputError('Cannot prompt for credentials in a non-interactive shell. Use SOCKET_CLI_API_TOKEN environment variable instead');
  }
  const {
    apiBaseUrl,
    apiProxy
  } = cli.flags;
  await attemptLogin(apiBaseUrl, apiProxy);
}

function applyLogout() {
  utils.updateConfigValue(constants.CONFIG_KEY_API_TOKEN, null);
  utils.updateConfigValue(constants.CONFIG_KEY_API_BASE_URL, null);
  utils.updateConfigValue(constants.CONFIG_KEY_API_PROXY, null);
  utils.updateConfigValue(constants.CONFIG_KEY_ENFORCED_ORGS, null);
}

function attemptLogout() {
  try {
    applyLogout();
    logger.logger.success('Successfully logged out');
    if (utils.isConfigFromFlag()) {
      logger.logger.log('');
      logger.logger.warn('Note: config is in read-only mode, at least one key was overridden through flag/env, so the logout was not persisted!');
    }
  } catch {
    logger.logger.fail('Failed to complete logout steps');
  }
}

const config$f = {
  commandName: 'logout',
  description: 'Socket API logout',
  hidden: false,
  flags: {
    ...flags.commonFlags
  },
  help: (command, _config) => `
    Usage
      $ ${command} [options]

    Logs out of the Socket API and clears all Socket credentials from disk

    Examples
      $ ${command}
  `
};
const cmdLogout = {
  description: config$f.description,
  hidden: config$f.hidden,
  run: run$G
};
async function run$G(argv, importMeta, {
  parentName
}) {
  const cli = utils.meowOrExit({
    argv,
    config: config$f,
    importMeta,
    parentName
  });
  const dryRun = !!cli.flags['dryRun'];
  if (dryRun) {
    logger.logger.log(constants.default.DRY_RUN_BAILING_NOW);
    return;
  }
  attemptLogout();
}

const {
  PACKAGE_LOCK_JSON,
  PNPM_LOCK_YAML,
  YARN_LOCK
} = constants.default;
const nodejsPlatformTypes = new Set(['javascript', 'js', 'nodejs', constants.NPM, constants.PNPM, 'ts', 'tsx', 'typescript']);
function argvObjectToArray(argvObj) {
  if (argvObj['help']) {
    return [constants.FLAG_HELP];
  }
  const result = [];
  for (const {
    0: key,
    1: value
  } of Object.entries(argvObj)) {
    if (key === '_' || key === '--') {
      continue;
    }
    if (key === 'babel' || key === 'install-deps' || key === 'validate') {
      // cdxgen documents no-babel, no-install-deps, and no-validate flags so
      // use them when relevant.
      result.push(`--${value ? key : `no-${key}`}`);
    } else if (value === true) {
      result.push(`--${key}`);
    } else if (typeof value === 'string') {
      result.push(`--${key}`, String(value));
    } else if (Array.isArray(value)) {
      result.push(`--${key}`, ...value.map(String));
    }
  }
  const pathArgs = argvObj['_'];
  if (Array.isArray(pathArgs)) {
    result.push(...pathArgs);
  }
  const argsAfterDoubleHyphen = argvObj['--'];
  if (Array.isArray(argsAfterDoubleHyphen)) {
    result.push('--', ...argsAfterDoubleHyphen);
  }
  return result;
}
async function runCdxgen(argvObj) {
  const argvMutable = {
    __proto__: null,
    ...argvObj
  };
  const shadowOpts = {
    ipc: {
      [constants.default.SOCKET_CLI_SHADOW_ACCEPT_RISKS]: true,
      [constants.default.SOCKET_CLI_SHADOW_API_TOKEN]: constants.default.SOCKET_PUBLIC_API_TOKEN,
      [constants.default.SOCKET_CLI_SHADOW_SILENT]: true
    },
    stdio: 'inherit'
  };

  // Detect package manager based on lockfiles.
  const pnpmLockPath = await utils.findUp(PNPM_LOCK_YAML, {
    onlyFiles: true
  });
  const npmLockPath = pnpmLockPath ? undefined : await utils.findUp(PACKAGE_LOCK_JSON, {
    onlyFiles: true
  });
  const yarnLockPath = pnpmLockPath || npmLockPath ? undefined : await utils.findUp(YARN_LOCK, {
    onlyFiles: true
  });
  const agent = pnpmLockPath ? constants.PNPM : yarnLockPath && utils.isYarnBerry() ? constants.YARN : constants.NPM;
  let cleanupPackageLock = false;
  if (yarnLockPath && argvMutable['type'] !== constants.YARN && nodejsPlatformTypes.has(argvMutable['type'])) {
    if (npmLockPath) {
      argvMutable['type'] = constants.NPM;
    } else {
      // Use synp to create a package-lock.json from the yarn.lock,
      // based on the node_modules folder, for a more accurate SBOM.
      try {
        const synpResult = await utils.spawnSynpDlx(['--source-file', `./${YARN_LOCK}`], {
          ...shadowOpts,
          agent
        });
        await synpResult.spawnPromise;
        argvMutable['type'] = constants.NPM;
        cleanupPackageLock = true;
      } catch {}
    }
  }

  // Use appropriate package manager for cdxgen.
  const shadowResult = await utils.spawnCdxgenDlx(argvObjectToArray(argvMutable), {
    ...shadowOpts,
    agent
  });
  shadowResult.spawnPromise.process.on('exit', () => {
    if (cleanupPackageLock) {
      try {
        // TODO: Consider using trash instead of rmSync for safer deletion.
        // This removes the temporary package-lock.json we created for cdxgen.
        fs$1.rmSync(`./${PACKAGE_LOCK_JSON}`);
      } catch {}
    }
    const outputPath = argvMutable['output'];
    if (outputPath) {
      const fullOutputPath = path.join(process.cwd(), outputPath);
      if (fs$1.existsSync(fullOutputPath)) {
        logger.logger.log(vendor.yoctocolorsCjsExports.cyanBright(`${outputPath} created!`));
      }
    }
  });
  return shadowResult;
}

// TODO: Convert yargs to meow.
const toLower = arg => arg.toLowerCase();
const arrayToLower = arg => arg.map(toLower);

// npx @cyclonedx/cdxgen@11.2.7 --help
//
// Options:
//   -o, --output                 Output file. Default bom.json                                       [default: "bom.json"]
//   -t, --type                   Project type. Please refer to https://cyclonedx.github.io/cdxgen/#/PROJECT_TYPES for supp
//                                orted languages/platforms.                                                        [array]
//       --exclude-type           Project types to exclude. Please refer to https://cyclonedx.github.io/cdxgen/#/PROJECT_TY
//                                PES for supported languages/platforms.
//   -r, --recurse                Recurse mode suitable for mono-repos. Defaults to true. Pass --no-recurse to disable.
//                                                                                                [boolean] [default: true]
//   -p, --print                  Print the SBOM as a table with tree.                                            [boolean]
//   -c, --resolve-class          Resolve class names for packages. jars only for now.                            [boolean]
//       --deep                   Perform deep searches for components. Useful while scanning C/C++ apps, live OS and oci i
//                                mages.                                                                          [boolean]
//       --server-url             Dependency track url. Eg: https://deptrack.cyclonedx.io
//       --skip-dt-tls-check      Skip TLS certificate check when calling Dependency-Track.      [boolean] [default: false]
//       --api-key                Dependency track api key
//       --project-group          Dependency track project group
//       --project-name           Dependency track project name. Default use the directory name
//       --project-version        Dependency track project version                                   [string] [default: ""]
//       --project-id             Dependency track project id. Either provide the id or the project name and version togeth
//                                er                                                                               [string]
//       --parent-project-id      Dependency track parent project id                                               [string]
//       --required-only          Include only the packages with required scope on the SBOM. Would set compositions.aggrega
//                                te to incomplete unless --no-auto-compositions is passed.                       [boolean]
//       --fail-on-error          Fail if any dependency extractor fails.                                         [boolean]
//       --no-babel               Do not use babel to perform usage analysis for JavaScript/TypeScript projects.  [boolean]
//       --generate-key-and-sign  Generate an RSA public/private key pair and then sign the generated SBOM using JSON Web S
//                                ignatures.                                                                      [boolean]
//       --server                 Run cdxgen as a server                                                          [boolean]
//       --server-host            Listen address                                                     [default: "127.0.0.1"]
//       --server-port            Listen port                                                             [default: "9090"]
//       --install-deps           Install dependencies automatically for some projects. Defaults to true but disabled for c
//                                ontainers and oci scans. Use --no-install-deps to disable this feature.
//                                                                                                [boolean] [default: true]
//       --validate               Validate the generated SBOM using json schema. Defaults to true. Pass --no-validate to di
//                                sable.                                                          [boolean] [default: true]
//       --evidence               Generate SBOM with evidence for supported languages.           [boolean] [default: false]
//       --spec-version           CycloneDX Specification version to use. Defaults to 1.6
//                                                                         [number] [choices: 1.4, 1.5, 1.6, 1.7] [default: 1.6]
//       --filter                 Filter components containing this word in purl or component.properties.value. Multiple va
//                                lues allowed.                                                                     [array]
//       --only                   Include components only containing this word in purl. Useful to generate BOM with first p
//                                arty components alone. Multiple values allowed.                                   [array]
//       --author                 The person(s) who created the BOM. Set this value if you're intending the modify the BOM
//                                and claim authorship.                               [array] [default: "OWASP Foundation"]
//       --profile                BOM profile to use for generation. Default generic.
//   [choices: "appsec", "research", "operational", "threat-modeling", "license-compliance", "generic", "machine-learning",
//                                                        "ml", "deep-learning", "ml-deep", "ml-tiny"] [default: "generic"]
//       --exclude                Additional glob pattern(s) to ignore                                              [array]
//       --export-proto           Serialize and export BOM as protobuf binary.  [boolean] [default: false]
//       --proto-bin-file         Path for the serialized protobuf binary.  [default: "bom.cdx"]
//       --include-formulation    Generate formulation section with git metadata and build tools. Defaults to false.
//                                                                                               [boolean] [default: false]
//       --include-crypto         Include crypto libraries as components.                        [boolean] [default: false]
//       --standard               The list of standards which may consist of regulations, industry or organizational-specif
//                                ic standards, maturity models, best practices, or any other requirements which can be eva
//                                luated against or attested to.
//   [array] [choices: "asvs-5.0", "asvs-4.0.3", "bsimm-v13", "masvs-2.0.0", "nist_ssdf-1.1", "pcissc-secure-slc-1.1", "scv
//                                                                                          s-1.0.0", "ssaf-DRAFT-2023-11"]
//       --json-pretty            Pretty-print the generated BOM json.                           [boolean] [default: false]
//       --min-confidence         Minimum confidence needed for the identity of a component from 0 - 1, where 1 is 100% con
//                                fidence.                                                            [number] [default: 0]
//       --technique              Analysis technique to use
//   [array] [choices: "auto", "source-code-analysis", "binary-analysis", "manifest-analysis", "hash-comparison", "instrume
//                                                                                                    ntation", "filename"]
//       --auto-compositions      Automatically set compositions when the BOM was filtered. Defaults to true
//                                                                                                [boolean] [default: true]
//   -h, --help                   Show help                                                                       [boolean]
//   -v, --version                Show version number                                                             [boolean]

// isSecureMode defined at:
// https://github.com/CycloneDX/cdxgen/blob/v11.2.7/lib/helpers/utils.js#L66
// const isSecureMode =
//   ['true', '1'].includes(process.env?.CDXGEN_SECURE_MODE) ||
//   process.env?.NODE_OPTIONS?.includes('--permission')

// Yargs CDXGEN configuration defined at:
// https://github.com/CycloneDX/cdxgen/blob/v11.2.7/bin/cdxgen.js#L64
const yargsConfig = {
  configuration: {
    'camel-case-expansion': false,
    'greedy-arrays': false,
    'parse-numbers': false,
    'populate--': true,
    'short-option-groups': false,
    'strip-aliased': true,
    'unknown-options-as-args': true
  },
  coerce: {
    'exclude-type': arrayToLower,
    'feature-flags': arrayToLower,
    filter: arrayToLower,
    only: arrayToLower,
    profile: toLower,
    standard: arrayToLower,
    technique: arrayToLower,
    type: arrayToLower
  },
  default: {
    //author: ['OWASP Foundation'],
    //'auto-compositions': true,
    //babel: true,
    //banner: false, // hidden
    //'deps-slices-file': 'deps.slices.json', // hidden
    //evidence: false,
    //'exclude-type': [],
    //'export-proto': false,
    //'fail-on-error': isSecureMode,
    //'feature-flags': [], // hidden
    //'include-crypto': false,
    //'include-formulation': false,
    //'install-deps': !isSecureMode
    //lifecycle: 'build', // hidden
    //'min-confidence': '0',
    //output: 'bom.json',
    //profile: 'generic',
    //'project-version': '',
    //'proto-bin-file': 'bom.cdx',
    //recurse: true,
    //'skip-dt-tls-check': false,
    //'semantics-slices-file': 'semantics.slices.json',
    //'server-host': '127.0.0.1',
    //'server-port': '9090',
    //'spec-version': '1.6',
    type: ['js']
    //validate: true,
  },
  alias: {
    help: ['h'],
    output: ['o'],
    print: ['p'],
    recurse: ['r'],
    'resolve-class': ['c'],
    type: ['t'],
    version: ['v']
  },
  array: [{
    key: 'author',
    type: 'string'
  }, {
    key: 'exclude',
    type: 'string'
  }, {
    key: 'exclude-type',
    type: 'string'
  }, {
    key: 'feature-flags',
    type: 'string'
  },
  // hidden
  {
    key: 'filter',
    type: 'string'
  }, {
    key: 'only',
    type: 'string'
  }, {
    key: 'standard',
    type: 'string'
  }, {
    key: 'technique',
    type: 'string'
  }, {
    key: 'type',
    type: 'string'
  }],
  boolean: ['auto-compositions', 'babel', 'banner',
  // hidden
  'deep', 'evidence', 'export-proto', 'fail-on-error', 'generate-key-and-sign', 'help', 'include-crypto', 'include-formulation', 'install-deps', 'json-pretty', 'print', 'recurse', 'required-only', 'resolve-class', 'skip-dt-tls-check', 'server', 'validate', 'version'],
  string: ['api-key', 'data-flow-slices-file',
  // hidden
  'deps-slices-file',
  // hidden
  'evinse-output',
  // hidden
  'lifecycle', 'min-confidence',
  // number
  'openapi-spec-file',
  // hidden
  'output', 'parent-project-id', 'profile', 'project-group', 'project-name', 'project-version', 'project-id', 'proto-bin-file', 'reachables-slices-file',
  // hidden
  'semantics-slices-file',
  // hidden
  'server-host', 'server-port', 'server-url', 'spec-version',
  // number
  'usages-slices-file' // hidden
  ]
};
const config$e = {
  commandName: 'cdxgen',
  description: 'Run cdxgen for SBOM generation',
  hidden: false,
  // Stub out flags and help.
  // TODO: Convert yargs to meow.
  flags: {},
  help: () => ''
};
const cmdManifestCdxgen = {
  description: config$e.description,
  hidden: config$e.hidden,
  run: run$F
};
async function run$F(argv, importMeta, context) {
  const {
    parentName
  } = {
    __proto__: null,
    ...context
  };
  const cli = utils.meowOrExit({
    // Don't let meow take over --help.
    argv: argv.filter(a => !utils.isHelpFlag(a)),
    config: config$e,
    importMeta,
    parentName
  });
  const {
    dryRun
  } = cli.flags;

  // Filter Socket flags from argv but keep --no-banner and --help for cdxgen.
  const argsToProcess = utils.filterFlags(argv, {
    ...flags.commonFlags,
    ...flags.outputFlags
  }, ['--no-banner', constants.FLAG_HELP, '-h']);
  const yargv = {
    ...vendor.yargsParser(argsToProcess, yargsConfig)
  };
  const pathArgs = [];
  const unknowns = [];
  for (const a of yargv._) {
    if (path$1.isPath(a)) {
      pathArgs.push(a);
    } else {
      unknowns.push(a);
    }
  }
  yargv._ = pathArgs;
  const {
    length: unknownsCount
  } = unknowns;
  if (unknownsCount) {
    // Use exit status of 2 to indicate incorrect usage, generally invalid
    // options or missing arguments.
    // https://www.gnu.org/software/bash/manual/html_node/Exit-Status.html
    process.exitCode = 2;
    logger.logger.fail(`Unknown ${words.pluralize('argument', unknownsCount)}: ${arrays.joinAnd(unknowns)}`);
    return;
  }
  if (dryRun) {
    logger.logger.log(constants.default.DRY_RUN_BAILING_NOW);
    return;
  }

  // Change defaults when not passing the --help flag.
  if (!yargv.help) {
    // Make 'lifecycle' default to 'pre-build', which also sets 'install-deps' to `false`,
    // to avoid arbitrary code execution on the cdxgen scan.
    // https://github.com/CycloneDX/cdxgen/issues/1328
    if (yargv.lifecycle === undefined) {
      yargv.lifecycle = 'pre-build';
      yargv['install-deps'] = false;
      logger.logger.info(`Setting cdxgen --lifecycle to "${yargv.lifecycle}" to avoid arbitrary code execution on this scan.\n  Pass "--lifecycle build" to generate a BOM consisting of information obtained during the build process.\n  See cdxgen ${vendor.terminalLinkExports('BOM lifecycles documentation', 'https://cyclonedx.github.io/cdxgen/#/ADVANCED?id=bom-lifecycles')} for more details.\n`);
    }
    if (yargv.output === undefined) {
      yargv.output = 'socket-cdx.json';
    }
  }
  process.exitCode = 1;
  const {
    spawnPromise
  } = await runCdxgen(yargv);

  // See https://nodejs.org/api/child_process.html#event-exit.
  spawnPromise.process.on('exit', (code, signalName) => {
    if (signalName) {
      process.kill(process.pid, signalName);
    } else if (typeof code === 'number') {
      // eslint-disable-next-line n/no-process-exit
      process.exit(code);
    }
  });
  await spawnPromise;
}

const config$d = {
  commandName: 'auto',
  description: 'Auto-detect build and attempt to generate manifest file',
  hidden: false,
  flags: {
    ...flags.commonFlags,
    verbose: {
      type: 'boolean',
      default: false,
      description: 'Enable debug output (only for auto itself; sub-steps need to have it pre-configured), may help when running into errors'
    }
  },
  help: (command, config) => `
    Usage
      $ ${command} [options] [CWD=.]

    Options
      ${utils.getFlagListOutput(config.flags)}

    Tries to figure out what language your target repo uses. If it finds a
    supported case then it will try to generate the manifest file for that
    language with the default or detected settings.

    Note: you can exclude languages from being auto-generated if you don't want
          them to. Run \`socket manifest setup\` in the same dir to disable it.

    Examples

      $ ${command}
      $ ${command} ./project/foo
  `
};
const cmdManifestAuto = {
  description: config$d.description,
  hidden: config$d.hidden,
  run: run$E
};
async function run$E(argv, importMeta, {
  parentName
}) {
  const cli = utils.meowOrExit({
    argv,
    config: config$d,
    importMeta,
    parentName
  });
  // TODO: Implement json/md further.
  const {
    json,
    markdown,
    verbose: verboseFlag
  } = cli.flags;
  const dryRun = !!cli.flags['dryRun'];
  const verbose = !!verboseFlag;
  let [cwd = '.'] = cli.input;
  // Note: path.resolve vs .join:
  // If given path is absolute then cwd should not affect it.
  cwd = path.resolve(process.cwd(), cwd);
  const outputKind = utils.getOutputKind(json, markdown);
  if (verbose) {
    logger.logger.group('- ', parentName, config$d.commandName, ':');
    logger.logger.group('- flags:', cli.flags);
    logger.logger.groupEnd();
    logger.logger.log('- input:', cli.input);
    logger.logger.log('- cwd:', cwd);
    logger.logger.groupEnd();
  }
  const sockJson = utils.readOrDefaultSocketJson(cwd);
  const detected = await detectManifestActions(sockJson, cwd);
  require$$9.debugDir('inspect', {
    detected
  });
  if (dryRun) {
    logger.logger.log(constants.default.DRY_RUN_BAILING_NOW);
    return;
  }
  if (!detected.count) {
    logger.logger.fail('Was unable to discover any targets for which we can generate manifest files...');
    logger.logger.log('');
    logger.logger.log('- Make sure this script would work with your target build (see `socket manifest --help` for your target).');
    logger.logger.log('- Make sure to run it from the correct dir (use --cwd to target another dir)');
    logger.logger.log('- Make sure the necessary build tools are available (`PATH`)');
    process.exitCode = 1;
    return;
  }
  await generateAutoManifest({
    detected,
    cwd,
    outputKind,
    verbose
  });
  logger.logger.success(`Finished. Should have attempted to generate manifest files for ${detected.count} targets.`);
}

const config$c = {
  commandName: 'conda',
  description: `[beta] Convert a Conda ${constants.ENVIRONMENT_YML} file to a python ${constants.REQUIREMENTS_TXT}`,
  hidden: false,
  flags: {
    ...flags.commonFlags,
    ...flags.outputFlags,
    file: {
      type: 'string',
      default: '',
      description: `Input file name (by default for Conda this is "${constants.ENVIRONMENT_YML}"), relative to cwd`
    },
    stdin: {
      type: 'boolean',
      description: 'Read the input from stdin (supersedes --file)'
    },
    out: {
      type: 'string',
      default: '',
      description: 'Output path (relative to cwd)'
    },
    stdout: {
      type: 'boolean',
      description: `Print resulting ${constants.REQUIREMENTS_TXT} to stdout (supersedes --out)`
    },
    verbose: {
      type: 'boolean',
      description: 'Print debug messages'
    }
  },
  help: (command, config) => `
    Usage
      $ ${command} [options] [CWD=.]

    Warning: While we don't support Conda necessarily, this tool extracts the pip
             block from an ${constants.ENVIRONMENT_YML} and outputs it as a ${constants.REQUIREMENTS_TXT}
             which you can scan as if it were a PyPI package.

    USE AT YOUR OWN RISK

    Note: FILE can be a dash (-) to indicate stdin. This way you can pipe the
          contents of a file to have it processed.

    Options
      ${utils.getFlagListOutput(config.flags)}

    Examples

      $ ${command}
      $ ${command} ./project/foo --file ${constants.ENVIRONMENT_YAML}
  `
};
const cmdManifestConda = {
  description: config$c.description,
  hidden: config$c.hidden,
  run: run$D
};
async function run$D(argv, importMeta, {
  parentName
}) {
  const cli = utils.meowOrExit({
    argv,
    config: config$c,
    importMeta,
    parentName
  });
  const {
    dryRun,
    json,
    markdown
  } = cli.flags;
  let [cwd = '.'] = cli.input;
  // Note: path.resolve vs .join:
  // If given path is absolute then cwd should not affect it.
  cwd = path.resolve(process.cwd(), cwd);
  const sockJson = utils.readOrDefaultSocketJson(cwd);
  let {
    file: filename,
    out,
    stdin,
    stdout,
    verbose
  } = cli.flags;

  // Set defaults for any flag/arg that is not given. Check socket.json first.
  if (stdin === undefined && sockJson.defaults?.manifest?.conda?.stdin !== undefined) {
    stdin = sockJson.defaults?.manifest?.conda?.stdin;
    logger.logger.info(`Using default --stdin from ${constants.SOCKET_JSON}:`, stdin);
  }
  if (stdin) {
    filename = '-';
  } else if (!filename) {
    if (sockJson.defaults?.manifest?.conda?.infile) {
      filename = sockJson.defaults?.manifest?.conda?.infile;
      logger.logger.info(`Using default --file from ${constants.SOCKET_JSON}:`, filename);
    } else {
      filename = constants.ENVIRONMENT_YML;
    }
  }
  if (stdout === undefined && sockJson.defaults?.manifest?.conda?.stdout !== undefined) {
    stdout = sockJson.defaults?.manifest?.conda?.stdout;
    logger.logger.info(`Using default --stdout from ${constants.SOCKET_JSON}:`, stdout);
  }
  if (stdout) {
    out = '-';
  } else if (!out) {
    if (sockJson.defaults?.manifest?.conda?.outfile) {
      out = sockJson.defaults?.manifest?.conda?.outfile;
      logger.logger.info(`Using default --out from ${constants.SOCKET_JSON}:`, out);
    } else {
      out = constants.REQUIREMENTS_TXT;
    }
  }
  if (verbose === undefined && sockJson.defaults?.manifest?.conda?.verbose !== undefined) {
    verbose = sockJson.defaults?.manifest?.conda?.verbose;
    logger.logger.info(`Using default --verbose from ${constants.SOCKET_JSON}:`, verbose);
  } else if (verbose === undefined) {
    verbose = false;
  }
  if (verbose) {
    logger.logger.group('- ', parentName, config$c.commandName, ':');
    logger.logger.group('- flags:', cli.flags);
    logger.logger.groupEnd();
    logger.logger.log('- target:', cwd);
    logger.logger.log('- output:', out);
    logger.logger.groupEnd();
  }
  const outputKind = utils.getOutputKind(json, markdown);
  const wasValidInput = utils.checkCommandInput(outputKind, {
    nook: true,
    test: cli.input.length <= 1,
    message: 'Can only accept one DIR (make sure to escape spaces!)',
    fail: `received ${cli.input.length}`
  }, {
    nook: true,
    test: !json || !markdown,
    message: `The \`${constants.FLAG_JSON}\` and \`${constants.FLAG_MARKDOWN}\` flags can not be used at the same time`,
    fail: 'bad'
  });
  if (!wasValidInput) {
    return;
  }
  logger.logger.warn('Warning: This will approximate your Conda dependencies using PyPI. We do not yet officially support Conda. Use at your own risk.');
  if (dryRun) {
    logger.logger.log(constants.default.DRY_RUN_BAILING_NOW);
    return;
  }
  await handleManifestConda({
    cwd,
    filename,
    out,
    outputKind,
    verbose
  });
}

const config$b = {
  commandName: 'gradle',
  description: '[beta] Use Gradle to generate a manifest file (`pom.xml`) for a Gradle/Java/Kotlin/etc project',
  hidden: false,
  flags: {
    ...flags.commonFlags,
    bin: {
      type: 'string',
      description: 'Location of gradlew binary to use, default: CWD/gradlew'
    },
    gradleOpts: {
      type: 'string',
      description: 'Additional options to pass on to ./gradlew, see `./gradlew --help`'
    },
    verbose: {
      type: 'boolean',
      description: 'Print debug messages'
    }
  },
  help: (command, config) => `
    Usage
      $ ${command} [options] [CWD=.]

    Options
      ${utils.getFlagListOutput(config.flags)}

    Uses gradle, preferably through your local project \`gradlew\`, to generate a
    \`pom.xml\` file for each task. If you have no \`gradlew\` you can try the
    global \`gradle\` binary but that may not work (hard to predict).

    The \`pom.xml\` is a manifest file similar to \`package.json\` for npm or
    or ${constants.REQUIREMENTS_TXT} for PyPi), but specifically for Maven, which is Java's
    dependency repository. Languages like Kotlin and Scala piggy back on it too.

    There are some caveats with the gradle to \`pom.xml\` conversion:

    - each task will generate its own xml file and by default it generates one xml
      for every task. (This may be a good thing!)

    - it's possible certain features don't translate well into the xml. If you
      think something is missing that could be supported please reach out.

    - it works with your \`gradlew\` from your repo and local settings and config

    Support is beta. Please report issues or give us feedback on what's missing.

    Examples

      $ ${command} .
      $ ${command} --bin=../gradlew .
  `
};
const cmdManifestGradle = {
  description: config$b.description,
  hidden: config$b.hidden,
  run: run$C
};
async function run$C(argv, importMeta, {
  parentName
}) {
  const cli = utils.meowOrExit({
    argv,
    config: config$b,
    importMeta,
    parentName
  });
  const {
    json = false,
    markdown = false
  } = cli.flags;
  const dryRun = !!cli.flags['dryRun'];

  // TODO: Implement json/md further.
  const outputKind = utils.getOutputKind(json, markdown);
  let [cwd = '.'] = cli.input;
  // Note: path.resolve vs .join:
  // If given path is absolute then cwd should not affect it.
  cwd = path.resolve(process.cwd(), cwd);
  const sockJson = utils.readOrDefaultSocketJson(cwd);
  require$$9.debugFn('inspect', `override: ${constants.SOCKET_JSON} gradle`, sockJson?.defaults?.manifest?.gradle);
  let {
    bin,
    gradleOpts,
    verbose
  } = cli.flags;

  // Set defaults for any flag/arg that is not given. Check socket.json first.
  if (!bin) {
    if (sockJson.defaults?.manifest?.gradle?.bin) {
      bin = sockJson.defaults?.manifest?.gradle?.bin;
      logger.logger.info(`Using default --bin from ${constants.SOCKET_JSON}:`, bin);
    } else {
      bin = path.join(cwd, 'gradlew');
    }
  }
  if (!gradleOpts) {
    if (sockJson.defaults?.manifest?.gradle?.gradleOpts) {
      gradleOpts = sockJson.defaults?.manifest?.gradle?.gradleOpts;
      logger.logger.info(`Using default --gradle-opts from ${constants.SOCKET_JSON}:`, gradleOpts);
    } else {
      gradleOpts = '';
    }
  }
  if (verbose === undefined) {
    if (sockJson.defaults?.manifest?.gradle?.verbose !== undefined) {
      verbose = sockJson.defaults?.manifest?.gradle?.verbose;
      logger.logger.info(`Using default --verbose from ${constants.SOCKET_JSON}:`, verbose);
    } else {
      verbose = false;
    }
  }
  if (verbose) {
    logger.logger.group('- ', parentName, config$b.commandName, ':');
    logger.logger.group('- flags:', cli.flags);
    logger.logger.groupEnd();
    logger.logger.log('- input:', cli.input);
    logger.logger.groupEnd();
  }

  // TODO: We're not sure it's feasible to parse source file from stdin. We could
  //       try, store contents in a file in some folder, target that folder... what
  //       would the file name be?

  const wasValidInput = utils.checkCommandInput(outputKind, {
    nook: true,
    test: cli.input.length <= 1,
    message: 'Can only accept one DIR (make sure to escape spaces!)',
    fail: 'received ' + cli.input.length
  });
  if (!wasValidInput) {
    return;
  }
  if (verbose) {
    logger.logger.group();
    logger.logger.info('- cwd:', cwd);
    logger.logger.info('- gradle bin:', bin);
    logger.logger.groupEnd();
  }
  if (dryRun) {
    logger.logger.log(constants.default.DRY_RUN_BAILING_NOW);
    return;
  }
  await convertGradleToMaven({
    bin: String(bin),
    cwd,
    gradleOpts: String(gradleOpts || '').split(' ').map(s => s.trim()).filter(Boolean),
    verbose: Boolean(verbose)
  });
}

// TODO: We may want to dedupe some pieces for all gradle languages. I think it
//       makes sense to have separate commands for them and I think it makes
//       sense for the help panels to note the requested language, rather than
//       `socket manifest kotlin` to print help screens with `gradle` as the
//       command. Room for improvement.
const config$a = {
  commandName: 'kotlin',
  description: '[beta] Use Gradle to generate a manifest file (`pom.xml`) for a Kotlin project',
  hidden: false,
  flags: {
    ...flags.commonFlags,
    bin: {
      type: 'string',
      description: 'Location of gradlew binary to use, default: CWD/gradlew'
    },
    gradleOpts: {
      type: 'string',
      description: 'Additional options to pass on to ./gradlew, see `./gradlew --help`'
    },
    verbose: {
      type: 'boolean',
      description: 'Print debug messages'
    }
  },
  help: (command, config) => `
    Usage
      $ ${command} [options] [CWD=.]

    Options
      ${utils.getFlagListOutput(config.flags)}

    Uses gradle, preferably through your local project \`gradlew\`, to generate a
    \`pom.xml\` file for each task. If you have no \`gradlew\` you can try the
    global \`gradle\` binary but that may not work (hard to predict).

    The \`pom.xml\` is a manifest file similar to \`package.json\` for npm or
    or ${constants.REQUIREMENTS_TXT} for PyPi), but specifically for Maven, which is Java's
    dependency repository. Languages like Kotlin and Scala piggy back on it too.

    There are some caveats with the gradle to \`pom.xml\` conversion:

    - each task will generate its own xml file and by default it generates one xml
      for every task. (This may be a good thing!)

    - it's possible certain features don't translate well into the xml. If you
      think something is missing that could be supported please reach out.

    - it works with your \`gradlew\` from your repo and local settings and config

    Support is beta. Please report issues or give us feedback on what's missing.

    Examples

      $ ${command} .
      $ ${command} --bin=../gradlew .
  `
};
const cmdManifestKotlin = {
  description: config$a.description,
  hidden: config$a.hidden,
  run: run$B
};
async function run$B(argv, importMeta, {
  parentName
}) {
  const cli = utils.meowOrExit({
    argv,
    config: config$a,
    importMeta,
    parentName
  });
  const {
    json = false,
    markdown = false
  } = cli.flags;
  const dryRun = !!cli.flags['dryRun'];

  // TODO: Implement json/md further.
  const outputKind = utils.getOutputKind(json, markdown);
  let [cwd = '.'] = cli.input;
  // Note: path.resolve vs .join:
  // If given path is absolute then cwd should not affect it.
  cwd = path.resolve(process.cwd(), cwd);
  const sockJson = utils.readOrDefaultSocketJson(cwd);
  require$$9.debugFn('inspect', `override: ${constants.SOCKET_JSON} gradle`, sockJson?.defaults?.manifest?.gradle);
  let {
    bin,
    gradleOpts,
    verbose
  } = cli.flags;

  // Set defaults for any flag/arg that is not given. Check socket.json first.
  if (!bin) {
    if (sockJson.defaults?.manifest?.gradle?.bin) {
      bin = sockJson.defaults?.manifest?.gradle?.bin;
      logger.logger.info(`Using default --bin from ${constants.SOCKET_JSON}:`, bin);
    } else {
      bin = path.join(cwd, 'gradlew');
    }
  }
  if (!gradleOpts) {
    if (sockJson.defaults?.manifest?.gradle?.gradleOpts) {
      gradleOpts = sockJson.defaults?.manifest?.gradle?.gradleOpts;
      logger.logger.info(`Using default --gradle-opts from ${constants.SOCKET_JSON}:`, gradleOpts);
    } else {
      gradleOpts = '';
    }
  }
  if (verbose === undefined) {
    if (sockJson.defaults?.manifest?.gradle?.verbose !== undefined) {
      verbose = sockJson.defaults?.manifest?.gradle?.verbose;
      logger.logger.info(`Using default --verbose from ${constants.SOCKET_JSON}:`, verbose);
    } else {
      verbose = false;
    }
  }
  if (verbose) {
    logger.logger.group('- ', parentName, config$a.commandName, ':');
    logger.logger.group('- flags:', cli.flags);
    logger.logger.groupEnd();
    logger.logger.log('- input:', cli.input);
    logger.logger.groupEnd();
  }

  // TODO: We're not sure it's feasible to parse source file from stdin. We could
  //       try, store contents in a file in some folder, target that folder... what
  //       would the file name be?

  const wasValidInput = utils.checkCommandInput(outputKind, {
    nook: true,
    test: cli.input.length <= 1,
    message: 'Can only accept one DIR (make sure to escape spaces!)',
    fail: 'received ' + cli.input.length
  });
  if (!wasValidInput) {
    return;
  }
  if (verbose) {
    logger.logger.group();
    logger.logger.info('- cwd:', cwd);
    logger.logger.info('- gradle bin:', bin);
    logger.logger.groupEnd();
  }
  if (dryRun) {
    logger.logger.log(constants.default.DRY_RUN_BAILING_NOW);
    return;
  }
  await convertGradleToMaven({
    bin: String(bin),
    cwd,
    gradleOpts: String(gradleOpts || '').split(' ').map(s => s.trim()).filter(Boolean),
    verbose: Boolean(verbose)
  });
}

const config$9 = {
  commandName: 'scala',
  description: "[beta] Generate a manifest file (`pom.xml`) from Scala's `build.sbt` file",
  hidden: false,
  flags: {
    ...flags.commonFlags,
    bin: {
      type: 'string',
      description: 'Location of sbt binary to use'
    },
    out: {
      type: 'string',
      description: 'Path of output file; where to store the resulting manifest, see also --stdout'
    },
    stdout: {
      type: 'boolean',
      description: 'Print resulting pom.xml to stdout (supersedes --out)'
    },
    sbtOpts: {
      type: 'string',
      description: 'Additional options to pass on to sbt, as per `sbt --help`'
    },
    verbose: {
      type: 'boolean',
      description: 'Print debug messages'
    }
  },
  help: (command, config) => `
    Usage
      $ ${command} [options] [CWD=.]

    Options
      ${utils.getFlagListOutput(config.flags)}

    Uses \`sbt makePom\` to generate a \`pom.xml\` from your \`build.sbt\` file.
    This xml file is the dependency manifest (like a package.json
    for Node.js or ${constants.REQUIREMENTS_TXT} for PyPi), but specifically for Scala.

    There are some caveats with \`build.sbt\` to \`pom.xml\` conversion:

    - the xml is exported as socket.pom.xml as to not confuse existing build tools
      but it will first hit your /target/sbt<version> folder (as a different name)

    - the pom.xml format (standard by Scala) does not support certain sbt features
      - \`excludeAll()\`, \`dependencyOverrides\`, \`force()\`, \`relativePath\`
      - For details: https://www.scala-sbt.org/1.x/docs/Library-Management.html

    - it uses your sbt settings and local configuration verbatim

    - it can only export one target per run, so if you have multiple targets like
      development and production, you must run them separately.

    You can specify --bin to override the path to the \`sbt\` binary to invoke.

    Support is beta. Please report issues or give us feedback on what's missing.

    This is only for SBT. If your Scala setup uses gradle, please see the help
    sections for \`socket manifest gradle\` or \`socket cdxgen\`.

    Examples

      $ ${command}
      $ ${command} ./proj --bin=/usr/bin/sbt --file=boot.sbt
  `
};
const cmdManifestScala = {
  description: config$9.description,
  hidden: config$9.hidden,
  run: run$A
};
async function run$A(argv, importMeta, {
  parentName
}) {
  const cli = utils.meowOrExit({
    argv,
    config: config$9,
    importMeta,
    parentName
  });
  const {
    json = false,
    markdown = false
  } = cli.flags;
  const dryRun = !!cli.flags['dryRun'];
  let [cwd = '.'] = cli.input;
  // Note: path.resolve vs .join:
  // If given path is absolute then cwd should not affect it.
  cwd = path.resolve(process.cwd(), cwd);

  // TODO: Implement json/md further.
  const outputKind = utils.getOutputKind(json, markdown);
  const sockJson = utils.readOrDefaultSocketJson(cwd);
  require$$9.debugFn('inspect', `override: ${constants.SOCKET_JSON} sbt`, sockJson?.defaults?.manifest?.sbt);
  let {
    bin,
    out,
    sbtOpts,
    stdout,
    verbose
  } = cli.flags;

  // Set defaults for any flag/arg that is not given. Check socket.json first.
  if (!bin) {
    if (sockJson.defaults?.manifest?.sbt?.bin) {
      bin = sockJson.defaults?.manifest?.sbt?.bin;
      logger.logger.info(`Using default --bin from ${constants.SOCKET_JSON}:`, bin);
    } else {
      bin = 'sbt';
    }
  }
  if (stdout === undefined && sockJson.defaults?.manifest?.sbt?.stdout !== undefined) {
    stdout = sockJson.defaults?.manifest?.sbt?.stdout;
    logger.logger.info(`Using default --stdout from ${constants.SOCKET_JSON}:`, stdout);
  }
  if (stdout) {
    out = '-';
  } else if (!out) {
    if (sockJson.defaults?.manifest?.sbt?.outfile) {
      out = sockJson.defaults?.manifest?.sbt?.outfile;
      logger.logger.info(`Using default --out from ${constants.SOCKET_JSON}:`, out);
    } else {
      out = './socket.pom.xml';
    }
  }
  if (!sbtOpts) {
    if (sockJson.defaults?.manifest?.sbt?.sbtOpts) {
      sbtOpts = sockJson.defaults?.manifest?.sbt?.sbtOpts;
      logger.logger.info(`Using default --sbt-opts from ${constants.SOCKET_JSON}:`, sbtOpts);
    } else {
      sbtOpts = '';
    }
  }
  if (verbose === undefined && sockJson.defaults?.manifest?.sbt?.verbose !== undefined) {
    verbose = sockJson.defaults?.manifest?.sbt?.verbose;
    logger.logger.info(`Using default --verbose from ${constants.SOCKET_JSON}:`, verbose);
  } else if (verbose === undefined) {
    verbose = false;
  }
  if (verbose) {
    logger.logger.group('- ', parentName, config$9.commandName, ':');
    logger.logger.group('- flags:', cli.flags);
    logger.logger.groupEnd();
    logger.logger.log('- input:', cli.input);
    logger.logger.groupEnd();
  }

  // TODO: We're not sure it's feasible to parse source file from stdin. We could
  //       try, store contents in a file in some folder, target that folder... what
  //       would the file name be?

  const wasValidInput = utils.checkCommandInput(outputKind, {
    nook: true,
    test: cli.input.length <= 1,
    message: 'Can only accept one DIR (make sure to escape spaces!)',
    fail: 'received ' + cli.input.length
  });
  if (!wasValidInput) {
    return;
  }
  if (verbose) {
    logger.logger.group();
    logger.logger.log('- target:', cwd);
    logger.logger.log('- sbt bin:', bin);
    logger.logger.log('- out:', out);
    logger.logger.groupEnd();
  }
  if (dryRun) {
    logger.logger.log(constants.default.DRY_RUN_BAILING_NOW);
    return;
  }
  await convertSbtToMaven({
    bin: String(bin),
    cwd: cwd,
    out: String(out),
    sbtOpts: String(sbtOpts).split(' ').map(s => s.trim()).filter(Boolean),
    verbose: Boolean(verbose)
  });
}

async function outputManifestSetup(result) {
  if (!result.ok) {
    process.exitCode = result.code ?? 1;
  }
  if (!result.ok) {
    logger.logger.fail(utils.failMsgWithBadge(result.message, result.cause));
    return;
  }
  logger.logger.success('Setup complete');
}

async function setupManifestConfig(cwd, defaultOnReadError = false) {
  const detected = await detectManifestActions(null, cwd);
  require$$9.debugDir('inspect', {
    detected
  });

  // - repeat
  //   - give the user an option to configure one of the supported targets
  //   - run through an interactive prompt for selected target
  //   - each target will have its own specific options
  //   - record them to the socket.yml (or socket-cli.yml ? or just socket.json ?)

  const jsonPath = path.join(cwd, constants.SOCKET_JSON);
  if (fs$1.existsSync(jsonPath)) {
    logger.logger.info(`Found ${constants.SOCKET_JSON} at ${jsonPath}`);
  } else {
    logger.logger.info(`No ${constants.SOCKET_JSON} found at ${cwd}, will generate a new one`);
  }
  logger.logger.log('');
  logger.logger.log('Note: This tool will set up flag and argument defaults for certain');
  logger.logger.log('      CLI commands. You can still override them by explicitly');
  logger.logger.log('      setting the flag. It is meant to be a convenience tool.');
  logger.logger.log('');
  logger.logger.log(`This command will generate a ${constants.SOCKET_JSON} file in the target cwd.`);
  logger.logger.log('You can choose to add this file to your repo (handy for collaboration)');
  logger.logger.log('or to add it to the ignored files, or neither. This file is only');
  logger.logger.log('used in CLI workflows.');
  logger.logger.log('');
  const choices = [{
    name: 'Conda'.padEnd(30, ' '),
    value: 'conda',
    description: `Generate ${constants.REQUIREMENTS_TXT} from a Conda environment.yml`
  }, {
    name: 'Gradle'.padEnd(30, ' '),
    value: 'gradle',
    description: 'Generate pom.xml files through gradle'
  }, {
    name: 'Kotlin (gradle)'.padEnd(30, ' '),
    value: 'gradle',
    description: 'Generate pom.xml files (for Kotlin) through gradle'
  }, {
    name: 'Scala (gradle)'.padEnd(30, ' '),
    value: 'gradle',
    description: 'Generate pom.xml files (for Scala) through gradle'
  }, {
    name: 'Scala (sbt)'.padEnd(30, ' '),
    value: 'sbt',
    description: 'Generate pom.xml files through sbt'
  }];
  choices.forEach(obj => {
    if (detected[obj.value]) {
      obj.name += ' [detected]';
    }
  });

  // Surface detected language first, then by alphabet
  choices.sort((a, b) => {
    if (detected[a.value] && !detected[b.value]) {
      return -1;
    }
    if (!detected[a.value] && detected[b.value]) {
      return 1;
    }
    return a.value < b.value ? -1 : a.value > b.value ? 1 : 0;
  });

  // Make exit the last entry...
  choices.push({
    name: 'None, exit configurator',
    value: '',
    description: 'Exit setup'
  });

  // TODO: Use detected to list those first.
  const targetEco = await prompts.select({
    message: 'Select ecosystem manifest generator to configure',
    choices
  });
  const sockJsonCResult = utils.readSocketJsonSync(cwd, defaultOnReadError);
  if (!sockJsonCResult.ok) {
    return sockJsonCResult;
  }
  const sockJson = sockJsonCResult.data;
  if (!sockJson.defaults) {
    sockJson.defaults = {};
  }
  if (!sockJson.defaults.manifest) {
    sockJson.defaults.manifest = {};
  }
  let result;
  switch (targetEco) {
    case 'conda':
      {
        if (!sockJson.defaults.manifest.conda) {
          sockJson.defaults.manifest.conda = {};
        }
        result = await setupConda(sockJson.defaults.manifest.conda);
        break;
      }
    case 'gradle':
      {
        if (!sockJson.defaults.manifest.gradle) {
          sockJson.defaults.manifest.gradle = {};
        }
        result = await setupGradle(sockJson.defaults.manifest.gradle);
        break;
      }
    case 'sbt':
      {
        if (!sockJson.defaults.manifest.sbt) {
          sockJson.defaults.manifest.sbt = {};
        }
        result = await setupSbt(sockJson.defaults.manifest.sbt);
        break;
      }
    default:
      {
        result = canceledByUser$1();
      }
  }
  if (!result.ok || result.data.canceled) {
    return result;
  }
  logger.logger.log('');
  logger.logger.log(`Setup complete. Writing ${constants.SOCKET_JSON}`);
  logger.logger.log('');
  if (await prompts.select({
    message: `Do you want to write the new config to ${jsonPath} ?`,
    choices: [{
      name: 'yes',
      value: true,
      description: 'Update config'
    }, {
      name: 'no',
      value: false,
      description: 'Do not update the config'
    }]
  })) {
    return await utils.writeSocketJson(cwd, sockJson);
  }
  return canceledByUser$1();
}
async function setupConda(config) {
  const on = await askForEnabled(!config.disabled);
  if (on === undefined) {
    return canceledByUser$1();
  } else if (on) {
    delete config.disabled;
  } else {
    config.disabled = true;
  }
  const infile = await askForInputFile(config.infile || 'environment.yml');
  if (infile === undefined) {
    return canceledByUser$1();
  } else if (infile === '-') {
    config.stdin = true;
  } else {
    delete config.stdin;
    if (infile) {
      config.infile = infile;
    } else {
      delete config.infile;
    }
  }
  const stdout = await askForStdout(config.stdout);
  if (stdout === undefined) {
    return canceledByUser$1();
  } else if (stdout === 'yes') {
    config.stdout = true;
  } else if (stdout === 'no') {
    config.stdout = false;
  } else {
    delete config.stdout;
  }
  if (!config.stdout) {
    const out = await askForOutputFile(config.outfile || constants.REQUIREMENTS_TXT);
    if (out === undefined) {
      return canceledByUser$1();
    } else if (out === '-') {
      config.stdout = true;
    } else {
      delete config.stdout;
      if (out) {
        config.outfile = out;
      } else {
        delete config.outfile;
      }
    }
  }
  const verbose = await askForVerboseFlag(config.verbose);
  if (verbose === undefined) {
    return canceledByUser$1();
  } else if (verbose === 'yes' || verbose === 'no') {
    config.verbose = verbose === 'yes';
  } else {
    delete config.verbose;
  }
  return notCanceled$1();
}
async function setupGradle(config) {
  const bin = await askForBin(config.bin || './gradlew');
  if (bin === undefined) {
    return canceledByUser$1();
  } else if (bin) {
    config.bin = bin;
  } else {
    delete config.bin;
  }
  const opts = await prompts.input({
    message: '(--gradle-opts) Enter gradle options to pass through',
    default: config.gradleOpts || '',
    required: false
    // validate: async string => bool
  });
  if (opts === undefined) {
    return canceledByUser$1();
  } else if (opts) {
    config.gradleOpts = opts;
  } else {
    delete config.gradleOpts;
  }
  const verbose = await askForVerboseFlag(config.verbose);
  if (verbose === undefined) {
    return canceledByUser$1();
  } else if (verbose === 'yes' || verbose === 'no') {
    config.verbose = verbose === 'yes';
  } else {
    delete config.verbose;
  }
  return notCanceled$1();
}
async function setupSbt(config) {
  const bin = await askForBin(config.bin || 'sbt');
  if (bin === undefined) {
    return canceledByUser$1();
  } else if (bin) {
    config.bin = bin;
  } else {
    delete config.bin;
  }
  const opts = await prompts.input({
    message: '(--sbt-opts) Enter sbt options to pass through',
    default: config.sbtOpts || '',
    required: false
    // validate: async string => bool
  });
  if (opts === undefined) {
    return canceledByUser$1();
  } else if (opts) {
    config.sbtOpts = opts;
  } else {
    delete config.sbtOpts;
  }
  const stdout = await askForStdout(config.stdout);
  if (stdout === undefined) {
    return canceledByUser$1();
  } else if (stdout === 'yes') {
    config.stdout = true;
  } else if (stdout === 'no') {
    config.stdout = false;
  } else {
    delete config.stdout;
  }
  if (config.stdout !== true) {
    const out = await askForOutputFile(config.outfile || 'sbt.pom.xml');
    if (out === undefined) {
      return canceledByUser$1();
    } else if (out === '-') {
      config.stdout = true;
    } else {
      delete config.stdout;
      if (out) {
        config.outfile = out;
      } else {
        delete config.outfile;
      }
    }
  }
  const verbose = await askForVerboseFlag(config.verbose);
  if (verbose === undefined) {
    return canceledByUser$1();
  } else if (verbose === 'yes' || verbose === 'no') {
    config.verbose = verbose === 'yes';
  } else {
    delete config.verbose;
  }
  return notCanceled$1();
}
async function askForStdout(defaultValue) {
  return await prompts.select({
    message: '(--stdout) Print the resulting pom.xml to stdout?',
    choices: [{
      name: 'no',
      value: 'no',
      description: 'Write output to a file, not stdout'
    }, {
      name: 'yes',
      value: 'yes',
      description: 'Print in stdout (this will supersede --out)'
    }, {
      name: '(leave default)',
      value: '',
      description: 'Do not store a setting for this'
    }],
    default: defaultValue === true ? 'yes' : defaultValue === false ? 'no' : ''
  });
}
async function askForEnabled(defaultValue) {
  return await prompts.select({
    message: 'Do you want to enable or disable auto generating manifest files for this language in this dir?',
    choices: [{
      name: 'Enable',
      value: true,
      description: 'Generate manifest files for this language when detected'
    }, {
      name: 'Disable',
      value: false,
      description: 'Do not generate manifest files for this language when detected, unless explicitly asking for it'
    }, {
      name: 'Cancel',
      value: undefined,
      description: 'Exit configurator'
    }],
    default: defaultValue === true ? 'enable' : defaultValue === false ? 'disable' : ''
  });
}
async function askForInputFile(defaultName = '') {
  return await prompts.input({
    message: '(--file) What should be the default file name to read? Should be an absolute path or relative to the cwd. Use `-` to read from stdin instead.' + (defaultName ? ' (Backspace to leave default)' : ''),
    default: defaultName,
    required: false
    // validate: async string => bool
  });
}
async function askForOutputFile(defaultName = '') {
  return await prompts.input({
    message: '(--out) What should be the default output file? Should be absolute path or relative to cwd.' + (defaultName ? ' (Backspace to leave default)' : ''),
    default: defaultName,
    required: false
    // validate: async string => bool
  });
}
async function askForBin(defaultName = '') {
  return await prompts.input({
    message: '(--bin) What should be the command to execute? Usually your build binary.' + (defaultName ? ' (Backspace to leave default)' : ''),
    default: defaultName,
    required: false
    // validate: async string => bool
  });
}
async function askForVerboseFlag(current) {
  return await prompts.select({
    message: '(--verbose) Should this run in verbose mode by default?',
    choices: [{
      name: 'no',
      value: 'no',
      description: 'Do not run this manifest in verbose mode'
    }, {
      name: 'yes',
      value: 'yes',
      description: 'Run this manifest in verbose mode'
    }, {
      name: '(leave default)',
      value: '',
      description: 'Do not store a setting for this'
    }],
    default: current === true ? 'yes' : current === false ? 'no' : ''
  });
}
function canceledByUser$1() {
  logger.logger.log('');
  logger.logger.info('User canceled');
  logger.logger.log('');
  return {
    ok: true,
    data: {
      canceled: true
    }
  };
}
function notCanceled$1() {
  return {
    ok: true,
    data: {
      canceled: false
    }
  };
}

async function handleManifestSetup(cwd, defaultOnReadError) {
  const result = await setupManifestConfig(cwd, defaultOnReadError);
  await outputManifestSetup(result);
}

const config$8 = {
  commandName: 'setup',
  description: 'Start interactive configurator to customize default flag values for `socket manifest` in this dir',
  hidden: false,
  flags: {
    ...flags.commonFlags,
    defaultOnReadError: {
      type: 'boolean',
      description: `If reading the ${constants.SOCKET_JSON} fails, just use a default config? Warning: This might override the existing json file!`
    }
  },
  help: (command, config) => `
    Usage
      $ ${command} [CWD=.]

    Options
      ${utils.getFlagListOutput(config.flags)}

    This command will try to detect all supported ecosystems in given CWD. Then
    it starts a configurator where you can setup default values for certain flags
    when creating manifest files in that dir. These configuration details are
    then stored in a local \`${constants.SOCKET_JSON}\` file (which you may or may not commit
    to the repo). Next time you run \`socket manifest ...\` it will load this
    json file and any flags which are not explicitly set in the command but which
    have been registered in the json file will get the default value set to that
    value you stored rather than the hardcoded defaults.

    This helps with for example when your build binary is in a particular path
    or when your build tool needs specific opts and you don't want to specify
    them when running the command every time.

    You can also disable manifest generation for certain ecosystems.

    This generated configuration file will only be used locally by the CLI. You
    can commit it to the repo (useful for collaboration) or choose to add it to
    your .gitignore all the same. Only this CLI will use it.

    Examples
      $ ${command}
      $ ${command} ./proj
  `
};
const cmdManifestSetup = {
  description: config$8.description,
  hidden: config$8.hidden,
  run: run$z
};
async function run$z(argv, importMeta, {
  parentName
}) {
  const cli = utils.meowOrExit({
    argv,
    config: config$8,
    importMeta,
    parentName
  });
  const {
    defaultOnReadError = false
  } = cli.flags;
  const dryRun = !!cli.flags['dryRun'];
  let [cwd = '.'] = cli.input;
  // Note: path.resolve vs .join:
  // If given path is absolute then cwd should not affect it.
  cwd = path.resolve(process.cwd(), cwd);
  if (dryRun) {
    logger.logger.log(constants.default.DRY_RUN_BAILING_NOW);
    return;
  }
  await handleManifestSetup(cwd, Boolean(defaultOnReadError));
}

const config$7 = {
  commandName: 'manifest',
  description: 'Generate a dependency manifest for certain ecosystems',
  hidden: false,
  flags: {
    ...flags.commonFlags
  }};
const cmdManifest = {
  description: config$7.description,
  hidden: config$7.hidden,
  run: run$y
};
async function run$y(argv, importMeta, {
  parentName
}) {
  await utils.meowWithSubcommands({
    argv,
    name: `${parentName} ${config$7.commandName}`,
    importMeta,
    subcommands: {
      auto: cmdManifestAuto,
      cdxgen: cmdManifestCdxgen,
      conda: cmdManifestConda,
      gradle: cmdManifestGradle,
      kotlin: cmdManifestKotlin,
      scala: cmdManifestScala,
      setup: cmdManifestSetup
    }
  }, {
    aliases: {
      yolo: {
        description: config$7.description,
        hidden: true,
        argv: ['auto']
      }
    },
    description: config$7.description,
    flags: config$7.flags
  });
}

const require$5 = require$$5.createRequire((typeof document === 'undefined' ? require$$0.pathToFileURL(__filename).href : (_documentCurrentScript && _documentCurrentScript.tagName.toUpperCase() === 'SCRIPT' && _documentCurrentScript.src || new URL('cli.js', document.baseURI).href)));
const CMD_NAME$r = constants.NPM;
const description$w = 'Wraps npm with Socket security scanning';
const hidden$q = false;
const cmdNpm = {
  description: description$w,
  hidden: hidden$q,
  run: run$x
};
async function run$x(argv, importMeta, context) {
  const {
    parentName
  } = {
    __proto__: null,
    ...context
  };
  const config = {
    commandName: CMD_NAME$r,
    description: description$w,
    hidden: hidden$q,
    flags: {
      ...flags.commonFlags
    },
    help: command => `
    Usage
      $ ${command} ...

    API Token Requirements
      ${utils.getFlagApiRequirementsOutput(`${parentName}:${CMD_NAME$r}`)}

    Note: Everything after "${constants.NPM}" is passed to the ${constants.NPM} command.
          Only the \`${constants.FLAG_DRY_RUN}\` and \`${constants.FLAG_HELP}\` flags are caught here.

    Use \`socket wrapper on\` to alias this command as \`${constants.NPM}\`.

    Examples
      $ ${command}
      $ ${command} install -g cowsay
      $ ${command} exec cowsay
    `
  };
  const cli = utils.meowOrExit({
    argv,
    config,
    importMeta,
    parentName
  });
  const dryRun = !!cli.flags['dryRun'];
  if (dryRun) {
    logger.logger.log(constants.default.DRY_RUN_BAILING_NOW);
    return;
  }
  const shadowNpmBin = /*@__PURE__*/require$5(constants.default.shadowNpmBinPath);
  process.exitCode = 1;

  // Filter Socket flags from argv but keep --json for npm.
  const argsToForward = utils.filterFlags(argv, {
    ...flags.commonFlags,
    ...flags.outputFlags
  }, [constants.FLAG_JSON]);
  const {
    spawnPromise
  } = await shadowNpmBin(argsToForward, {
    stdio: 'inherit'
  });

  // See https://nodejs.org/api/child_process.html#event-exit.
  spawnPromise.process.on('exit', (code, signalName) => {
    if (signalName) {
      process.kill(process.pid, signalName);
    } else if (typeof code === 'number') {
      // eslint-disable-next-line n/no-process-exit
      process.exit(code);
    }
  });
  await spawnPromise;
}

const require$4 = require$$5.createRequire((typeof document === 'undefined' ? require$$0.pathToFileURL(__filename).href : (_documentCurrentScript && _documentCurrentScript.tagName.toUpperCase() === 'SCRIPT' && _documentCurrentScript.src || new URL('cli.js', document.baseURI).href)));
const CMD_NAME$q = constants.NPX;
const description$v = 'Wraps npx with Socket security scanning';
const hidden$p = false;
const cmdNpx = {
  description: description$v,
  hidden: hidden$p,
  run: run$w
};
async function run$w(argv, importMeta, {
  parentName
}) {
  const config = {
    commandName: CMD_NAME$q,
    description: description$v,
    hidden: hidden$p,
    flags: {
      ...flags.commonFlags
    },
    help: (command, _config) => `
    Usage
      $ ${command} ...

    API Token Requirements
      ${utils.getFlagApiRequirementsOutput(`${parentName}:${CMD_NAME$q}`)}

    Note: Everything after "${constants.NPX}" is passed to the ${constants.NPX} command.
          Only the \`${constants.FLAG_DRY_RUN}\` and \`${constants.FLAG_HELP}\` flags are caught here.

    Use \`socket wrapper on\` to alias this command as \`${constants.NPX}\`.

    Examples
      $ ${command} cowsay
      $ ${command} cowsay@1.6.0 hello
  `
  };
  const cli = utils.meowOrExit({
    argv,
    config,
    parentName,
    importMeta
  });
  const dryRun = !!cli.flags['dryRun'];
  if (dryRun) {
    logger.logger.log(constants.default.DRY_RUN_BAILING_NOW);
    return;
  }
  const shadowNpxBin = /*@__PURE__*/require$4(constants.default.shadowNpxBinPath);
  process.exitCode = 1;
  const {
    spawnPromise
  } = await shadowNpxBin(argv, {
    stdio: 'inherit'
  });

  // See https://nodejs.org/api/child_process.html#event-exit.
  spawnPromise.process.on('exit', (code, signalName) => {
    if (signalName) {
      process.kill(process.pid, signalName);
    } else if (typeof code === 'number') {
      // eslint-disable-next-line n/no-process-exit
      process.exit(code);
    }
  });
  await spawnPromise;
}

const config$6 = {
  commandName: 'oops',
  description: 'Trigger an intentional error (for development)',
  hidden: true,
  flags: {
    ...flags.commonFlags,
    ...flags.outputFlags,
    throw: {
      type: 'boolean',
      default: false,
      description: 'Throw an explicit error even if --json or --markdown are set'
    }
  },
  help: (parentName, config) => `
    Usage
      $ ${parentName} ${config.commandName}

    Don't run me.
  `
};
const cmdOops = {
  description: config$6.description,
  hidden: config$6.hidden,
  run: run$v
};
async function run$v(argv, importMeta, {
  parentName
}) {
  const cli = utils.meowOrExit({
    argv,
    config: config$6,
    parentName,
    importMeta
  });
  const {
    json,
    markdown,
    throw: justThrow
  } = cli.flags;
  const dryRun = !!cli.flags['dryRun'];
  if (dryRun) {
    logger.logger.log(constants.default.DRY_RUN_BAILING_NOW);
    return;
  }
  if (json && !justThrow) {
    process.exitCode = 1;
    logger.logger.log(utils.serializeResultJson({
      ok: false,
      message: 'Oops',
      cause: 'This error was intentionally left blank'
    }));
  }
  if (markdown && !justThrow) {
    process.exitCode = 1;
    logger.logger.fail(utils.failMsgWithBadge('Oops', 'This error was intentionally left blank'));
    return;
  }
  throw new Error('This error was intentionally left blank.');
}

const {
  BUN: BUN$4,
  NPM: NPM$4,
  PNPM: PNPM$4,
  VLT: VLT$5,
  YARN_BERRY: YARN_BERRY$4,
  YARN_CLASSIC: YARN_CLASSIC$4
} = constants.default;
function matchLsCmdViewHumanStdout(stdout, name) {
  return stdout.includes(` ${name}@`);
}
function matchQueryCmdStdout(stdout, name) {
  return stdout.includes(`"${name}"`);
}
function lsStdoutIncludes(pkgEnvDetails, stdout, name) {
  switch (pkgEnvDetails.agent) {
    case BUN$4:
    case YARN_BERRY$4:
    case YARN_CLASSIC$4:
      return matchLsCmdViewHumanStdout(stdout, name);
    case PNPM$4:
    case VLT$5:
    case NPM$4:
    default:
      return matchQueryCmdStdout(stdout, name);
  }
}

function getDependencyEntries(pkgEnvDetails) {
  const {
    dependencies,
    devDependencies,
    optionalDependencies,
    peerDependencies
  } = pkgEnvDetails.editablePkgJson.content;
  return [['dependencies', dependencies ? {
    __proto__: null,
    ...dependencies
  } : undefined], ['devDependencies', devDependencies ? {
    __proto__: null,
    ...devDependencies
  } : undefined], ['peerDependencies', peerDependencies ? {
    __proto__: null,
    ...peerDependencies
  } : undefined], ['optionalDependencies', optionalDependencies ? {
    __proto__: null,
    ...optionalDependencies
  } : undefined]].filter(({
    1: o
  }) => o);
}

const {
  BUN: BUN$3,
  NPM: NPM$3,
  OVERRIDES: OVERRIDES$1,
  PNPM: PNPM$3,
  RESOLUTIONS: RESOLUTIONS$1,
  VLT: VLT$4,
  YARN_BERRY: YARN_BERRY$3,
  YARN_CLASSIC: YARN_CLASSIC$3
} = constants.default;
function getOverridesDataBun(pkgEnvDetails, pkgJson = pkgEnvDetails.editablePkgJson.content) {
  const overrides = pkgJson?.[RESOLUTIONS$1] ?? {};
  return {
    type: YARN_BERRY$3,
    overrides
  };
}

// npm overrides documentation:
// https://docs.npmjs.com/cli/v10/configuring-npm/package-json#overrides
function getOverridesDataNpm(pkgEnvDetails, pkgJson = pkgEnvDetails.editablePkgJson.content) {
  const overrides = pkgJson?.[OVERRIDES$1] ?? {};
  return {
    type: NPM$3,
    overrides
  };
}

// pnpm overrides documentation:
// https://pnpm.io/package_json#pnpmoverrides
function getOverridesDataPnpm(pkgEnvDetails, pkgJson = pkgEnvDetails.editablePkgJson.content) {
  const overrides = pkgJson?.[PNPM$3]?.[OVERRIDES$1] ?? {};
  return {
    type: PNPM$3,
    overrides
  };
}
function getOverridesDataVlt(pkgEnvDetails, pkgJson = pkgEnvDetails.editablePkgJson.content) {
  const overrides = pkgJson?.[OVERRIDES$1] ?? {};
  return {
    type: VLT$4,
    overrides
  };
}

// Yarn resolutions documentation:
// https://yarnpkg.com/configuration/manifest#resolutions
function getOverridesDataYarn(pkgEnvDetails, pkgJson = pkgEnvDetails.editablePkgJson.content) {
  const overrides = pkgJson?.[RESOLUTIONS$1] ?? {};
  return {
    type: YARN_BERRY$3,
    overrides
  };
}

// Yarn resolutions documentation:
// https://classic.yarnpkg.com/en/docs/selective-version-resolutions
function getOverridesDataYarnClassic(pkgEnvDetails, pkgJson = pkgEnvDetails.editablePkgJson.content) {
  const overrides = pkgJson?.[RESOLUTIONS$1] ?? {};
  return {
    type: YARN_CLASSIC$3,
    overrides
  };
}
function getOverridesData(pkgEnvDetails, pkgJson) {
  switch (pkgEnvDetails.agent) {
    case BUN$3:
      return getOverridesDataBun(pkgEnvDetails, pkgJson);
    case PNPM$3:
      return getOverridesDataPnpm(pkgEnvDetails, pkgJson);
    case VLT$4:
      return getOverridesDataVlt(pkgEnvDetails, pkgJson);
    case YARN_BERRY$3:
      return getOverridesDataYarn(pkgEnvDetails, pkgJson);
    case YARN_CLASSIC$3:
      return getOverridesDataYarnClassic(pkgEnvDetails, pkgJson);
    case NPM$3:
    default:
      return getOverridesDataNpm(pkgEnvDetails, pkgJson);
  }
}

const {
  BUN: BUN$2,
  EXT_LOCK,
  NPM: NPM$2,
  PNPM: PNPM$2,
  VLT: VLT$3,
  YARN_BERRY: YARN_BERRY$2,
  YARN_CLASSIC: YARN_CLASSIC$2
} = constants.default;
function npmLockSrcIncludes(lockSrc, name) {
  // Detects the package name in the following cases:
  //   "name":
  return lockSrc.includes(`"${name}":`);
}
function bunLockSrcIncludes(lockSrc, name, lockName) {
  // This is a bit counterintuitive. When lockName ends with a .lockb
  // we treat it as a yarn.lock. When lockName ends with a .lock we
  // treat it as a package-lock.json. The bun.lock format is not identical
  // package-lock.json, however it close enough for npmLockIncludes to work.
  const lockfileScanner = lockName?.endsWith(EXT_LOCK) ? npmLockSrcIncludes : yarnLockSrcIncludes;
  return lockfileScanner(lockSrc, name);
}
function pnpmLockSrcIncludes(lockSrc, name) {
  const escapedName = regexps.escapeRegExp(name);
  return new RegExp(
  // Detects the package name.
  // v9.0 and v6.0 lockfile patterns:
  //   'name'
  //   name:
  //   name@
  // v6.0 lockfile patterns:
  //   /name@
  `(?<=^\\s*)(?:'${escapedName}'|/?${escapedName}(?=[:@]))`, 'm').test(lockSrc);
}
function vltLockSrcIncludes(lockSrc, name) {
  // Detects the package name in the following cases:
  //   "name"
  return lockSrc.includes(`"${name}"`);
}
function yarnLockSrcIncludes(lockSrc, name) {
  const escapedName = regexps.escapeRegExp(name);
  return new RegExp(
  // Detects the package name in the following cases:
  //   "name@
  //   , "name@
  //   name@
  //   , name@
  `(?<=(?:^\\s*|,\\s*)"?)${escapedName}(?=@)`, 'm').test(lockSrc);
}
function lockSrcIncludes(pkgEnvDetails, lockSrc, name, lockName) {
  switch (pkgEnvDetails.agent) {
    case BUN$2:
      return bunLockSrcIncludes(lockSrc, name, lockName);
    case PNPM$2:
      return pnpmLockSrcIncludes(lockSrc, name);
    case VLT$3:
      return vltLockSrcIncludes(lockSrc, name);
    case YARN_BERRY$2:
      return yarnLockSrcIncludes(lockSrc, name);
    case YARN_CLASSIC$2:
      return yarnLockSrcIncludes(lockSrc, name);
    case NPM$2:
    default:
      return npmLockSrcIncludes(lockSrc, name);
  }
}

const {
  BUN: BUN$1,
  NPM: NPM$1,
  PNPM: PNPM$1,
  VLT: VLT$2,
  YARN_BERRY: YARN_BERRY$1,
  YARN_CLASSIC: YARN_CLASSIC$1
} = constants.default;
function cleanupQueryStdout(stdout) {
  if (stdout === '') {
    return '';
  }
  let pkgs;
  try {
    pkgs = JSON.parse(stdout);
  } catch {}
  if (!Array.isArray(pkgs) || !pkgs.length) {
    return '';
  }
  const names = new Set();
  for (const {
    _id,
    name,
    pkgid
  } of pkgs) {
    // `npm query` results may not have a "name" property, in which case we
    // fallback to "_id" and then "pkgid".
    // `vlt ls --view json` results always have a "name" property.
    const fallback = _id ?? pkgid ?? '';
    const resolvedName = name ?? fallback.slice(0, fallback.indexOf('@', 1));
    // Add package names, except for those under the `@types` scope as those
    // are known to only be dev dependencies.
    if (resolvedName && !resolvedName.startsWith('@types/')) {
      names.add(resolvedName);
    }
  }
  return JSON.stringify(Array.from(names), null, 2);
}
function parsableToQueryStdout(stdout) {
  if (stdout === '') {
    return '';
  }
  // Convert the parsable stdout into a json array of unique names.
  // The matchAll regexp looks for a forward (posix) or backward (win32) slash
  // and matches one or more non-slashes until the newline.
  const names = new Set(stdout.matchAll(/(?<=[/\\])[^/\\]+(?=\n)/g));
  return JSON.stringify(Array.from(names), null, 2);
}
async function npmQuery(npmExecPath, cwd) {
  let stdout = '';
  try {
    stdout = (await spawn.spawn(npmExecPath, ['query', ':not(.dev)'], {
      cwd,
      // On Windows, npm is often a .cmd file that requires shell execution.
      // The spawn function from @socketsecurity/registry will handle this properly
      // when shell is true.
      shell: constants.default.WIN32
    })).stdout;
  } catch {}
  return cleanupQueryStdout(stdout);
}
async function lsBun(pkgEnvDetails, options) {
  const {
    cwd = process.cwd()
  } = {
    __proto__: null,
    ...options
  };
  try {
    // Bun does not support filtering by production packages yet.
    // https://github.com/oven-sh/bun/issues/8283
    return (await spawn.spawn(pkgEnvDetails.agentExecPath, ['pm', 'ls', '--all'], {
      cwd,
      // On Windows, bun is often a .cmd file that requires shell execution.
      // The spawn function from @socketsecurity/registry will handle this properly
      // when shell is true.
      shell: constants.default.WIN32
    })).stdout;
  } catch {}
  return '';
}
async function lsNpm(pkgEnvDetails, options) {
  const {
    cwd = process.cwd()
  } = {
    __proto__: null,
    ...options
  };
  return await npmQuery(pkgEnvDetails.agentExecPath, cwd);
}
async function lsPnpm(pkgEnvDetails, options) {
  const {
    cwd = process.cwd(),
    npmExecPath
  } = {
    __proto__: null,
    ...options
  };
  if (npmExecPath && npmExecPath !== NPM$1) {
    const result = await npmQuery(npmExecPath, cwd);
    if (result) {
      return result;
    }
  }
  let stdout = '';
  try {
    stdout = (await spawn.spawn(pkgEnvDetails.agentExecPath,
    // Pnpm uses the alternative spelling of parsable.
    // https://en.wiktionary.org/wiki/parsable
    ['ls', '--parseable', constants.FLAG_PROD, '--depth', 'Infinity'], {
      cwd,
      // On Windows, pnpm is often a .cmd file that requires shell execution.
      // The spawn function from @socketsecurity/registry will handle this properly
      // when shell is true.
      shell: constants.default.WIN32
    })).stdout;
  } catch {}
  return parsableToQueryStdout(stdout);
}
async function lsVlt(pkgEnvDetails, options) {
  const {
    cwd = process.cwd()
  } = {
    __proto__: null,
    ...options
  };
  let stdout = '';
  try {
    // See https://docs.vlt.sh/cli/commands/list#options.
    stdout = (await spawn.spawn(pkgEnvDetails.agentExecPath, ['ls', '--view', 'human', ':not(.dev)'], {
      cwd,
      // On Windows, pnpm is often a .cmd file that requires shell execution.
      // The spawn function from @socketsecurity/registry will handle this properly
      // when shell is true.
      shell: constants.default.WIN32
    })).stdout;
  } catch {}
  return cleanupQueryStdout(stdout);
}
async function lsYarnBerry(pkgEnvDetails, options) {
  const {
    cwd = process.cwd()
  } = {
    __proto__: null,
    ...options
  };
  try {
    // Yarn Berry does not support filtering by production packages yet.
    // https://github.com/yarnpkg/berry/issues/5117
    return (await spawn.spawn(pkgEnvDetails.agentExecPath, ['info', '--recursive', '--name-only'], {
      cwd,
      // On Windows, yarn is often a .cmd file that requires shell execution.
      // The spawn function from @socketsecurity/registry will handle this properly
      // when shell is true.
      shell: constants.default.WIN32
    })).stdout;
  } catch {}
  return '';
}
async function lsYarnClassic(pkgEnvDetails, options) {
  const {
    cwd = process.cwd()
  } = {
    __proto__: null,
    ...options
  };
  try {
    // However, Yarn Classic does support it.
    // https://github.com/yarnpkg/yarn/releases/tag/v1.0.0
    // > Fix: Excludes dev dependencies from the yarn list output when the
    //   environment is production
    return (await spawn.spawn(pkgEnvDetails.agentExecPath, ['list', constants.FLAG_PROD], {
      cwd,
      // On Windows, yarn is often a .cmd file that requires shell execution.
      // The spawn function from @socketsecurity/registry will handle this properly
      // when shell is true.
      shell: constants.default.WIN32
    })).stdout;
  } catch {}
  return '';
}
async function listPackages(pkgEnvDetails, options) {
  switch (pkgEnvDetails.agent) {
    case BUN$1:
      return await lsBun(pkgEnvDetails, options);
    case PNPM$1:
      return await lsPnpm(pkgEnvDetails, options);
    case VLT$2:
      return await lsVlt(pkgEnvDetails, options);
    case YARN_BERRY$1:
      return await lsYarnBerry(pkgEnvDetails, options);
    case YARN_CLASSIC$1:
      return await lsYarnClassic(pkgEnvDetails, options);
    case NPM$1:
    default:
      return await lsNpm(pkgEnvDetails, options);
  }
}

const CMD_NAME$p = 'socket optimize';

const {
  BUN,
  NPM,
  OVERRIDES,
  PNPM,
  RESOLUTIONS,
  VLT: VLT$1,
  YARN_BERRY,
  YARN_CLASSIC
} = constants.default;
const depFields = ['dependencies', 'devDependencies', 'peerDependencies', 'peerDependenciesMeta', 'optionalDependencies', 'bundleDependencies'];
function getEntryIndexes(entries, keys) {
  return keys.map(n => entries.findIndex(p => p[0] === n)).filter(n => n !== -1).sort((a, b) => a - b);
}
function getLowestEntryIndex(entries, keys) {
  return getEntryIndexes(entries, keys)?.[0] ?? -1;
}
function getHighestEntryIndex(entries, keys) {
  return getEntryIndexes(entries, keys).at(-1) ?? -1;
}
function updatePkgJsonField(editablePkgJson, field, value) {
  const oldValue = editablePkgJson.content[field];
  if (oldValue) {
    // The field already exists so we simply update the field value.
    if (field === PNPM) {
      const isPnpmObj = require$$11.isObject(oldValue);
      if (require$$11.hasKeys(value)) {
        editablePkgJson.update({
          [field]: {
            ...(isPnpmObj ? oldValue : {}),
            overrides: {
              ...(isPnpmObj ? oldValue[OVERRIDES] : {}),
              ...value
            }
          }
        });
      } else {
        // Properties with undefined values are deleted when saved as JSON.
        editablePkgJson.update(require$$11.hasKeys(oldValue) ? {
          [field]: {
            ...(isPnpmObj ? oldValue : {}),
            overrides: undefined
          }
        } : {
          [field]: undefined
        });
      }
    } else if (field === OVERRIDES || field === RESOLUTIONS) {
      // Properties with undefined values are deleted when saved as JSON.
      editablePkgJson.update({
        [field]: require$$11.hasKeys(value) ? value : undefined
      });
    } else {
      editablePkgJson.update({
        [field]: value
      });
    }
    return;
  }
  if ((field === OVERRIDES || field === PNPM || field === RESOLUTIONS) && !require$$11.hasKeys(value)) {
    return;
  }
  // Since the field doesn't exist we want to insert it into the package.json
  // in a place that makes sense, e.g. close to the "dependencies" field. If
  // we can't find a place to insert the field we'll add it to the bottom.
  const entries = Object.entries(editablePkgJson.content);
  let insertIndex = -1;
  let isPlacingHigher = false;
  if (field === OVERRIDES) {
    insertIndex = getLowestEntryIndex(entries, [RESOLUTIONS]);
    if (insertIndex === -1) {
      isPlacingHigher = true;
      insertIndex = getHighestEntryIndex(entries, [...depFields, PNPM]);
    }
  } else if (field === RESOLUTIONS) {
    isPlacingHigher = true;
    insertIndex = getHighestEntryIndex(entries, [...depFields, OVERRIDES, PNPM]);
  } else if (field === PNPM) {
    insertIndex = getLowestEntryIndex(entries, [OVERRIDES, RESOLUTIONS]);
    if (insertIndex === -1) {
      isPlacingHigher = true;
      insertIndex = getHighestEntryIndex(entries, depFields);
    }
  }
  if (insertIndex === -1) {
    insertIndex = getLowestEntryIndex(entries, ['engines', 'files']);
  }
  if (insertIndex === -1) {
    isPlacingHigher = true;
    insertIndex = getHighestEntryIndex(entries, ['exports', 'imports', 'main']);
  }
  if (insertIndex === -1) {
    insertIndex = entries.length;
  } else if (isPlacingHigher) {
    insertIndex += 1;
  }
  entries.splice(insertIndex, 0, [field, field === PNPM ? {
    [OVERRIDES]: value
  } : value]);
  editablePkgJson.fromJSON(`${JSON.stringify(Object.fromEntries(entries), null, 2)}\n`);
}
function updateOverridesField(editablePkgJson, overrides) {
  updatePkgJsonField(editablePkgJson, OVERRIDES, overrides);
}
function updateResolutionsField(editablePkgJson, overrides) {
  updatePkgJsonField(editablePkgJson, RESOLUTIONS, overrides);
}
function updatePnpmField(editablePkgJson, overrides) {
  updatePkgJsonField(editablePkgJson, PNPM, overrides);
}
function updateManifest(agent, editablePkgJson, overrides) {
  switch (agent) {
    case BUN:
      updateResolutionsField(editablePkgJson, overrides);
      return;
    case PNPM:
      updatePnpmField(editablePkgJson, overrides);
      return;
    case VLT$1:
      updateOverridesField(editablePkgJson, overrides);
      return;
    case YARN_BERRY:
      updateResolutionsField(editablePkgJson, overrides);
      return;
    case YARN_CLASSIC:
      updateResolutionsField(editablePkgJson, overrides);
      return;
    case NPM:
    default:
      updateOverridesField(editablePkgJson, overrides);
      return;
  }
}

const manifestNpmOverrides = registry.getManifestData(constants.NPM);
async function addOverrides(pkgEnvDetails, pkgPath, options) {
  const {
    agent,
    lockName,
    lockSrc,
    npmExecPath,
    pkgPath: rootPath
  } = pkgEnvDetails;
  const {
    logger,
    pin,
    prod,
    spinner,
    state = {
      added: new Set(),
      addedInWorkspaces: new Set(),
      updated: new Set(),
      updatedInWorkspaces: new Set(),
      warnedPnpmWorkspaceRequiresNpm: false
    }
  } = {
    __proto__: null,
    ...options
  };
  const workspacePkgJsonPaths = await utils.globWorkspace(agent, pkgPath);
  const isPnpm = agent === constants.PNPM;
  const isWorkspace = workspacePkgJsonPaths.length > 0;
  const isWorkspaceRoot = pkgPath === rootPath;
  const isLockScanned = isWorkspaceRoot && !prod;
  const workspace = isWorkspaceRoot ? 'root' : path.relative(rootPath, pkgPath);
  if (isWorkspace && isPnpm &&
  // npmExecPath will === the agent name IF it CANNOT be resolved.
  npmExecPath === constants.NPM && !state.warnedPnpmWorkspaceRequiresNpm) {
    state.warnedPnpmWorkspaceRequiresNpm = true;
    spinner?.stop();
    logger?.warn(utils.cmdPrefixMessage(CMD_NAME$p, `${agent} workspace support requires \`npm ls\`, falling back to \`${agent} list\``));
    spinner?.start();
  }
  const overridesDataObjects = [];
  if (isWorkspace || pkgEnvDetails.editablePkgJson.content['private']) {
    overridesDataObjects.push(getOverridesData(pkgEnvDetails));
  } else {
    overridesDataObjects.push(getOverridesDataNpm(pkgEnvDetails), getOverridesDataYarnClassic(pkgEnvDetails));
  }
  const depAliasMap = new Map();
  const depEntries = getDependencyEntries(pkgEnvDetails);
  const manifestEntries = manifestNpmOverrides.filter(({
    1: data
  }) => vendor.semverExports.satisfies(
  // Roughly check Node range as semver.coerce will strip leading
  // v's, carets (^), comparators (<,<=,>,>=,=), and tildes (~).
  vendor.semverExports.coerce(data.engines.node), pkgEnvDetails.pkgRequirements.node));
  const addingText = `Adding overrides to ${workspace}...`;
  let loggedAddingText = false;

  // Chunk package names to process them in parallel 3 at a time.
  await require$$12.pEach(manifestEntries, async ({
    1: data
  }) => {
    const {
      name: sockRegPkgName,
      package: origPkgName,
      version
    } = data;
    const major = utils.getMajor(version);
    const sockOverridePrefix = `npm:${sockRegPkgName}@`;
    const sockOverrideSpec = `${sockOverridePrefix}${pin ? version : `^${major}`}`;
    for (const {
      1: depObj
    } of depEntries) {
      const sockSpec = require$$11.hasOwn(depObj, sockRegPkgName) ? depObj[sockRegPkgName] : undefined;
      if (sockSpec) {
        depAliasMap.set(sockRegPkgName, sockSpec);
      }
      const origSpec = require$$11.hasOwn(depObj, origPkgName) ? depObj[origPkgName] : undefined;
      if (origSpec) {
        let thisSpec = origSpec;
        // Add package aliases for direct dependencies to avoid npm EOVERRIDE
        // errors...
        // https://docs.npmjs.com/cli/v8/using-npm/package-spec#aliases
        if (
        // ...if the spec doesn't start with a valid Socket override.
        !(thisSpec.startsWith(sockOverridePrefix) &&
        // Check the validity of the spec by parsing it with npm-package-arg
        // and seeing if it will coerce to a version.
        vendor.semverExports.coerce(utils.safeNpa(thisSpec).subSpec.rawSpec)?.version)) {
          thisSpec = sockOverrideSpec;
          depObj[origPkgName] = thisSpec;
          state.added.add(sockRegPkgName);
          if (!isWorkspaceRoot) {
            state.addedInWorkspaces.add(workspace);
          }
          if (!loggedAddingText) {
            spinner?.setText(addingText);
            loggedAddingText = true;
          }
        }
        depAliasMap.set(origPkgName, thisSpec);
      }
    }
    if (isWorkspaceRoot) {
      // The lockSrcIncludes and lsStdoutIncludes functions overlap in their
      // first two parameters. lockSrcIncludes accepts an optional third parameter
      // which lsStdoutIncludes will ignore.
      const thingScanner = isLockScanned ? lockSrcIncludes : lsStdoutIncludes;
      const thingToScan = isLockScanned ? lockSrc : await listPackages(pkgEnvDetails, {
        cwd: pkgPath,
        npmExecPath
      });
      // Chunk package names to process them in parallel 3 at a time.
      await require$$12.pEach(overridesDataObjects, async ({
        overrides,
        type
      }) => {
        const overrideExists = require$$11.hasOwn(overrides, origPkgName);
        if (overrideExists || thingScanner(pkgEnvDetails, thingToScan, origPkgName, lockName)) {
          const oldSpec = overrideExists ? overrides[origPkgName] : undefined;
          const origDepAlias = depAliasMap.get(origPkgName);
          const sockRegDepAlias = depAliasMap.get(sockRegPkgName);
          const depAlias = sockRegDepAlias ?? origDepAlias;
          let newSpec = sockOverrideSpec;
          if (type === constants.NPM && depAlias) {
            // With npm one may not set an override for a package that one directly
            // depends on unless both the dependency and the override itself share
            // the exact same spec. To make this limitation easier to deal with,
            // overrides may also be defined as a reference to a spec for a direct
            // dependency by prefixing the name of the package to match the version
            // of with a $.
            // https://docs.npmjs.com/cli/v8/configuring-npm/package-json#overrides
            newSpec = `$${sockRegDepAlias ? sockRegPkgName : origPkgName}`;
          } else if (typeof oldSpec === 'string') {
            const thisSpec = oldSpec.startsWith('$') ? depAlias || newSpec : oldSpec || newSpec;
            if (thisSpec.startsWith(sockOverridePrefix)) {
              if (pin && utils.getMajor(
              // Check the validity of the spec by parsing it with npm-package-arg
              // and seeing if it will coerce to a version. semver.coerce
              // will strip leading v's, carets (^), comparators (<,<=,>,>=,=),
              // and tildes (~). If not coerced to a valid version then
              // default to the manifest entry version.
              vendor.semverExports.coerce(utils.safeNpa(thisSpec).subSpec.rawSpec)?.version ?? version) !== major) {
                const otherVersion = (await packages.fetchPackageManifest(thisSpec))?.version;
                if (otherVersion && otherVersion !== version) {
                  newSpec = `${sockOverridePrefix}${pin ? otherVersion : `^${utils.getMajor(otherVersion)}`}`;
                }
              }
            } else {
              newSpec = oldSpec;
            }
          }
          if (newSpec !== oldSpec) {
            overrides[origPkgName] = newSpec;
            const addedOrUpdated = overrideExists ? 'updated' : 'added';
            state[addedOrUpdated].add(sockRegPkgName);
            if (!loggedAddingText) {
              spinner?.setText(addingText);
              loggedAddingText = true;
            }
          }
        }
      }, {
        concurrency: 3
      });
    }
  }, {
    concurrency: 3
  });
  if (isWorkspace) {
    // Chunk package names to process them in parallel 3 at a time.
    await require$$12.pEach(workspacePkgJsonPaths, async workspacePkgJsonPath => {
      const otherState = await addOverrides(pkgEnvDetails, path.dirname(workspacePkgJsonPath), {
        logger,
        pin,
        prod,
        spinner
      });
      for (const key of ['added', 'addedInWorkspaces', 'updated', 'updatedInWorkspaces']) {
        for (const value of otherState[key]) {
          state[key].add(value);
        }
      }
    }, {
      concurrency: 3
    });
  }
  if (state.added.size > 0 || state.updated.size > 0) {
    pkgEnvDetails.editablePkgJson.update(Object.fromEntries(depEntries));
    if (isWorkspaceRoot) {
      for (const {
        overrides,
        type
      } of overridesDataObjects) {
        updateManifest(type, pkgEnvDetails.editablePkgJson, require$$11.toSortedObject(overrides));
      }
    }
    await pkgEnvDetails.editablePkgJson.save();
  }
  return state;
}

const {
  NPM_BUGGY_OVERRIDES_PATCHED_VERSION
} = constants.default;
async function updateLockfile(pkgEnvDetails, options) {
  const {
    cmdName = '',
    logger,
    spinner
  } = {
    __proto__: null,
    ...options
  };
  const wasSpinning = !!spinner?.isSpinning;
  spinner?.start(`Updating ${pkgEnvDetails.lockName}...`);
  try {
    await utils.runAgentInstall(pkgEnvDetails, {
      spinner
    });
    if (pkgEnvDetails.features.npmBuggyOverrides) {
      spinner?.stop();
      logger?.log(`💡 Re-run ${cmdName ? `${cmdName} ` : ''}whenever ${pkgEnvDetails.lockName} changes.\n   This can be skipped for ${pkgEnvDetails.agent} >=${NPM_BUGGY_OVERRIDES_PATCHED_VERSION}.`);
    }
  } catch (e) {
    spinner?.stop();
    require$$9.debugFn('error', 'Lockfile update failed');
    require$$9.debugDir('error', e);
    if (wasSpinning) {
      spinner.start();
    }
    return {
      ok: false,
      message: 'Update failed',
      cause: utils.cmdPrefixMessage(cmdName, `${pkgEnvDetails.agent} install failed to update ${pkgEnvDetails.lockName}`)
    };
  }
  spinner?.stop();
  if (wasSpinning) {
    spinner.start();
  }
  return {
    ok: true,
    data: undefined
  };
}

async function applyOptimization(pkgEnvDetails, {
  pin,
  prod
}) {
  const {
    spinner
  } = constants.default;
  spinner.start();
  const state = await addOverrides(pkgEnvDetails, pkgEnvDetails.pkgPath, {
    logger: logger.logger,
    pin,
    prod,
    spinner
  });
  const addedCount = state.added.size;
  const updatedCount = state.updated.size;
  const pkgJsonChanged = addedCount > 0 || updatedCount > 0;
  if (pkgJsonChanged || pkgEnvDetails.features.npmBuggyOverrides) {
    const result = await updateLockfile(pkgEnvDetails, {
      cmdName: CMD_NAME$p,
      logger: logger.logger,
      spinner
    });
    if (!result.ok) {
      spinner.stop();
      return result;
    }
  }
  spinner.stop();
  return {
    ok: true,
    data: {
      addedCount,
      addedInWorkspaces: state.addedInWorkspaces.size,
      pkgJsonChanged,
      updatedCount,
      updatedInWorkspaces: state.updatedInWorkspaces.size
    }
  };
}

async function outputOptimizeResult(result, outputKind) {
  if (!result.ok) {
    process.exitCode = result.code ?? 1;
  }
  if (outputKind === 'json') {
    logger.logger.log(utils.serializeResultJson(result));
    return;
  }
  if (!result.ok) {
    logger.logger.fail(utils.failMsgWithBadge(result.message, result.cause));
    return;
  }
  const data = result.data;
  if (data.updatedCount > 0) {
    logger.logger?.log(`${createActionMessage('Updated', data.updatedCount, data.updatedInWorkspaces)}${data.addedCount ? '.' : '🚀'}`);
  }
  if (data.addedCount > 0) {
    logger.logger?.log(`${createActionMessage('Added', data.addedCount, data.addedInWorkspaces)} 🚀`);
  }
  if (!data.pkgJsonChanged) {
    logger.logger?.log('Scan complete. No Socket.dev optimized overrides applied.');
  }
  logger.logger.log('');
  logger.logger.success('Finished!');
  logger.logger.log('');
}
function createActionMessage(verb, overrideCount, workspaceCount) {
  return `${verb} ${overrideCount} Socket.dev optimized ${words.pluralize('override', overrideCount)}${workspaceCount ? ` in ${workspaceCount} ${words.pluralize('workspace', workspaceCount)}` : ''}`;
}

const {
  VLT
} = constants.default;
async function handleOptimize({
  cwd,
  outputKind,
  pin,
  prod
}) {
  require$$9.debugFn('notice', `Starting optimization for ${cwd}`);
  require$$9.debugDir('inspect', {
    cwd,
    outputKind,
    pin,
    prod
  });
  const pkgEnvCResult = await utils.detectAndValidatePackageEnvironment(cwd, {
    cmdName: CMD_NAME$p,
    logger: logger.logger,
    prod
  });
  if (!pkgEnvCResult.ok) {
    process.exitCode = pkgEnvCResult.code ?? 1;
    require$$9.debugFn('warn', 'Package environment validation failed');
    require$$9.debugDir('inspect', {
      pkgEnvCResult
    });
    await outputOptimizeResult(pkgEnvCResult, outputKind);
    return;
  }
  const pkgEnvDetails = pkgEnvCResult.data;
  if (!pkgEnvDetails) {
    process.exitCode = 1;
    require$$9.debugFn('warn', 'No package environment details found');
    await outputOptimizeResult({
      ok: false,
      message: 'No package found.',
      cause: `No valid package environment found for project path: ${cwd}`
    }, outputKind);
    return;
  }
  require$$9.debugFn('notice', `Detected package manager: ${pkgEnvDetails.agent} v${pkgEnvDetails.agentVersion}`);
  require$$9.debugDir('inspect', {
    pkgEnvDetails
  });
  const {
    agent,
    agentVersion
  } = pkgEnvDetails;
  if (agent === VLT) {
    process.exitCode = 1;
    require$$9.debugFn('warn', `${agent} does not support overrides`);
    await outputOptimizeResult({
      ok: false,
      message: 'Unsupported',
      cause: utils.cmdPrefixMessage(CMD_NAME$p, `${agent} v${agentVersion} does not support overrides.`)
    }, outputKind);
    return;
  }
  logger.logger.info(`Optimizing packages for ${agent} v${agentVersion}.\n`);
  require$$9.debugFn('notice', 'Applying optimization');
  const optimizationResult = await applyOptimization(pkgEnvDetails, {
    pin,
    prod
  });
  if (!optimizationResult.ok) {
    process.exitCode = optimizationResult.code ?? 1;
  }
  require$$9.debugFn('notice', `Optimization ${optimizationResult.ok ? 'succeeded' : 'failed'}`);
  require$$9.debugDir('inspect', {
    optimizationResult
  });
  await outputOptimizeResult(optimizationResult, outputKind);
}

const CMD_NAME$o = 'optimize';
const description$u = 'Optimize dependencies with @socketregistry overrides';
const hidden$o = false;
const cmdOptimize = {
  description: description$u,
  hidden: hidden$o,
  run: run$u
};
async function run$u(argv, importMeta, {
  parentName
}) {
  const config = {
    commandName: CMD_NAME$o,
    description: description$u,
    hidden: hidden$o,
    flags: {
      ...flags.commonFlags,
      pin: {
        type: 'boolean',
        default: false,
        description: 'Pin overrides to latest version'
      },
      prod: {
        type: 'boolean',
        default: false,
        description: 'Add overrides for production dependencies only'
      }
    },
    help: (command, config) => `
    Usage
      $ ${command} [options] [CWD=.]

    API Token Requirements
      ${utils.getFlagApiRequirementsOutput(`${parentName}:${CMD_NAME$o}`)}

    Options
      ${utils.getFlagListOutput(config.flags)}

    Examples
      $ ${command}
      $ ${command} ./path/to/project --pin
  `
  };
  const cli = utils.meowOrExit({
    argv,
    config,
    importMeta,
    parentName
  });
  const dryRun = !!cli.flags['dryRun'];
  if (dryRun) {
    logger.logger.log(constants.default.DRY_RUN_BAILING_NOW);
    return;
  }
  const {
    json,
    markdown,
    pin,
    prod
  } = cli.flags;
  let [cwd = '.'] = cli.input;
  // Note: path.resolve vs .join:
  // If given path is absolute then cwd should not affect it.
  cwd = path.resolve(process.cwd(), cwd);
  const outputKind = utils.getOutputKind(json, markdown);
  await handleOptimize({
    cwd,
    pin: Boolean(pin),
    outputKind,
    prod: Boolean(prod)
  });
}

async function fetchDependencies(config, options) {
  const {
    sdkOpts
  } = {
    __proto__: null,
    ...options
  };
  const sockSdkCResult = await utils.setupSdk(sdkOpts);
  if (!sockSdkCResult.ok) {
    return sockSdkCResult;
  }
  const sockSdk = sockSdkCResult.data;
  const {
    limit,
    offset
  } = {
    __proto__: null,
    ...config
  };
  return await utils.handleApiCall(sockSdk.searchDependencies({
    limit,
    offset
  }), {
    description: 'organization dependencies'
  });
}

// @ts-ignore
async function outputDependencies(result, {
  limit,
  offset,
  outputKind
}) {
  if (!result.ok) {
    process.exitCode = result.code ?? 1;
  }
  if (outputKind === 'json') {
    logger.logger.log(utils.serializeResultJson(result));
    return;
  }
  if (!result.ok) {
    logger.logger.fail(utils.failMsgWithBadge(result.message, result.cause));
    return;
  }
  outputMarkdown(result.data, {
    limit,
    offset
  });
}
function outputMarkdown(result, {
  limit,
  offset
}) {
  logger.logger.log('# Organization dependencies');
  logger.logger.log('');
  logger.logger.log('Request details:');
  logger.logger.log('- Offset:', offset);
  logger.logger.log('- Limit:', limit);
  logger.logger.log('- Is there more data after this?', result.end ? 'no' : 'yes');
  logger.logger.log('');
  const options = {
    columns: [{
      field: 'type',
      name: vendor.yoctocolorsCjsExports.cyan('Ecosystem')
    }, {
      field: 'namespace',
      name: vendor.yoctocolorsCjsExports.cyan('Namespace')
    }, {
      field: 'name',
      name: vendor.yoctocolorsCjsExports.cyan('Name')
    }, {
      field: 'version',
      name: vendor.yoctocolorsCjsExports.cyan('Version')
    }, {
      field: 'repository',
      name: vendor.yoctocolorsCjsExports.cyan('Repository')
    }, {
      field: 'branch',
      name: vendor.yoctocolorsCjsExports.cyan('Branch')
    }, {
      field: 'direct',
      name: vendor.yoctocolorsCjsExports.cyan('Direct')
    }]
  };
  logger.logger.log(vendor.srcExports(options, result.rows));
}

async function handleDependencies({
  limit,
  offset,
  outputKind
}) {
  require$$9.debugFn('notice', `Fetching dependencies with limit=${limit}, offset=${offset}`);
  require$$9.debugDir('inspect', {
    limit,
    offset,
    outputKind
  });
  const result = await fetchDependencies({
    limit,
    offset
  });
  require$$9.debugFn('notice', `Dependencies ${result.ok ? 'fetched successfully' : 'fetch failed'}`);
  require$$9.debugDir('inspect', {
    result
  });
  await outputDependencies(result, {
    limit,
    offset,
    outputKind
  });
}

const CMD_NAME$n = 'dependencies';
const description$t = 'Search for any dependency that is being used in your organization';
const hidden$n = false;
const cmdOrganizationDependencies = {
  description: description$t,
  hidden: hidden$n,
  run: run$t
};
async function run$t(argv, importMeta, {
  parentName
}) {
  const config = {
    commandName: CMD_NAME$n,
    description: description$t,
    hidden: hidden$n,
    flags: {
      ...flags.commonFlags,
      limit: {
        type: 'number',
        default: 50,
        description: 'Maximum number of dependencies returned'
      },
      offset: {
        type: 'number',
        default: 0,
        description: 'Page number'
      },
      ...flags.outputFlags
    },
    help: (command, config) => `
    Usage
      ${command} [options]

    API Token Requirements
      ${utils.getFlagApiRequirementsOutput(`${parentName}:${CMD_NAME$n}`)}

    Options
      ${utils.getFlagListOutput(config.flags)}

    Examples
      ${command}
      ${command} --limit 20 --offset 10
  `
  };
  const cli = utils.meowOrExit({
    argv,
    config,
    parentName,
    importMeta
  });
  const {
    json,
    limit,
    markdown,
    offset
  } = cli.flags;
  const dryRun = !!cli.flags['dryRun'];
  const hasApiToken = utils.hasDefaultApiToken();
  const outputKind = utils.getOutputKind(json, markdown);
  const wasValidInput = utils.checkCommandInput(outputKind, {
    nook: true,
    test: !json || !markdown,
    message: `The \`${constants.FLAG_JSON}\` and \`${constants.FLAG_MARKDOWN}\` flags can not be used at the same time`,
    fail: 'bad'
  }, {
    nook: true,
    test: hasApiToken,
    message: 'This command requires a Socket API token for access',
    fail: 'try `socket login`'
  });
  if (!wasValidInput) {
    return;
  }
  if (dryRun) {
    logger.logger.log(constants.default.DRY_RUN_BAILING_NOW);
    return;
  }
  await handleDependencies({
    limit: Number(limit || 0) || 0,
    offset: Number(offset || 0) || 0,
    outputKind
  });
}

async function fetchLicensePolicy(orgSlug, options) {
  const {
    sdkOpts
  } = {
    __proto__: null,
    ...options
  };
  const sockSdkCResult = await utils.setupSdk(sdkOpts);
  if (!sockSdkCResult.ok) {
    return sockSdkCResult;
  }
  const sockSdk = sockSdkCResult.data;
  return await utils.handleApiCall(sockSdk.getOrgLicensePolicy(orgSlug), {
    description: 'organization license policy'
  });
}

async function outputLicensePolicy(result, outputKind) {
  if (!result.ok) {
    process.exitCode = result.code ?? 1;
  }
  if (outputKind === 'json') {
    logger.logger.log(utils.serializeResultJson(result));
    return;
  }
  if (!result.ok) {
    logger.logger.fail(utils.failMsgWithBadge(result.message, result.cause));
    return;
  }
  logger.logger.info('Use --json to get the full result');
  logger.logger.log('# License policy');
  logger.logger.log('');
  logger.logger.log('This is the license policy for your organization:');
  logger.logger.log('');
  const rules = result.data['license_policy'];
  const entries = rules ? Object.entries(rules) : [];
  const mapped = entries.map(({
    0: key,
    1: value
  }) => [key, value?.['allowed'] ? ' yes' : ' no']);
  mapped.sort(([a], [b]) => a < b ? -1 : a > b ? 1 : 0);
  logger.logger.log(utils.mdTableOfPairs(mapped, ['License Name', 'Allowed']));
  logger.logger.log('');
}

async function handleLicensePolicy(orgSlug, outputKind) {
  const data = await fetchLicensePolicy(orgSlug);
  await outputLicensePolicy(data, outputKind);
}

const CMD_NAME$m = 'license';
const description$s = 'Retrieve the license policy of an organization';
const hidden$m = false;
const cmdOrganizationPolicyLicense = {
  description: description$s,
  hidden: hidden$m,
  run: run$s
};
async function run$s(argv, importMeta, {
  parentName
}) {
  const config = {
    commandName: CMD_NAME$m,
    description: description$s,
    hidden: hidden$m,
    flags: {
      ...flags.commonFlags,
      ...flags.outputFlags,
      interactive: {
        type: 'boolean',
        default: true,
        description: 'Allow for interactive elements, asking for input. Use --no-interactive to prevent any input questions, defaulting them to cancel/no.'
      },
      org: {
        type: 'string',
        description: 'Force override the organization slug, overrides the default org from config'
      }
    },
    help: command => `
    Usage
      $ ${command} [options]

    API Token Requirements
      ${utils.getFlagApiRequirementsOutput(`${parentName}:${CMD_NAME$m}`)}

    Options
      ${utils.getFlagListOutput(config.flags)}

    Your API token will need the \`license-policy:read\` permission otherwise
    the request will fail with an authentication error.

    Examples
      $ ${command}
      $ ${command} --json
  `
  };
  const cli = utils.meowOrExit({
    argv,
    config,
    parentName,
    importMeta
  });
  const {
    json,
    markdown,
    org: orgFlag
  } = cli.flags;
  const dryRun = !!cli.flags['dryRun'];
  const interactive = !!cli.flags['interactive'];
  const hasApiToken = utils.hasDefaultApiToken();
  const {
    0: orgSlug
  } = await utils.determineOrgSlug(String(orgFlag || ''), interactive, dryRun);
  const outputKind = utils.getOutputKind(json, markdown);
  const wasValidInput = utils.checkCommandInput(outputKind, {
    nook: true,
    test: !json || !markdown,
    message: 'The json and markdown flags cannot be both set, pick one',
    fail: 'omit one'
  }, {
    nook: true,
    test: hasApiToken,
    message: 'This command requires a Socket API token for access',
    fail: 'try `socket login`'
  });
  if (!wasValidInput) {
    return;
  }
  if (dryRun) {
    logger.logger.log(constants.default.DRY_RUN_BAILING_NOW);
    return;
  }
  await handleLicensePolicy(orgSlug, outputKind);
}

async function fetchSecurityPolicy(orgSlug, options) {
  const {
    sdkOpts
  } = {
    __proto__: null,
    ...options
  };
  const sockSdkCResult = await utils.setupSdk(sdkOpts);
  if (!sockSdkCResult.ok) {
    return sockSdkCResult;
  }
  const sockSdk = sockSdkCResult.data;
  return await utils.handleApiCall(sockSdk.getOrgSecurityPolicy(orgSlug), {
    description: 'organization security policy'
  });
}

async function outputSecurityPolicy(result, outputKind) {
  if (!result.ok) {
    process.exitCode = result.code ?? 1;
  }
  if (outputKind === 'json') {
    logger.logger.log(utils.serializeResultJson(result));
    return;
  }
  if (!result.ok) {
    logger.logger.fail(utils.failMsgWithBadge(result.message, result.cause));
    return;
  }
  logger.logger.log('# Security policy');
  logger.logger.log('');
  logger.logger.log(`The default security policy setting is: "${result.data.securityPolicyDefault}"`);
  logger.logger.log('');
  logger.logger.log('These are the security policies per setting for your organization:');
  logger.logger.log('');
  const rules = result.data.securityPolicyRules;
  const entries = rules ? Object.entries(rules) : [];
  const mapped = entries.map(({
    0: key,
    1: value
  }) => [key, value.action]);
  mapped.sort(([a], [b]) => a < b ? -1 : a > b ? 1 : 0);
  logger.logger.log(utils.mdTableOfPairs(mapped, ['name', 'action']));
  logger.logger.log('');
}

async function handleSecurityPolicy(orgSlug, outputKind) {
  const data = await fetchSecurityPolicy(orgSlug);
  await outputSecurityPolicy(data, outputKind);
}

const CMD_NAME$l = 'security';
const description$r = 'Retrieve the security policy of an organization';
const hidden$l = true;
const cmdOrganizationPolicySecurity = {
  description: description$r,
  hidden: hidden$l,
  run: run$r
};
async function run$r(argv, importMeta, {
  parentName
}) {
  const config = {
    commandName: CMD_NAME$l,
    description: description$r,
    hidden: hidden$l,
    flags: {
      ...flags.commonFlags,
      ...flags.outputFlags,
      interactive: {
        type: 'boolean',
        default: true,
        description: 'Allow for interactive elements, asking for input. Use --no-interactive to prevent any input questions, defaulting them to cancel/no.'
      },
      org: {
        type: 'string',
        description: 'Force override the organization slug, overrides the default org from config'
      }
    },
    help: (command, _config) => `
    Usage
      $ ${command} [options]

    API Token Requirements
      ${utils.getFlagApiRequirementsOutput(`${parentName}:${CMD_NAME$l}`)}

    Options
      ${utils.getFlagListOutput(config.flags)}

    Your API token will need the \`security-policy:read\` permission otherwise
    the request will fail with an authentication error.

    Examples
      $ ${command}
      $ ${command} --json
  `
  };
  const cli = utils.meowOrExit({
    argv,
    config,
    parentName,
    importMeta
  });
  const {
    json,
    markdown,
    org: orgFlag
  } = cli.flags;
  const dryRun = !!cli.flags['dryRun'];
  const interactive = !!cli.flags['interactive'];
  const hasApiToken = utils.hasDefaultApiToken();
  const {
    0: orgSlug
  } = await utils.determineOrgSlug(String(orgFlag || ''), interactive, dryRun);
  const outputKind = utils.getOutputKind(json, markdown);
  const wasValidInput = utils.checkCommandInput(outputKind, {
    nook: true,
    test: !json || !markdown,
    message: 'The json and markdown flags cannot be both set, pick one',
    fail: 'omit one'
  }, {
    nook: true,
    test: hasApiToken,
    message: 'This command requires a Socket API token for access',
    fail: 'try `socket login`'
  });
  if (!wasValidInput) {
    return;
  }
  if (dryRun) {
    logger.logger.log(constants.default.DRY_RUN_BAILING_NOW);
    return;
  }
  await handleSecurityPolicy(orgSlug, outputKind);
}

async function outputOrganizationList(orgsCResult, outputKind = 'text') {
  if (!orgsCResult.ok) {
    process.exitCode = orgsCResult.code ?? 1;
  }
  if (outputKind === 'json') {
    logger.logger.log(utils.serializeResultJson(orgsCResult));
    return;
  }
  if (!orgsCResult.ok) {
    logger.logger.fail(utils.failMsgWithBadge(orgsCResult.message, orgsCResult.cause));
    return;
  }
  const {
    organizations
  } = orgsCResult.data;
  const visibleTokenPrefix = utils.getVisibleTokenPrefix();
  if (outputKind !== 'markdown') {
    logger.logger.log(`List of organizations associated with your API token, starting with: ${vendor.yoctocolorsCjsExports.italic(visibleTokenPrefix)}\n`);
    // Just dump.
    for (const o of organizations) {
      logger.logger.log(`- Name: ${vendor.yoctocolorsCjsExports.bold(o.name ?? 'undefined')}, ID: ${vendor.yoctocolorsCjsExports.bold(o.id)}, Plan: ${vendor.yoctocolorsCjsExports.bold(o.plan)}`);
    }
    return;
  }

  // | Syntax      | Description |
  // | ----------- | ----------- |
  // | Header      | Title       |
  // | Paragraph   | Text        |
  let mw1 = 4;
  let mw2 = 2;
  let mw3 = 4;
  for (const o of organizations) {
    mw1 = Math.max(mw1, o.name?.length ?? 0);
    mw2 = Math.max(mw2, o.id.length);
    mw3 = Math.max(mw3, o.plan.length);
  }
  logger.logger.log('# Organizations\n');
  logger.logger.log(`List of organizations associated with your API token, starting with: ${vendor.yoctocolorsCjsExports.italic(visibleTokenPrefix)}\n`);
  logger.logger.log(`| Name${' '.repeat(mw1 - 4)} | ID${' '.repeat(mw2 - 2)} | Plan${' '.repeat(mw3 - 4)} |`);
  logger.logger.log(`| ${'-'.repeat(mw1)} | ${'-'.repeat(mw2)} | ${'-'.repeat(mw3)} |`);
  for (const o of organizations) {
    logger.logger.log(`| ${(o.name || '').padEnd(mw1, ' ')} | ${(o.id || '').padEnd(mw2, ' ')} | ${(o.plan || '').padEnd(mw3, ' ')} |`);
  }
  logger.logger.log(`| ${'-'.repeat(mw1)} | ${'-'.repeat(mw2)} | ${'-'.repeat(mw3)} |`);
}

async function handleOrganizationList(outputKind = 'text') {
  require$$9.debugFn('notice', 'Fetching organization list');
  require$$9.debugDir('inspect', {
    outputKind
  });
  const data = await utils.fetchOrganization();
  require$$9.debugFn('notice', `Organization list ${data.ok ? 'fetched successfully' : 'fetch failed'}`);
  require$$9.debugDir('inspect', {
    data
  });
  await outputOrganizationList(data, outputKind);
}

const CMD_NAME$k = 'list';
const description$q = 'List organizations associated with the Socket API token';
const hidden$k = false;
const cmdOrganizationList = {
  description: description$q,
  hidden: hidden$k,
  run: run$q
};
async function run$q(argv, importMeta, {
  parentName
}) {
  const config = {
    commandName: CMD_NAME$k,
    description: description$q,
    hidden: hidden$k,
    flags: {
      ...flags.commonFlags,
      ...flags.outputFlags
    },
    help: (command, _config) => `
    Usage
      $ ${command} [options]

    API Token Requirements
      ${utils.getFlagApiRequirementsOutput(`${parentName}:${CMD_NAME$k}`)}

    Options
      ${utils.getFlagListOutput(config.flags)}

    Examples
      $ ${command}
      $ ${command} --json
  `
  };
  const cli = utils.meowOrExit({
    argv,
    config,
    parentName,
    importMeta
  });
  const {
    json,
    markdown
  } = cli.flags;
  const dryRun = !!cli.flags['dryRun'];
  const hasApiToken = utils.hasDefaultApiToken();
  const outputKind = utils.getOutputKind(json, markdown);
  const wasValidInput = utils.checkCommandInput(outputKind, {
    nook: true,
    test: !json || !markdown,
    message: `The \`${constants.FLAG_JSON}\` and \`${constants.FLAG_MARKDOWN}\` flags can not be used at the same time`,
    fail: 'bad'
  }, {
    nook: true,
    test: hasApiToken,
    message: 'This command requires a Socket API token for access',
    fail: 'try `socket login`'
  });
  if (!wasValidInput) {
    return;
  }
  if (dryRun) {
    logger.logger.log(constants.default.DRY_RUN_BAILING_NOW);
    return;
  }
  await handleOrganizationList(outputKind);
}

const description$p = 'Organization policy details';
const cmdOrganizationPolicy = {
  description: description$p,
  // Hidden because it was broken all this time (nobody could be using it)
  // and we're not sure if it's useful to anyone in its current state.
  // Until we do, we'll hide this to keep the help tidier.
  // And later, we may simply move this under `scan`, anyways.
  hidden: false,
  async run(argv, importMeta, {
    parentName
  }) {
    await utils.meowWithSubcommands({
      argv,
      name: `${parentName} policy`,
      importMeta,
      subcommands: {
        security: cmdOrganizationPolicySecurity,
        license: cmdOrganizationPolicyLicense
      }
    }, {
      description: description$p,
      defaultSub: 'list' // Backwards compat
    });
  }
};

async function fetchQuota(options) {
  const {
    sdkOpts
  } = {
    __proto__: null,
    ...options
  };
  const sockSdkCResult = await utils.setupSdk(sdkOpts);
  if (!sockSdkCResult.ok) {
    return sockSdkCResult;
  }
  const sockSdk = sockSdkCResult.data;
  return await utils.handleApiCall(sockSdk.getQuota(), {
    description: 'token quota'
  });
}

async function outputQuota(result, outputKind = 'text') {
  if (!result.ok) {
    process.exitCode = result.code ?? 1;
  }
  if (outputKind === 'json') {
    logger.logger.log(utils.serializeResultJson(result));
    return;
  }
  if (!result.ok) {
    logger.logger.fail(utils.failMsgWithBadge(result.message, result.cause));
    return;
  }
  if (outputKind === 'markdown') {
    logger.logger.log('# Quota');
    logger.logger.log('');
    logger.logger.log(`Quota left on the current API token: ${result.data.quota}`);
    logger.logger.log('');
    return;
  }
  logger.logger.log(`Quota left on the current API token: ${result.data.quota}`);
  logger.logger.log('');
}

async function handleQuota(outputKind = 'text') {
  const data = await fetchQuota();
  await outputQuota(data, outputKind);
}

const config$5 = {
  commandName: 'quota',
  description: 'List organizations associated with the Socket API token',
  hidden: true,
  flags: {
    ...flags.commonFlags,
    ...flags.outputFlags
  },
  help: (command, _config) => `
    Usage
      $ ${command} [options]

    Options
      ${utils.getFlagListOutput(config$5.flags)}

    Examples
      $ ${command}
      $ ${command} --json
  `
};
const cmdOrganizationQuota = {
  description: config$5.description,
  hidden: config$5.hidden,
  run: run$p
};
async function run$p(argv, importMeta, {
  parentName
}) {
  const cli = utils.meowOrExit({
    argv,
    config: config$5,
    parentName,
    importMeta
  });
  const dryRun = !!cli.flags['dryRun'];
  const json = Boolean(cli.flags['json']);
  const markdown = Boolean(cli.flags['markdown']);
  const hasApiToken = utils.hasDefaultApiToken();
  const outputKind = utils.getOutputKind(json, markdown);
  const wasValidInput = utils.checkCommandInput(outputKind, {
    nook: true,
    test: !json || !markdown,
    message: 'The json and markdown flags cannot be both set, pick one',
    fail: 'omit one'
  }, {
    nook: true,
    test: hasApiToken,
    message: 'This command requires a Socket API token for access',
    fail: 'try `socket login`'
  });
  if (!wasValidInput) {
    return;
  }
  if (dryRun) {
    logger.logger.log(constants.default.DRY_RUN_BAILING_NOW);
    return;
  }
  await handleQuota(outputKind);
}

const description$o = 'Manage Socket organization account details';
const cmdOrganization = {
  description: description$o,
  hidden: false,
  async run(argv, importMeta, {
    parentName
  }) {
    await utils.meowWithSubcommands({
      argv,
      name: `${parentName} organization`,
      importMeta,
      subcommands: {
        dependencies: cmdOrganizationDependencies,
        list: cmdOrganizationList,
        quota: cmdOrganizationQuota,
        policy: cmdOrganizationPolicy
      }
    }, {
      aliases: {
        deps: {
          description: cmdOrganizationDependencies.description,
          hidden: true,
          argv: ['dependencies']
        },
        license: {
          description: cmdOrganizationPolicyLicense.description,
          hidden: true,
          argv: ['policy', 'license']
        },
        security: {
          description: cmdOrganizationPolicySecurity.description,
          hidden: true,
          argv: ['policy', 'security']
        }
      },
      description: description$o
    });
  }
};

async function fetchPurlDeepScore(purl) {
  logger.logger.info(`Requesting deep score data for this purl: ${purl}`);
  return await utils.queryApiSafeJson(`purl/score/${encodeURIComponent(purl)}`, 'the deep package scores');
}

async function outputPurlsDeepScore(purl, result, outputKind) {
  if (!result.ok) {
    process.exitCode = result.code ?? 1;
  }
  if (outputKind === 'json') {
    logger.logger.log(utils.serializeResultJson(result));
    return;
  }
  if (!result.ok) {
    logger.logger.fail(utils.failMsgWithBadge(result.message, result.cause));
    return;
  }
  if (outputKind === 'markdown') {
    const md = createMarkdownReport(result.data);
    logger.logger.success(`Score report for "${result.data.purl}" ("${purl}"):\n`);
    logger.logger.log(md);
    return;
  }
  logger.logger.log(`Score report for "${purl}" (use --json for raw and --markdown for formatted reports):`);
  logger.logger.log(result.data);
  logger.logger.log('');
}
function createMarkdownReport(data) {
  const {
    self: {
      alerts: selfAlerts,
      capabilities: selfCaps,
      purl,
      score: selfScore
    },
    transitively: {
      alerts,
      capabilities,
      dependencyCount,
      func,
      lowest,
      score
    }
  } = data;
  const o = ['# Complete Package Score', ''];
  if (dependencyCount) {
    o.push(`This is a Socket report for the package *"${purl}"* and its *${dependencyCount}* direct/transitive dependencies.`);
  } else {
    o.push(`This is a Socket report for the package *"${purl}"*. It has *no dependencies*.`);
  }
  o.push('');
  if (dependencyCount) {
    o.push(`It will show you the shallow score for just the package itself and a deep score for all the transitives combined. Additionally you can see which capabilities were found and the top alerts as well as a package that was responsible for it.`);
  } else {
    o.push(`It will show you the shallow score for the package itself, which capabilities were found, and its top alerts.`);
    o.push('');
    o.push('Since it has no dependencies, the shallow score is also the deep score.');
  }
  o.push('');
  if (dependencyCount) {
    // This doesn't make much sense if there are no dependencies. Better to omit it.
    o.push('The report should give you a good insight into the status of this package.');
    o.push('');
    o.push('## Package itself');
    o.push('');
    o.push('Here are results for the package itself (excluding data from dependencies).');
  } else {
    o.push('## Report');
    o.push('');
    o.push('The report should give you a good insight into the status of this package.');
  }
  o.push('');
  o.push('### Shallow Score');
  o.push('');
  o.push('This score is just for the package itself:');
  o.push('');
  o.push(`- Overall: ${selfScore.overall}`);
  o.push(`- Maintenance: ${selfScore.maintenance}`);
  o.push(`- Quality: ${selfScore.quality}`);
  o.push(`- Supply Chain: ${selfScore.supplyChain}`);
  o.push(`- Vulnerability: ${selfScore.vulnerability}`);
  o.push(`- License: ${selfScore.license}`);
  o.push('');
  o.push('### Capabilities');
  o.push('');
  if (selfCaps.length) {
    o.push('These are the capabilities detected in the package itself:');
    o.push('');
    for (const cap of selfCaps) {
      o.push(`- ${cap}`);
    }
  } else {
    o.push('No capabilities were found in the package.');
  }
  o.push('');
  o.push('### Alerts for this package');
  o.push('');
  if (selfAlerts.length) {
    if (dependencyCount) {
      o.push('These are the alerts found for the package itself:');
    } else {
      o.push('These are the alerts found for this package:');
    }
    o.push('');
    o.push(utils.mdTable(selfAlerts, ['severity', 'name'], ['Severity', 'Alert Name']));
  } else {
    o.push('There are currently no alerts for this package.');
  }
  o.push('');
  if (dependencyCount) {
    o.push('## Transitive Package Results');
    o.push('');
    o.push('Here are results for the package and its direct/transitive dependencies.');
    o.push('');
    o.push('### Deep Score');
    o.push('');
    o.push('This score represents the package and and its direct/transitive dependencies:');
    o.push(`The function used to calculate the values in aggregate is: *"${func}"*`);
    o.push('');
    o.push(`- Overall: ${score.overall}`);
    o.push(`- Maintenance: ${score.maintenance}`);
    o.push(`- Quality: ${score.quality}`);
    o.push(`- Supply Chain: ${score.supplyChain}`);
    o.push(`- Vulnerability: ${score.vulnerability}`);
    o.push(`- License: ${score.license}`);
    o.push('');
    o.push('### Capabilities');
    o.push('');
    o.push('These are the packages with the lowest recorded score. If there is more than one with the lowest score, just one is shown here. This may help you figure out the source of low scores.');
    o.push('');
    o.push(`- Overall: ${lowest.overall}`);
    o.push(`- Maintenance: ${lowest.maintenance}`);
    o.push(`- Quality: ${lowest.quality}`);
    o.push(`- Supply Chain: ${lowest.supplyChain}`);
    o.push(`- Vulnerability: ${lowest.vulnerability}`);
    o.push(`- License: ${lowest.license}`);
    o.push('');
    o.push('### Capabilities');
    o.push('');
    if (capabilities.length) {
      o.push('These are the capabilities detected in at least one package:');
      o.push('');
      for (const cap of capabilities) {
        o.push(`- ${cap}`);
      }
    } else {
      o.push('This package had no capabilities and neither did any of its direct/transitive dependencies.');
    }
    o.push('');
    o.push('### Alerts');
    o.push('');
    if (alerts.length) {
      o.push('These are the alerts found:');
      o.push('');
      o.push(utils.mdTable(alerts, ['severity', 'name', 'example'], ['Severity', 'Alert Name', 'Example package reporting it']));
    } else {
      o.push('This package had no alerts and neither did any of its direct/transitive dependencies');
    }
    o.push('');
  }
  return o.join('\n');
}

async function handlePurlDeepScore(purl, outputKind) {
  require$$9.debugFn('notice', `Fetching deep score for ${purl}`);
  require$$9.debugDir('inspect', {
    purl,
    outputKind
  });
  const result = await fetchPurlDeepScore(purl);
  require$$9.debugFn('notice', `Deep score ${result.ok ? 'fetched successfully' : 'fetch failed'}`);
  require$$9.debugDir('inspect', {
    result
  });
  await outputPurlsDeepScore(purl, result, outputKind);
}

// Either an ecosystem was given or all args must be (namespaced) purls
// The `pkg:` part is optional here. We'll scan for `eco/name@version`.
// Not hardcoding the namespace since we don't know what the server accepts.
// The ecosystem is considered as the first package if it is not an a-z string.
function parsePackageSpecifiers(ecosystem, pkgs) {
  let valid = true;
  const purls = [];
  if (!ecosystem) {
    valid = false;
  } else if (/^[a-zA-Z]+$/.test(ecosystem)) {
    for (let i = 0; i < pkgs.length; ++i) {
      const pkg = pkgs[i] ?? '';
      if (!pkg) {
        valid = false;
        break;
      } else if (pkg.startsWith('pkg:')) {
        // keep
        purls.push(pkg);
      } else {
        purls.push('pkg:' + ecosystem + '/' + pkg);
      }
    }
    if (!purls.length) {
      valid = false;
    }
  } else {
    // Assume ecosystem is a purl, too.
    pkgs.unshift(ecosystem);
    for (let i = 0; i < pkgs.length; ++i) {
      const pkg = pkgs[i] ?? '';
      if (!/^(?:pkg:)?[a-zA-Z]+\/./.test(pkg)) {
        // At least one purl did not start with `pkg:eco/x` or `eco/x`.
        valid = false;
        break;
      } else if (pkg.startsWith('pkg:')) {
        purls.push(pkg);
      } else {
        purls.push('pkg:' + pkg);
      }
    }
    if (!purls.length) {
      valid = false;
    }
  }
  return {
    purls,
    valid
  };
}

const CMD_NAME$j = 'score';
const description$n = 'Look up score for one package which reflects all of its transitive dependencies as well';
const hidden$j = false;
const cmdPackageScore = {
  description: description$n,
  hidden: hidden$j,
  run: run$o
};
async function run$o(argv, importMeta, {
  parentName
}) {
  const config = {
    commandName: CMD_NAME$j,
    description: description$n,
    hidden: hidden$j,
    flags: {
      ...flags.commonFlags,
      ...flags.outputFlags
    },
    help: (command, config) => `
    Usage
      $ ${command} [options] <<ECOSYSTEM> <NAME> | <PURL>>

    API Token Requirements
      ${utils.getFlagApiRequirementsOutput(`${parentName}:${CMD_NAME$j}`)}

    Options
      ${utils.getFlagListOutput(config.flags)}

    Show deep scoring details for one package. The score will reflect the package
    itself, any of its dependencies, and any of its transitive dependencies.

    When you want to know whether to trust a package, this is the command to run.

    See also the \`socket package shallow\` command, which returns the shallow
    score for any number of packages. That will not reflect the dependency scores.

    Only a few ecosystems are supported like npm, pypi, nuget, gem, golang, and maven.

    A "purl" is a standard package name formatting: \`pkg:eco/name@version\`
    This command will automatically prepend "pkg:" when not present.

    The version is optional but when given should be a direct match. The \`pkg:\`
    prefix is optional.

    Note: if a package cannot be found it may be too old or perhaps was removed
          before we had the opportunity to process it.

    Examples
      $ ${command} npm babel-cli
      $ ${command} npm eslint@1.0.0 --json
      $ ${command} pkg:golang/github.com/steelpoor/tlsproxy@v0.0.0-20250304082521-29051ed19c60
      $ ${command} nuget/needpluscommonlibrary@1.0.0 --markdown
  `
  };
  const cli = utils.meowOrExit({
    argv,
    config,
    importMeta,
    parentName
  });
  const {
    json,
    markdown
  } = cli.flags;
  const dryRun = !!cli.flags['dryRun'];
  const [ecosystem = '', purl] = cli.input;
  const hasApiToken = utils.hasDefaultApiToken();
  const outputKind = utils.getOutputKind(json, markdown);
  const {
    purls,
    valid
  } = parsePackageSpecifiers(ecosystem, purl ? [purl] : []);
  const wasValidInput = utils.checkCommandInput(outputKind, {
    test: valid,
    message: 'First parameter must be an ecosystem or the whole purl',
    fail: 'bad'
  }, {
    test: purls.length === 1,
    message: 'Expecting at least one package',
    fail: purls.length === 0 ? 'missing' : 'too many'
  }, {
    nook: true,
    test: !json || !markdown,
    message: 'The json and markdown flags cannot be both set, pick one',
    fail: 'omit one'
  }, {
    nook: true,
    test: hasApiToken,
    message: 'This command requires a Socket API token for access',
    fail: 'try `socket login`'
  });
  if (!wasValidInput) {
    return;
  }
  if (dryRun) {
    logger.logger.log(constants.default.DRY_RUN_BAILING_NOW);
    return;
  }
  await handlePurlDeepScore(purls[0] || '', outputKind);
}

async function fetchPurlsShallowScore(purls, options) {
  const {
    sdkOpts
  } = {
    __proto__: null,
    ...options
  };
  const sockSdkCResult = await utils.setupSdk(sdkOpts);
  if (!sockSdkCResult.ok) {
    return sockSdkCResult;
  }
  const sockSdk = sockSdkCResult.data;
  logger.logger.info(`Requesting shallow score data for ${purls.length} package urls (purl): ${arrays.joinAnd(purls)}`);
  const batchPackageCResult = await utils.handleApiCall(sockSdk.batchPackageFetch({
    components: purls.map(purl => ({
      purl
    }))
  }, {
    alerts: 'true'
  }), {
    description: 'looking up package'
  });
  if (!batchPackageCResult.ok) {
    return batchPackageCResult;
  }

  // TODO: Seems like there's a bug in the typing since we absolutely have to
  // return the .data here.
  return {
    ok: true,
    data: batchPackageCResult.data
  };
}

// This is a simplified view of an artifact. Potentially merged with other artifacts.

function outputPurlsShallowScore(purls, result, outputKind) {
  if (!result.ok) {
    process.exitCode = result.code ?? 1;
  }
  if (outputKind === 'json') {
    logger.logger.log(utils.serializeResultJson(result));
    return;
  }
  if (!result.ok) {
    logger.logger.fail(utils.failMsgWithBadge(result.message, result.cause));
    return;
  }
  const {
    missing,
    rows
  } = preProcess(result.data, purls);
  if (outputKind === 'markdown') {
    const md = generateMarkdownReport(rows, missing);
    logger.logger.log(md);
    return;
  }
  const txt = generateTextReport(rows, missing);
  logger.logger.log(txt);
}
function formatReportCard(artifact, colorize) {
  const scoreResult = {
    'Supply Chain Risk': Math.floor((artifact.score?.supplyChain ?? 0) * 100),
    Maintenance: Math.floor((artifact.score?.maintenance ?? 0) * 100),
    Quality: Math.floor((artifact.score?.quality ?? 0) * 100),
    Vulnerabilities: Math.floor((artifact.score?.vulnerability ?? 0) * 100),
    License: Math.floor((artifact.score?.license ?? 0) * 100)
  };
  const alertString = getAlertString(artifact.alerts, {
    colorize
  });
  if (!artifact.ecosystem) {
    require$$9.debugFn('notice', 'miss: artifact ecosystem', artifact);
  }
  const purl = `pkg:${artifact.ecosystem}/${artifact.name}${artifact.version ? '@' + artifact.version : ''}`;

  // Calculate proper padding based on longest label.
  const maxLabelLength = Math.max(...Object.keys(scoreResult).map(label => label.length));
  const labelPadding = maxLabelLength + 2; // +2 for ": "

  return ['Package: ' + (colorize ? vendor.yoctocolorsCjsExports.bold(purl) : purl), '', ...Object.entries(scoreResult).map(score => `- ${score[0]}:`.padEnd(labelPadding, ' ') + `  ${formatScore(score[1], {
    colorize
  })}`), alertString].join('\n');
}
function formatScore(score, options) {
  const {
    colorize,
    padding = 3
  } = {
    __proto__: null,
    ...options
  };
  const padded = String(score).padStart(padding, ' ');
  if (!colorize) {
    return padded;
  }
  if (score >= 80) {
    return vendor.yoctocolorsCjsExports.green(padded);
  }
  if (score >= 60) {
    return vendor.yoctocolorsCjsExports.yellow(padded);
  }
  return vendor.yoctocolorsCjsExports.red(padded);
}
function getAlertString(alerts, options) {
  const {
    colorize
  } = {
    __proto__: null,
    ...options
  };
  if (!alerts.size) {
    return `- Alerts: ${colorize ? vendor.yoctocolorsCjsExports.green('none') : 'none'}!`;
  }
  const o = Array.from(alerts.values());
  const bad = o.filter(alert => alert.severity !== 'low' && alert.severity !== 'middle').sort((a, b) => a.type < b.type ? -1 : a.type > b.type ? 1 : 0);
  const mid = o.filter(alert => alert.severity === 'middle').sort((a, b) => a.type < b.type ? -1 : a.type > b.type ? 1 : 0);
  const low = o.filter(alert => alert.severity === 'low').sort((a, b) => a.type < b.type ? -1 : a.type > b.type ? 1 : 0);

  // We need to create the no-color string regardless because the actual string
  // contains a bunch of invisible ANSI chars which would screw up length checks.
  const colorless = `- Alerts (${bad.length}/${mid.length}/${low.length}):`;
  const padding = `  ${' '.repeat(Math.max(0, 20 - colorless.length))}`;
  if (colorize) {
    return `- Alerts (${vendor.yoctocolorsCjsExports.red(bad.length)}/${vendor.yoctocolorsCjsExports.yellow(mid.length)}/${low.length}):${padding}${arrays.joinAnd([...bad.map(a => vendor.yoctocolorsCjsExports.red(`${vendor.yoctocolorsCjsExports.dim(`[${a.severity}] `)}${a.type}`)), ...mid.map(a => vendor.yoctocolorsCjsExports.yellow(`${vendor.yoctocolorsCjsExports.dim(`[${a.severity}] `)}${a.type}`)), ...low.map(a => `${vendor.yoctocolorsCjsExports.dim(`[${a.severity}] `)}${a.type}`)])}`;
  }
  return `${colorless}${padding}${arrays.joinAnd([...bad.map(a => `[${a.severity}] ${a.type}`), ...mid.map(a => `[${a.severity}] ${a.type}`), ...low.map(a => `[${a.severity}] ${a.type}`)])}`;
}
function preProcess(artifacts, requestedPurls) {
  // Dedupe results (for example, PyPI will emit one package for each system release (win/mac/cpu) even if it's
  // the same package version with same results. The duplication is irrelevant and annoying to the user.

  // Make some effort to match the requested data with the response
  // Dedupe and merge results when only the .release value is different

  // API does not tell us which purls were not found.
  // Generate all purls to try so we can try to match search request.
  const purls = new Set();
  for (const data of artifacts) {
    purls.add(`pkg:${data.type}/${data.namespace ? `${data.namespace}/` : ''}${data.name}@${data.version}`);
    purls.add(`pkg:${data.type}/${data.name}@${data.version}`);
    purls.add(`pkg:${data.type}/${data.name}`);
    purls.add(`pkg:${data.type}/${data.namespace ? `${data.namespace}/` : ''}${data.name}`);
  }
  // Try to match the searched purls against this list
  const missing = requestedPurls.filter(purl => {
    if (purls.has(purl)) {
      return false;
    }
    if (purl.endsWith('@latest') && purls.has(purl.slice(0, -'@latest'.length))) {
      return false;
    }
    // Not found.
    return true;
  });

  // Create a unique set of rows which represents each artifact that is returned
  // while deduping when the artifact (main) meta data only differs due to the
  // .release field (observed with python, at least).
  // Merge the alerts for duped packages. Use lowest score between all of them.
  const rows = new Map();
  for (const artifact of artifacts) {
    const purl = `pkg:${artifact.type}/${artifact.namespace ? `${artifact.namespace}/` : ''}${artifact.name}${artifact.version ? `@${artifact.version}` : ''}`;
    if (rows.has(purl)) {
      const row = rows.get(purl);
      if (!row) {
        // Unreachable; Satisfy TS.
        continue;
      }
      if ((artifact.score?.supplyChain || 100) < row.score.supplyChain) {
        row.score.supplyChain = artifact.score?.supplyChain || 100;
      }
      if ((artifact.score?.maintenance || 100) < row.score.maintenance) {
        row.score.maintenance = artifact.score?.maintenance || 100;
      }
      if ((artifact.score?.quality || 100) < row.score.quality) {
        row.score.quality = artifact.score?.quality || 100;
      }
      if ((artifact.score?.vulnerability || 100) < row.score.vulnerability) {
        row.score.vulnerability = artifact.score?.vulnerability || 100;
      }
      if ((artifact.score?.license || 100) < row.score.license) {
        row.score.license = artifact.score?.license || 100;
      }
      artifact.alerts?.forEach(({
        severity,
        type
      }) => {
        row.alerts.set(`${type}:${severity}`, {
          type: type ?? 'unknown',
          severity: severity ?? 'none'
        });
      });
    } else {
      const alerts = new Map();
      artifact.alerts?.forEach(({
        severity,
        type
      }) => {
        alerts.set(`${type}:${severity}`, {
          type: type ?? 'unknown',
          severity: severity ?? 'none'
        });
      });
      rows.set(purl, {
        ecosystem: artifact.type,
        namespace: artifact.namespace || '',
        name: artifact.name,
        version: artifact.version || '',
        score: {
          supplyChain: artifact.score?.supplyChain || 100,
          maintenance: artifact.score?.maintenance || 100,
          quality: artifact.score?.quality || 100,
          vulnerability: artifact.score?.vulnerability || 100,
          license: artifact.score?.license || 100
        },
        alerts
      });
    }
  }
  return {
    rows,
    missing
  };
}
function generateMarkdownReport(artifacts, missing) {
  const blocks = [];
  const dupes = new Set();
  for (const artifact of artifacts.values()) {
    const block = `## ${formatReportCard(artifact, false)}`;
    if (dupes.has(block)) {
      // Omit duplicate blocks.
      continue;
    }
    dupes.add(block);
    blocks.push(block);
  }
  return `
# Shallow Package Report

This report contains the response for requesting data on some package url(s).

Please note: The listed scores are ONLY for the package itself. It does NOT
             reflect the scores of any dependencies, transitive or otherwise.

${missing.length ? `\n## Missing response\n\nAt least one package had no response or the purl was not canonical:\n\n${missing.map(purl => `- ${purl}\n`).join('')}` : ''}

${blocks.join('\n\n\n')}
    `.trim();
}
function generateTextReport(artifacts, missing) {
  const o = [];
  o.push(`\n${vendor.yoctocolorsCjsExports.bold('Shallow Package Score')}\n`);
  o.push('Please note: The listed scores are ONLY for the package itself. It does NOT\n' + '             reflect the scores of any dependencies, transitive or otherwise.');
  if (missing.length) {
    o.push(`\nAt least one package had no response or the purl was not canonical:\n${missing.map(purl => `\n- ${vendor.yoctocolorsCjsExports.bold(purl)}`).join('')}`);
  }
  const dupes = new Set();
  for (const artifact of artifacts.values()) {
    const block = formatReportCard(artifact, true);
    if (dupes.has(block)) {
      // Omit duplicate blocks.
      continue;
    }
    dupes.add(block);
    o.push('\n');
    o.push(block);
  }
  o.push('');
  return o.join('\n');
}

async function handlePurlsShallowScore({
  outputKind,
  purls
}) {
  require$$9.debugFn('notice', `Fetching shallow scores for ${purls.length} packages`);
  require$$9.debugDir('inspect', {
    purls,
    outputKind
  });
  const packageData = await fetchPurlsShallowScore(purls);
  require$$9.debugFn('notice', `Shallow scores ${packageData.ok ? 'fetched successfully' : 'fetch failed'}`);
  require$$9.debugDir('inspect', {
    packageData
  });
  outputPurlsShallowScore(purls, packageData, outputKind);
}

const CMD_NAME$i = 'shallow';
const description$m = 'Look up info regarding one or more packages but not their transitives';
const hidden$i = false;
const cmdPackageShallow = {
  description: description$m,
  hidden: hidden$i,
  alias: {
    shallowScore: {
      description: description$m,
      hidden: true,
      argv: []
    }
  },
  run: run$n
};
async function run$n(argv, importMeta, {
  parentName
}) {
  const config = {
    commandName: CMD_NAME$i,
    description: description$m,
    hidden: hidden$i,
    flags: {
      ...flags.commonFlags,
      ...flags.outputFlags
    },
    help: (command, config) => `
    Usage
      $ ${command} [options] <<ECOSYSTEM> <PKGNAME> [<PKGNAME> ...] | <PURL> [<PURL> ...]>

    API Token Requirements
      ${utils.getFlagApiRequirementsOutput(`${parentName}:${CMD_NAME$i}`)}

    Options
      ${utils.getFlagListOutput(config.flags)}

    Show scoring details for one or more packages purely based on their own package.
    This means that any dependency scores are not reflected by the score. You can
    use the \`socket package score <pkg>\` command to get its full transitive score.

    Only a few ecosystems are supported like npm, pypi, nuget, gem, golang, and maven.

    A "purl" is a standard package name formatting: \`pkg:eco/name@version\`
    This command will automatically prepend "pkg:" when not present.

    If the first arg is an ecosystem, remaining args that are not a purl are
    assumed to be scoped to that ecosystem. The \`pkg:\` prefix is optional.

    Note: if a package cannot be found, it may be too old or perhaps was removed
          before we had the opportunity to process it.

    Examples
      $ ${command} npm webtorrent
      $ ${command} npm webtorrent@1.9.1
      $ ${command} npm/webtorrent@1.9.1
      $ ${command} pkg:npm/webtorrent@1.9.1
      $ ${command} maven webtorrent babel
      $ ${command} npm/webtorrent golang/babel
      $ ${command} npm npm/webtorrent@1.0.1 babel
  `
  };
  const cli = utils.meowOrExit({
    argv,
    config,
    importMeta,
    parentName
  });
  const {
    json,
    markdown
  } = cli.flags;
  const dryRun = !!cli.flags['dryRun'];
  const [ecosystem = '', ...pkgs] = cli.input;
  const outputKind = utils.getOutputKind(json, markdown);
  const {
    purls,
    valid
  } = parsePackageSpecifiers(ecosystem, pkgs);
  const wasValidInput = utils.checkCommandInput(outputKind, {
    test: valid,
    message: 'First parameter should be an ecosystem or all args must be purls',
    fail: 'bad'
  }, {
    test: purls.length > 0,
    message: 'Expecting at least one package',
    fail: 'missing'
  }, {
    nook: true,
    test: !json || !markdown,
    message: 'The json and markdown flags cannot be both set, pick one',
    fail: 'omit one'
  });
  if (!wasValidInput) {
    return;
  }
  if (dryRun) {
    logger.logger.log(constants.default.DRY_RUN_BAILING_NOW);
    return;
  }
  await handlePurlsShallowScore({
    outputKind,
    purls
  });
}

const description$l = 'Look up published package details';
const cmdPackage = {
  description: description$l,
  hidden: false,
  async run(argv, importMeta, {
    parentName
  }) {
    await utils.meowWithSubcommands({
      argv,
      name: `${parentName} package`,
      importMeta,
      subcommands: {
        score: cmdPackageScore,
        shallow: cmdPackageShallow
      }
    }, {
      aliases: {
        deep: {
          description: description$l,
          hidden: true,
          argv: ['score']
        }
      },
      description: description$l
    });
  }
};

const PatchRecordSchema = vendor.object({
  exportedAt: vendor.string(),
  files: vendor.record(vendor.string(),
  // File path
  vendor.object({
    beforeHash: vendor.string(),
    afterHash: vendor.string()
  })),
  vulnerabilities: vendor.record(vendor.string(),
  // Vulnerability ID like "GHSA-jrhj-2j3q-xf3v"
  vendor.object({
    cves: vendor.array(vendor.string()),
    summary: vendor.string(),
    severity: vendor.string(),
    description: vendor.string(),
    patchExplanation: vendor.string()
  }))
});
const PatchManifestSchema = vendor.object({
  patches: vendor.record(
  // Package identifier like "npm:simplehttpserver@0.0.6".
  vendor.string(), PatchRecordSchema)
});

async function outputPatchResult(result, outputKind) {
  if (!result.ok) {
    process.exitCode = result.code ?? 1;
  }
  if (outputKind === constants.OUTPUT_JSON) {
    logger.logger.log(utils.serializeResultJson(result));
    return;
  }
  if (!result.ok) {
    logger.logger.fail(utils.failMsgWithBadge(result.message, result.cause));
    return;
  }
  const {
    patched
  } = result.data;
  logger.logger.log('');
  if (patched.length) {
    logger.logger.group(`Successfully processed patches for ${patched.length} ${words.pluralize('package', patched.length)}:`);
    for (const pkg of patched) {
      logger.logger.success(pkg);
    }
    logger.logger.groupEnd();
  } else {
    logger.logger.warn('No packages found requiring patches.');
  }
  logger.logger.log('');
  logger.logger.success('Patch command completed!');
}

async function applyNpmPatches(socketDir, patches, options) {
  const {
    cwd = process.cwd(),
    dryRun = false,
    purlObjs,
    spinner
  } = {
    __proto__: null,
    ...options
  };
  const wasSpinning = !!spinner?.isSpinning;
  spinner?.start();
  const patchLookup = new Map();
  for (const patchInfo of patches) {
    patchLookup.set(patchInfo.purl, patchInfo);
  }
  const nmPaths = await findNodeModulesPaths(cwd);
  spinner?.stop();
  logger.logger.log(`Found ${nmPaths.length} ${constants.NODE_MODULES} ${words.pluralize('folder', nmPaths.length)}`);
  logger.logger.group('');
  spinner?.start();
  const result = {
    passed: [],
    failed: []
  };
  for (const nmPath of nmPaths) {
    // eslint-disable-next-line no-await-in-loop
    const dirNames = await fs$2.readDirNames(nmPath);
    for (const dirName of dirNames) {
      const isScoped = dirName.startsWith('@');
      const pkgPath = path.join(nmPath, dirName);
      const pkgSubNames = isScoped ?
      // eslint-disable-next-line no-await-in-loop
      await fs$2.readDirNames(pkgPath) : [dirName];
      for (const pkgSubName of pkgSubNames) {
        const dirFullName = isScoped ? `${dirName}/${pkgSubName}` : pkgSubName;
        const pkgPath = path.join(nmPath, dirFullName);
        // eslint-disable-next-line no-await-in-loop
        const pkgJson = await packages.readPackageJson(pkgPath, {
          throws: false
        });
        if (!strings.isNonEmptyString(pkgJson?.name) || !strings.isNonEmptyString(pkgJson?.version)) {
          continue;
        }
        const purl = `pkg:npm/${pkgJson.name}@${pkgJson.version}`;
        const purlObj = utils.getPurlObject(purl, {
          throws: false
        });
        if (!purlObj) {
          continue;
        }

        // Skip if specific packages requested and this isn't one of them
        if (purlObjs?.length && purlObjs.findIndex(p => p.type === constants.NPM && p.namespace === purlObj.namespace && p.name === purlObj.name) === -1) {
          continue;
        }
        const patchInfo = patchLookup.get(purl);
        if (!patchInfo) {
          continue;
        }
        spinner?.stop();
        logger.logger.log(`Found match: ${pkgJson.name}@${pkgJson.version} at ${pkgPath}`);
        logger.logger.log(`Patch key: ${patchInfo.key}`);
        logger.logger.group(`Processing files:`);
        spinner?.start();
        let passed = true;
        for (const {
          0: fileName,
          1: fileInfo
        } of Object.entries(patchInfo.patch.files)) {
          // eslint-disable-next-line no-await-in-loop
          const filePatchPassed = await processFilePatch(pkgPath, fileName, fileInfo, socketDir, {
            dryRun,
            spinner
          });
          if (!filePatchPassed) {
            passed = false;
          }
        }
        logger.logger.groupEnd();
        if (passed) {
          result.passed.push(purl);
        } else {
          result.failed.push(purl);
        }
      }
    }
  }
  spinner?.stop();
  logger.logger.groupEnd();
  if (wasSpinning) {
    spinner.start();
  }
  return result;
}

/**
 * Compute SHA256 hash of file contents.
 */
async function computeSHA256(filepath) {
  try {
    const content = await fs$1.promises.readFile(filepath);
    const hash = require$$0$1.createHash('sha256');
    hash.update(content);
    return {
      ok: true,
      data: hash.digest('hex')
    };
  } catch (e) {
    return {
      ok: false,
      message: 'Failed to compute file hash',
      cause: `Unable to read file ${filepath}: ${utils.getErrorCause(e)}`
    };
  }
}
async function findNodeModulesPaths(cwd) {
  const rootNmPath = await utils.findUp(constants.NODE_MODULES, {
    cwd,
    onlyDirectories: true
  });
  if (!rootNmPath) {
    return [];
  }
  return await vendor.outExports.glob([`**/${constants.NODE_MODULES}`], {
    absolute: true,
    cwd: path.dirname(rootNmPath),
    dot: true,
    followSymbolicLinks: false,
    onlyDirectories: true
  });
}
async function processFilePatch(pkgPath, fileName, fileInfo, socketDir, options) {
  const {
    dryRun,
    spinner
  } = {
    __proto__: null,
    ...options
  };
  const wasSpinning = !!spinner?.isSpinning;
  spinner?.stop();
  const filepath = path.join(pkgPath, fileName);
  if (!fs$1.existsSync(filepath)) {
    logger.logger.log(`File not found: ${fileName}`);
    if (wasSpinning) {
      spinner?.start();
    }
    return false;
  }
  const currentHashResult = await computeSHA256(filepath);
  if (!currentHashResult.ok) {
    logger.logger.log(`Failed to compute hash for: ${fileName}: ${currentHashResult.cause || currentHashResult.message}`);
    if (wasSpinning) {
      spinner?.start();
    }
    return false;
  }
  if (currentHashResult.data === fileInfo.afterHash) {
    logger.logger.success(`File already patched: ${fileName}`);
    logger.logger.group();
    logger.logger.log(`Current hash: ${currentHashResult.data}`);
    logger.logger.groupEnd();
    if (wasSpinning) {
      spinner?.start();
    }
    return true;
  }
  if (currentHashResult.data !== fileInfo.beforeHash) {
    logger.logger.fail(`File hash mismatch: ${fileName}`);
    logger.logger.group();
    logger.logger.log(`Expected: ${fileInfo.beforeHash}`);
    logger.logger.log(`Current:  ${currentHashResult.data}`);
    logger.logger.log(`Target:   ${fileInfo.afterHash}`);
    logger.logger.groupEnd();
    if (wasSpinning) {
      spinner?.start();
    }
    return false;
  }
  logger.logger.success(`File matches expected hash: ${fileName}`);
  logger.logger.group();
  logger.logger.log(`Current hash: ${currentHashResult.data}`);
  logger.logger.log(`Ready to patch to: ${fileInfo.afterHash}`);
  logger.logger.group();
  if (dryRun) {
    logger.logger.log(`(dry run - no changes made)`);
    logger.logger.groupEnd();
    logger.logger.groupEnd();
    if (wasSpinning) {
      spinner?.start();
    }
    return false;
  }
  const blobPath = path.join(socketDir, 'blobs', fileInfo.afterHash);
  if (!fs$1.existsSync(blobPath)) {
    logger.logger.fail(`Error: Patch file not found at ${blobPath}`);
    logger.logger.groupEnd();
    logger.logger.groupEnd();
    if (wasSpinning) {
      spinner?.start();
    }
    return false;
  }
  spinner?.start();
  let result = true;
  try {
    await fs$1.promises.copyFile(blobPath, filepath);

    // Verify the hash after copying to ensure file integrity.
    const verifyHashResult = await computeSHA256(filepath);
    if (!verifyHashResult.ok) {
      logger.logger.error(`Failed to verify hash after patch: ${verifyHashResult.cause || verifyHashResult.message}`);
      result = false;
    } else if (verifyHashResult.data !== fileInfo.afterHash) {
      logger.logger.error(`Hash verification failed after patch`);
      logger.logger.group();
      logger.logger.log(`Expected: ${fileInfo.afterHash}`);
      logger.logger.log(`Got:      ${verifyHashResult.data}`);
      logger.logger.groupEnd();
      result = false;
    } else {
      logger.logger.success(`Patch applied successfully`);
    }
  } catch (e) {
    logger.logger.error('Error applying patch');
    require$$9.debugDir('error', e);
    result = false;
  }
  logger.logger.groupEnd();
  logger.logger.groupEnd();
  spinner?.stop();
  if (wasSpinning) {
    spinner?.start();
  }
  return result;
}
async function handlePatch({
  cwd,
  dryRun,
  outputKind,
  purlObjs,
  spinner
}) {
  try {
    const dotSocketDirPath = path.join(cwd, constants.DOT_SOCKET_DIR);
    const manifestPath = path.join(dotSocketDirPath, constants.MANIFEST_JSON);
    const manifestContent = await fs$1.promises.readFile(manifestPath, constants.UTF8);
    const manifestData = JSON.parse(manifestContent);
    const purls = purlObjs.map(String);
    const validated = PatchManifestSchema.parse(manifestData);

    // Parse PURLs and group by ecosystem.
    const patchesByEcosystem = new Map();
    for (const {
      0: key,
      1: patch
    } of Object.entries(validated.patches)) {
      const purl = utils.normalizePurl(key);
      if (purls.length && !purls.includes(purl)) {
        continue;
      }
      const purlObj = utils.getPurlObject(purl, {
        throws: false
      });
      if (!purlObj) {
        continue;
      }
      let patches = patchesByEcosystem.get(purlObj.type);
      if (!Array.isArray(patches)) {
        patches = [];
        patchesByEcosystem.set(purlObj.type, patches);
      }
      patches.push({
        key,
        patch,
        purl,
        purlObj
      });
    }
    if (purls.length) {
      spinner.start(`Checking patches for: ${arrays.joinAnd(purls)}`);
    } else {
      spinner.start('Scanning all dependencies for available patches');
    }
    const patched = [];
    const npmPatches = patchesByEcosystem.get(constants.NPM);
    if (npmPatches) {
      const patchingResults = await applyNpmPatches(dotSocketDirPath, npmPatches, {
        cwd,
        dryRun,
        purlObjs,
        spinner
      });
      patched.push(...patchingResults.passed);
    }
    spinner.stop();
    await outputPatchResult({
      ok: true,
      data: {
        patched
      }
    }, outputKind);
  } catch (e) {
    spinner.stop();
    let message = 'Failed to apply patches';
    let cause = utils.getErrorCause(e);
    if (e instanceof SyntaxError) {
      message = `Invalid JSON in ${constants.MANIFEST_JSON}`;
      cause = e.message;
    } else if (e instanceof Error && 'issues' in e) {
      message = 'Schema validation failed';
      cause = String(e);
    }
    await outputPatchResult({
      ok: false,
      code: 1,
      message,
      cause
    }, outputKind);
  }
}

const CMD_NAME$h = 'patch';
const description$k = 'Apply CVE patches to dependencies';
const hidden$h = true;
const cmdPatch = {
  description: description$k,
  hidden: hidden$h,
  run: run$m
};
async function run$m(argv, importMeta, {
  parentName
}) {
  const config = {
    commandName: CMD_NAME$h,
    description: description$k,
    hidden: hidden$h,
    flags: {
      ...flags.commonFlags,
      ...flags.outputFlags,
      purl: {
        type: 'string',
        default: [],
        description: 'Specify purls to patch, as either a comma separated value or as multiple flags',
        isMultiple: true,
        shortFlag: 'p'
      }
    },
    help: (command, config) => `
    Usage
      $ ${command} [options] [CWD=.]

    API Token Requirements
      ${utils.getFlagApiRequirementsOutput(`${parentName}:${CMD_NAME$h}`)}

    Options
      ${utils.getFlagListOutput(config.flags)}

    Examples
      $ ${command}
      $ ${command} --package lodash
      $ ${command} ./path/to/project --package lodash,react
    `
  };
  const cli = utils.meowOrExit({
    argv,
    config,
    parentName,
    importMeta
  }, {
    allowUnknownFlags: false
  });
  const {
    dryRun,
    json,
    markdown
  } = cli.flags;
  const outputKind = utils.getOutputKind(json, markdown);
  const wasValidInput = utils.checkCommandInput(outputKind, {
    nook: true,
    test: !json || !markdown,
    message: 'The json and markdown flags cannot be both set, pick one',
    fail: 'omit one'
  });
  if (!wasValidInput) {
    return;
  }
  let [cwd = '.'] = cli.input;
  // Note: path.resolve vs .join:
  // If given path is absolute then cwd should not affect it.
  cwd = path.resolve(process.cwd(), cwd);
  const dotSocketDirPath = path.join(cwd, constants.DOT_SOCKET_DIR);
  if (!fs$1.existsSync(dotSocketDirPath)) {
    throw new utils.InputError(`No ${constants.DOT_SOCKET_DIR} directory found in current directory`);
  }
  const manifestPath = path.join(dotSocketDirPath, constants.MANIFEST_JSON);
  if (!fs$1.existsSync(manifestPath)) {
    throw new utils.InputError(`No ${constants.MANIFEST_JSON} found in ${constants.DOT_SOCKET_DIR} directory`);
  }
  const {
    spinner
  } = constants.default;
  const purlObjs = arrays.arrayUnique(utils.cmdFlagValueToArray(cli.flags['purl'])).map(p => utils.getPurlObject(p, {
    throws: false
  })).filter(Boolean);
  await handlePatch({
    cwd,
    dryRun,
    outputKind,
    purlObjs,
    spinner
  });
}

const require$3 = require$$5.createRequire((typeof document === 'undefined' ? require$$0.pathToFileURL(__filename).href : (_documentCurrentScript && _documentCurrentScript.tagName.toUpperCase() === 'SCRIPT' && _documentCurrentScript.src || new URL('cli.js', document.baseURI).href)));
const CMD_NAME$g = constants.PNPM;
const description$j = 'Wraps pnpm with Socket security scanning';
const hidden$g = true;
const cmdPnpm = {
  description: description$j,
  hidden: hidden$g,
  run: run$l
};
async function run$l(argv, importMeta, context) {
  const {
    parentName
  } = {
    __proto__: null,
    ...context
  };
  const config = {
    commandName: CMD_NAME$g,
    description: description$j,
    hidden: hidden$g,
    flags: {
      ...flags.commonFlags
    },
    help: command => `
    Usage
      $ ${command} ...

    API Token Requirements
      ${utils.getFlagApiRequirementsOutput(`${parentName}:${CMD_NAME$g}`)}

    Note: Everything after "${constants.PNPM}" is passed to the ${constants.PNPM} command.
          Only the \`${constants.FLAG_DRY_RUN}\` and \`${constants.FLAG_HELP}\` flags are caught here.

    Use \`socket wrapper on\` to alias this command as \`${constants.PNPM}\`.

    Examples
      $ ${command}
      $ ${command} install
      $ ${command} add package-name
      $ ${command} dlx package-name
    `
  };
  const cli = utils.meowOrExit({
    argv,
    config,
    parentName,
    importMeta
  });
  const dryRun = !!cli.flags['dryRun'];
  if (dryRun) {
    logger.logger.log(constants.default.DRY_RUN_BAILING_NOW);
    return;
  }
  const shadowPnpmBin = /*@__PURE__*/require$3(constants.default.shadowPnpmBinPath);
  process.exitCode = 1;

  // Filter Socket flags from argv.
  const filteredArgv = utils.filterFlags(argv, config.flags);
  const {
    spawnPromise
  } = await shadowPnpmBin(filteredArgv, {
    stdio: 'inherit'
  });
  await spawnPromise;
  process.exitCode = 0;
}

async function runRawNpm(argv) {
  process.exitCode = 1;
  const spawnPromise = spawn.spawn(utils.getNpmBinPath(), argv, {
    // On Windows, npm is often a .cmd file that requires shell execution.
    // The spawn function from @socketsecurity/registry will handle this properly
    // when shell is true.
    shell: constants.default.WIN32,
    stdio: 'inherit'
  });

  // See https://nodejs.org/api/child_process.html#event-exit.
  spawnPromise.process.on('exit', (code, signalName) => {
    if (signalName) {
      process.kill(process.pid, signalName);
    } else if (typeof code === 'number') {
      // eslint-disable-next-line n/no-process-exit
      process.exit(code);
    }
  });
  await spawnPromise;
}

const config$4 = {
  commandName: 'raw-npm',
  description: 'Run npm without the Socket wrapper',
  hidden: false,
  flags: {
    ...flags.commonFlags
  },
  help: command => `
    Usage
      $ ${command} ...

    Execute \`npm\` without gating installs through the Socket API.
    Useful when  \`socket wrapper on\` is enabled and you want to bypass
    the Socket wrapper. Use at your own risk.

    Note: Everything after "raw-npm" is passed to the npm command.
          Only the \`${constants.FLAG_DRY_RUN}\` and \`${constants.FLAG_HELP}\` flags are caught here.

    Examples
      $ ${command} install -g cowsay
  `
};
const cmdRawNpm = {
  description: config$4.description,
  hidden: config$4.hidden,
  run: run$k
};
async function run$k(argv, importMeta, {
  parentName
}) {
  const cli = utils.meowOrExit({
    argv,
    config: config$4,
    parentName,
    importMeta
  });
  const dryRun = !!cli.flags['dryRun'];
  if (dryRun) {
    logger.logger.log(constants.default.DRY_RUN_BAILING_NOW);
    return;
  }
  await runRawNpm(argv);
}

async function runRawNpx(argv) {
  process.exitCode = 1;
  const spawnPromise = spawn.spawn(utils.getNpxBinPath(), argv, {
    // On Windows, npx is often a .cmd file that requires shell execution.
    // The spawn function from @socketsecurity/registry will handle this properly
    // when shell is true.
    shell: constants.default.WIN32,
    stdio: 'inherit'
  });

  // See https://nodejs.org/api/child_process.html#event-exit.
  spawnPromise.process.on('exit', (code, signalName) => {
    if (signalName) {
      process.kill(process.pid, signalName);
    } else if (typeof code === 'number') {
      // eslint-disable-next-line n/no-process-exit
      process.exit(code);
    }
  });
  await spawnPromise;
}

const config$3 = {
  commandName: 'raw-npx',
  description: 'Run npx without the Socket wrapper',
  hidden: false,
  flags: {
    ...flags.commonFlags
  },
  help: command => `
    Usage
      $ ${command} ...

    Execute \`npx\` without gating installs through the Socket API.
    Useful when  \`socket wrapper on\` is enabled and you want to bypass
    the Socket wrapper. Use at your own risk.

    Note: Everything after "raw-npx" is passed to the npx command.
          Only the \`${constants.FLAG_DRY_RUN}\` and \`${constants.FLAG_HELP}\` flags are caught here.

    Examples
      $ ${command} cowsay
  `
};
const cmdRawNpx = {
  description: config$3.description,
  hidden: config$3.hidden,
  run: run$j
};
async function run$j(argv, importMeta, {
  parentName
}) {
  const cli = utils.meowOrExit({
    argv,
    config: config$3,
    parentName,
    importMeta
  });
  const dryRun = !!cli.flags['dryRun'];
  if (dryRun) {
    logger.logger.log(constants.default.DRY_RUN_BAILING_NOW);
    return;
  }
  await runRawNpx(argv);
}

async function fetchCreateRepo(config, options) {
  const {
    defaultBranch,
    description,
    homepage,
    orgSlug,
    repoName,
    visibility
  } = config;
  const {
    sdkOpts
  } = {
    __proto__: null,
    ...options
  };
  const sockSdkCResult = await utils.setupSdk(sdkOpts);
  if (!sockSdkCResult.ok) {
    return sockSdkCResult;
  }
  const sockSdk = sockSdkCResult.data;
  return await utils.handleApiCall(sockSdk.createOrgRepo(orgSlug, {
    default_branch: defaultBranch,
    description,
    homepage,
    name: repoName,
    visibility
  }), {
    description: 'to create a repository'
  });
}

function outputCreateRepo(result, requestedName, outputKind) {
  if (!result.ok) {
    process.exitCode = result.code ?? 1;
  }
  if (outputKind === 'json') {
    logger.logger.log(utils.serializeResultJson(result));
    return;
  }
  if (!result.ok) {
    logger.logger.fail(utils.failMsgWithBadge(result.message, result.cause));
    return;
  }
  const {
    slug
  } = result.data;
  logger.logger.success(`OK. Repository created successfully, slug: \`${slug}\`${slug !== requestedName ? ' (Warning: slug is not the same as name that was requested!)' : ''}`);
}

async function handleCreateRepo({
  defaultBranch,
  description,
  homepage,
  orgSlug,
  repoName,
  visibility
}, outputKind) {
  require$$9.debugFn('notice', `Creating repository ${orgSlug}/${repoName}`);
  require$$9.debugDir('inspect', {
    defaultBranch,
    description,
    homepage,
    orgSlug,
    repoName,
    visibility,
    outputKind
  });
  const data = await fetchCreateRepo({
    defaultBranch,
    description,
    homepage,
    orgSlug,
    repoName,
    visibility
  });
  require$$9.debugFn('notice', `Repository creation ${data.ok ? 'succeeded' : 'failed'}`);
  require$$9.debugDir('inspect', {
    data
  });
  outputCreateRepo(data, repoName, outputKind);
}

const CMD_NAME$f = 'create';
const description$i = 'Create a repository in an organization';
const hidden$f = false;
const cmdRepositoryCreate = {
  description: description$i,
  hidden: hidden$f,
  run: run$i
};
async function run$i(argv, importMeta, {
  parentName
}) {
  const config = {
    commandName: CMD_NAME$f,
    description: description$i,
    hidden: hidden$f,
    flags: {
      ...flags.commonFlags,
      ...flags.outputFlags,
      defaultBranch: {
        type: 'string',
        default: 'main',
        description: 'Repository default branch. Defaults to "main"'
      },
      homepage: {
        type: 'string',
        default: '',
        description: 'Repository url'
      },
      interactive: {
        type: 'boolean',
        default: true,
        description: 'Allow for interactive elements, asking for input. Use --no-interactive to prevent any input questions, defaulting them to cancel/no.'
      },
      org: {
        type: 'string',
        description: 'Force override the organization slug, overrides the default org from config'
      },
      repoDescription: {
        type: 'string',
        default: '',
        description: 'Repository description'
      },
      visibility: {
        type: 'string',
        default: 'private',
        description: 'Repository visibility (Default Private)'
      }
    },
    help: (command, config) => `
    Usage
      $ ${command} [options] <REPO>

    API Token Requirements
      ${utils.getFlagApiRequirementsOutput(`${parentName}:${CMD_NAME$f}`)}

    The REPO name should be a "slug". Follows the same naming convention as GitHub.

    Options
      ${utils.getFlagListOutput(config.flags)}

    Examples
      $ ${command} test-repo
      $ ${command} our-repo --homepage=socket.dev --default-branch=trunk
  `
  };
  const cli = utils.meowOrExit({
    argv,
    config,
    parentName,
    importMeta
  });
  const {
    json,
    markdown,
    org: orgFlag
  } = cli.flags;
  const dryRun = !!cli.flags['dryRun'];
  const interactive = !!cli.flags['interactive'];
  const noLegacy = !cli.flags['repoName'];
  const [repoName = ''] = cli.input;
  const hasApiToken = utils.hasDefaultApiToken();
  const {
    0: orgSlug
  } = await utils.determineOrgSlug(String(orgFlag || ''), interactive, dryRun);
  const outputKind = utils.getOutputKind(json, markdown);
  const wasValidInput = utils.checkCommandInput(outputKind, {
    nook: true,
    test: !!orgSlug,
    message: 'Org name by default setting, --org, or auto-discovered',
    fail: 'missing'
  }, {
    nook: true,
    test: noLegacy,
    message: `Legacy flags are no longer supported. See the ${utils.webLink(constants.V1_MIGRATION_GUIDE_URL, 'v1 migration guide')}.`,
    fail: `received legacy flags`
  }, {
    test: !!repoName,
    message: 'Repository name as first argument',
    fail: 'missing'
  }, {
    nook: true,
    test: hasApiToken,
    message: 'This command requires a Socket API token for access',
    fail: 'try `socket login`'
  });
  if (!wasValidInput) {
    return;
  }
  if (dryRun) {
    logger.logger.log(constants.default.DRY_RUN_BAILING_NOW);
    return;
  }
  await handleCreateRepo({
    orgSlug,
    repoName: String(repoName),
    description: String(cli.flags['repoDescription'] || ''),
    homepage: String(cli.flags['homepage'] || ''),
    defaultBranch: String(cli.flags['defaultBranch'] || ''),
    visibility: String(cli.flags['visibility'] || 'private')
  }, outputKind);
}

async function fetchDeleteRepo(orgSlug, repoName, options) {
  const {
    sdkOpts
  } = {
    __proto__: null,
    ...options
  };
  const sockSdkCResult = await utils.setupSdk(sdkOpts);
  if (!sockSdkCResult.ok) {
    return sockSdkCResult;
  }
  const sockSdk = sockSdkCResult.data;
  return await utils.handleApiCall(sockSdk.deleteOrgRepo(orgSlug, repoName), {
    description: 'to delete a repository'
  });
}

async function outputDeleteRepo(result, repoName, outputKind) {
  if (!result.ok) {
    process.exitCode = result.code ?? 1;
  }
  if (outputKind === 'json') {
    logger.logger.log(utils.serializeResultJson(result));
    return;
  }
  if (!result.ok) {
    logger.logger.fail(utils.failMsgWithBadge(result.message, result.cause));
    return;
  }
  logger.logger.success(`OK. Repository \`${repoName}\` deleted successfully`);
}

async function handleDeleteRepo(orgSlug, repoName, outputKind) {
  const data = await fetchDeleteRepo(orgSlug, repoName);
  await outputDeleteRepo(data, repoName, outputKind);
}

const CMD_NAME$e = 'del';
const description$h = 'Delete a repository in an organization';
const hidden$e = false;
const cmdRepositoryDel = {
  description: description$h,
  hidden: hidden$e,
  run: run$h
};
async function run$h(argv, importMeta, {
  parentName
}) {
  const config = {
    commandName: CMD_NAME$e,
    description: description$h,
    hidden: hidden$e,
    flags: {
      ...flags.commonFlags,
      ...flags.outputFlags,
      interactive: {
        type: 'boolean',
        default: true,
        description: 'Allow for interactive elements, asking for input. Use --no-interactive to prevent any input questions, defaulting them to cancel/no.'
      },
      org: {
        type: 'string',
        description: 'Force override the organization slug, overrides the default org from config'
      }
    },
    help: (command, config) => `
    Usage
      $ ${command} [options] <REPO>

    API Token Requirements
      ${utils.getFlagApiRequirementsOutput(`${parentName}:${CMD_NAME$e}`)}

    Options
      ${utils.getFlagListOutput(config.flags)}

    Examples
      $ ${command} test-repo
  `
  };
  const cli = utils.meowOrExit({
    argv,
    config,
    parentName,
    importMeta
  });
  const {
    json,
    markdown,
    org: orgFlag
  } = cli.flags;
  const dryRun = !!cli.flags['dryRun'];
  const interactive = !!cli.flags['interactive'];
  const noLegacy = !cli.flags['repoName'];
  const [repoName = ''] = cli.input;
  const hasApiToken = utils.hasDefaultApiToken();
  const {
    0: orgSlug
  } = await utils.determineOrgSlug(String(orgFlag || ''), interactive, dryRun);
  const outputKind = utils.getOutputKind(json, markdown);
  const wasValidInput = utils.checkCommandInput(outputKind, {
    nook: true,
    test: noLegacy,
    message: `Legacy flags are no longer supported. See the ${utils.webLink(constants.V1_MIGRATION_GUIDE_URL, 'v1 migration guide')}.`,
    fail: `received legacy flags`
  }, {
    nook: true,
    test: !!orgSlug,
    message: 'Org name by default setting, --org, or auto-discovered',
    fail: 'missing'
  }, {
    test: !!repoName,
    message: 'Repository name as first argument',
    fail: 'missing'
  }, {
    nook: true,
    test: hasApiToken,
    message: 'This command requires a Socket API token for access',
    fail: 'try `socket login`'
  });
  if (!wasValidInput) {
    return;
  }
  if (dryRun) {
    logger.logger.log(constants.default.DRY_RUN_BAILING_NOW);
    return;
  }
  await handleDeleteRepo(orgSlug, repoName, outputKind);
}

async function fetchListAllRepos(orgSlug, options) {
  const {
    direction,
    sdkOpts,
    sort
  } = {
    __proto__: null,
    ...options
  };
  const sockSdkCResult = await utils.setupSdk(sdkOpts);
  if (!sockSdkCResult.ok) {
    return sockSdkCResult;
  }
  const sockSdk = sockSdkCResult.data;
  const rows = [];
  let protection = 0;
  let nextPage = 0;
  while (nextPage >= 0) {
    if (++protection > 100) {
      return {
        ok: false,
        message: 'Infinite loop detected',
        cause: `Either there are over 100 pages of results or the fetch has run into an infinite loop. Breaking it off now. nextPage=${nextPage}`
      };
    }
    // eslint-disable-next-line no-await-in-loop
    const orgRepoListCResult = await utils.handleApiCall(sockSdk.getOrgRepoList(orgSlug, {
      sort,
      direction,
      per_page: String(100),
      // max
      page: String(nextPage)
    }), {
      description: 'list of repositories'
    });
    if (!orgRepoListCResult.ok) {
      return orgRepoListCResult;
    }
    rows.push(...orgRepoListCResult.data.results);
    nextPage = orgRepoListCResult.data.nextPage ?? -1;
  }
  return {
    ok: true,
    data: {
      results: rows,
      nextPage: null
    }
  };
}

async function fetchListRepos(config, options) {
  const {
    direction,
    orgSlug,
    page,
    perPage,
    sort
  } = {
    __proto__: null,
    ...config
  };
  const {
    sdkOpts
  } = {
    __proto__: null,
    ...options
  };
  const sockSdkCResult = await utils.setupSdk(sdkOpts);
  if (!sockSdkCResult.ok) {
    return sockSdkCResult;
  }
  const sockSdk = sockSdkCResult.data;
  return await utils.handleApiCall(sockSdk.getOrgRepoList(orgSlug, {
    sort,
    direction,
    per_page: String(perPage),
    page: String(page)
  }), {
    description: 'list of repositories'
  });
}

// @ts-ignore
async function outputListRepos(result, outputKind, page, nextPage, sort, perPage, direction) {
  if (!result.ok) {
    process.exitCode = result.code ?? 1;
  }
  if (outputKind === 'json') {
    if (result.ok) {
      logger.logger.log(utils.serializeResultJson({
        ok: true,
        data: {
          data: result.data,
          direction,
          nextPage: nextPage ?? 0,
          page,
          perPage,
          sort
        }
      }));
    } else {
      logger.logger.log(utils.serializeResultJson(result));
    }
    return;
  }
  if (!result.ok) {
    logger.logger.fail(utils.failMsgWithBadge(result.message, result.cause));
    return;
  }
  logger.logger.log(`Result page: ${page}, results per page: ${perPage === Infinity ? 'all' : perPage}, sorted by: ${sort}, direction: ${direction}`);
  const options = {
    columns: [{
      field: 'id',
      name: vendor.yoctocolorsCjsExports.magenta('ID')
    }, {
      field: 'name',
      name: vendor.yoctocolorsCjsExports.magenta('Name')
    }, {
      field: 'visibility',
      name: vendor.yoctocolorsCjsExports.magenta('Visibility')
    }, {
      field: 'default_branch',
      name: vendor.yoctocolorsCjsExports.magenta('Default branch')
    }, {
      field: 'archived',
      name: vendor.yoctocolorsCjsExports.magenta('Archived')
    }]
  };
  logger.logger.log(vendor.srcExports(options, result.data.results));
  if (nextPage) {
    logger.logger.info(`This is page ${page}. Server indicated there are more results available on page ${nextPage}...`);
    logger.logger.info(`(Hint: you can use \`socket repository list --page ${nextPage}\`)`);
  } else if (perPage === Infinity) {
    logger.logger.info(`This should be the entire list available on the server.`);
  } else {
    logger.logger.info(`This is page ${page}. Server indicated this is the last page with results.`);
  }
}

async function handleListRepos({
  all,
  direction,
  orgSlug,
  outputKind,
  page,
  perPage,
  sort
}) {
  if (all) {
    const data = await fetchListAllRepos(orgSlug, {
      direction,
      sort
    });
    await outputListRepos(data, outputKind, 0, 0, sort, Infinity, direction);
  } else {
    const data = await fetchListRepos({
      direction,
      orgSlug,
      page,
      perPage,
      sort
    });
    if (!data.ok) {
      await outputListRepos(data, outputKind, 0, 0, '', 0, direction);
    } else {
      // Note: nextPage defaults to 0, is null when there's no next page
      await outputListRepos(data, outputKind, page, data.data.nextPage, sort, perPage, direction);
    }
  }
}

const CMD_NAME$d = 'list';
const description$g = 'List repositories in an organization';
const hidden$d = false;
const cmdRepositoryList = {
  description: description$g,
  hidden: hidden$d,
  run: run$g
};
async function run$g(argv, importMeta, {
  parentName
}) {
  const config = {
    commandName: CMD_NAME$d,
    description: description$g,
    hidden: hidden$d,
    flags: {
      ...flags.commonFlags,
      ...flags.outputFlags,
      all: {
        type: 'boolean',
        default: false,
        description: 'By default view shows the last n repos. This flag allows you to fetch the entire list. Will ignore --page and --per-page.'
      },
      direction: {
        type: 'string',
        default: 'desc',
        description: 'Direction option'
      },
      interactive: {
        type: 'boolean',
        default: true,
        description: 'Allow for interactive elements, asking for input. Use --no-interactive to prevent any input questions, defaulting them to cancel/no.'
      },
      org: {
        type: 'string',
        default: '',
        description: 'Force override the organization slug, overrides the default org from config'
      },
      perPage: {
        type: 'number',
        default: 30,
        description: 'Number of results per page',
        shortFlag: 'pp'
      },
      page: {
        type: 'number',
        default: 1,
        description: 'Page number',
        shortFlag: 'p'
      },
      sort: {
        type: 'string',
        default: 'created_at',
        description: 'Sorting option',
        shortFlag: 's'
      }
    },
    help: (command, config) => `
    Usage
      $ ${command} [options]

    API Token Requirements
      ${utils.getFlagApiRequirementsOutput(`${parentName}:${CMD_NAME$d}`)}

    Options
      ${utils.getFlagListOutput(config.flags)}

    Examples
      $ ${command}
      $ ${command} --json
  `
  };
  const cli = utils.meowOrExit({
    argv,
    config,
    parentName,
    importMeta
  });
  const {
    all,
    direction = 'desc',
    dryRun,
    interactive,
    json,
    markdown,
    org: orgFlag,
    page,
    perPage,
    sort
  } = cli.flags;
  const hasApiToken = utils.hasDefaultApiToken();
  const {
    0: orgSlug
  } = await utils.determineOrgSlug(orgFlag, interactive, dryRun);
  const outputKind = utils.getOutputKind(json, markdown);
  const wasValidInput = utils.checkCommandInput(outputKind, {
    nook: true,
    test: !!orgSlug,
    message: 'Org name by default setting, --org, or auto-discovered',
    fail: 'missing'
  }, {
    nook: true,
    test: !json || !markdown,
    message: `The \`${constants.FLAG_JSON}\` and \`${constants.FLAG_MARKDOWN}\` flags can not be used at the same time`,
    fail: 'bad'
  }, {
    nook: true,
    test: hasApiToken,
    message: 'This command requires a Socket API token for access',
    fail: 'try `socket login`'
  }, {
    nook: true,
    test: direction === 'asc' || direction === 'desc',
    message: 'The --direction value must be "asc" or "desc"',
    fail: 'unexpected value'
  });
  if (!wasValidInput) {
    return;
  }
  if (dryRun) {
    logger.logger.log(constants.default.DRY_RUN_BAILING_NOW);
    return;
  }
  await handleListRepos({
    all,
    direction,
    orgSlug,
    outputKind,
    page,
    perPage,
    sort
  });
}

async function fetchUpdateRepo(config, options) {
  const {
    defaultBranch,
    description,
    homepage,
    orgSlug,
    repoName,
    visibility
  } = {
    __proto__: null,
    ...config
  };
  const {
    sdkOpts
  } = {
    __proto__: null,
    ...options
  };
  const sockSdkCResult = await utils.setupSdk(sdkOpts);
  if (!sockSdkCResult.ok) {
    return sockSdkCResult;
  }
  const sockSdk = sockSdkCResult.data;
  return await utils.handleApiCall(sockSdk.updateOrgRepo(orgSlug, repoName, {
    default_branch: defaultBranch,
    description,
    homepage,
    name: repoName,
    orgSlug,
    visibility
  }), {
    description: 'to update a repository'
  });
}

async function outputUpdateRepo(result, repoName, outputKind) {
  if (!result.ok) {
    process.exitCode = result.code ?? 1;
  }
  if (outputKind === 'json') {
    logger.logger.log(utils.serializeResultJson(result));
    return;
  }
  if (!result.ok) {
    logger.logger.fail(utils.failMsgWithBadge(result.message, result.cause));
    return;
  }
  logger.logger.success(`Repository \`${repoName}\` updated successfully`);
}

async function handleUpdateRepo({
  defaultBranch,
  description,
  homepage,
  orgSlug,
  repoName,
  visibility
}, outputKind) {
  const data = await fetchUpdateRepo({
    defaultBranch,
    description,
    homepage,
    orgSlug,
    repoName,
    visibility
  });
  await outputUpdateRepo(data, repoName, outputKind);
}

const CMD_NAME$c = 'update';
const description$f = 'Update a repository in an organization';
const hidden$c = false;
const cmdRepositoryUpdate = {
  description: description$f,
  hidden: hidden$c,
  run: run$f
};
async function run$f(argv, importMeta, {
  parentName
}) {
  const config = {
    commandName: CMD_NAME$c,
    description: description$f,
    hidden: hidden$c,
    flags: {
      ...flags.commonFlags,
      ...flags.outputFlags,
      defaultBranch: {
        type: 'string',
        shortFlag: 'b',
        default: 'main',
        description: 'Repository default branch'
      },
      homepage: {
        type: 'string',
        shortFlag: 'h',
        default: '',
        description: 'Repository url'
      },
      interactive: {
        type: 'boolean',
        default: true,
        description: 'Allow for interactive elements, asking for input. Use --no-interactive to prevent any input questions, defaulting them to cancel/no.'
      },
      org: {
        type: 'string',
        description: 'Force override the organization slug, overrides the default org from config'
      },
      repoDescription: {
        type: 'string',
        shortFlag: 'd',
        default: '',
        description: 'Repository description'
      },
      visibility: {
        type: 'string',
        shortFlag: 'v',
        default: 'private',
        description: 'Repository visibility (Default Private)'
      }
    },
    help: (command, config) => `
    Usage
      $ ${command} [options] <REPO>

    API Token Requirements
      ${utils.getFlagApiRequirementsOutput(`${parentName}:${CMD_NAME$c}`)}

    Options
      ${utils.getFlagListOutput(config.flags)}

    Examples
      $ ${command} test-repo
      $ ${command} test-repo --homepage https://example.com
  `
  };
  const cli = utils.meowOrExit({
    argv,
    config,
    parentName,
    importMeta
  });
  const {
    json,
    markdown,
    org: orgFlag
  } = cli.flags;
  const dryRun = !!cli.flags['dryRun'];
  const interactive = !!cli.flags['interactive'];
  const noLegacy = !cli.flags['repoName'];
  const [repoName = ''] = cli.input;
  const hasApiToken = utils.hasDefaultApiToken();
  const {
    0: orgSlug
  } = await utils.determineOrgSlug(String(orgFlag || ''), interactive, dryRun);
  const outputKind = utils.getOutputKind(json, markdown);
  const wasValidInput = utils.checkCommandInput(outputKind, {
    nook: true,
    test: noLegacy,
    message: `Legacy flags are no longer supported. See the ${utils.webLink(constants.V1_MIGRATION_GUIDE_URL, 'v1 migration guide')}.`,
    fail: `received legacy flags`
  }, {
    nook: true,
    test: !!orgSlug,
    message: 'Org name by default setting, --org, or auto-discovered',
    fail: 'missing'
  }, {
    test: !!repoName,
    message: 'Repository name as first argument',
    fail: 'missing'
  }, {
    nook: true,
    test: hasApiToken,
    message: 'This command requires a Socket API token for access',
    fail: 'try `socket login`'
  });
  if (!wasValidInput) {
    return;
  }
  if (dryRun) {
    logger.logger.log(constants.default.DRY_RUN_BAILING_NOW);
    return;
  }
  await handleUpdateRepo({
    orgSlug,
    repoName: String(repoName),
    description: String(cli.flags['repoDescription'] || ''),
    homepage: String(cli.flags['homepage'] || ''),
    defaultBranch: String(cli.flags['defaultBranch'] || ''),
    visibility: String(cli.flags['visibility'] || 'private')
  }, outputKind);
}

async function fetchViewRepo(orgSlug, repoName, options) {
  const {
    sdkOpts
  } = {
    __proto__: null,
    ...options
  };
  const sockSdkCResult = await utils.setupSdk(sdkOpts);
  if (!sockSdkCResult.ok) {
    return sockSdkCResult;
  }
  const sockSdk = sockSdkCResult.data;
  return await utils.handleApiCall(sockSdk.getOrgRepo(orgSlug, repoName), {
    description: 'repository data'
  });
}

// @ts-ignore
async function outputViewRepo(result, outputKind) {
  if (!result.ok) {
    process.exitCode = result.code ?? 1;
  }
  if (outputKind === 'json') {
    logger.logger.log(utils.serializeResultJson(result));
    return;
  }
  if (!result.ok) {
    logger.logger.fail(utils.failMsgWithBadge(result.message, result.cause));
    return;
  }
  const options = {
    columns: [{
      field: 'id',
      name: vendor.yoctocolorsCjsExports.magenta('ID')
    }, {
      field: 'name',
      name: vendor.yoctocolorsCjsExports.magenta('Name')
    }, {
      field: 'visibility',
      name: vendor.yoctocolorsCjsExports.magenta('Visibility')
    }, {
      field: 'default_branch',
      name: vendor.yoctocolorsCjsExports.magenta('Default branch')
    }, {
      field: 'homepage',
      name: vendor.yoctocolorsCjsExports.magenta('Homepage')
    }, {
      field: 'archived',
      name: vendor.yoctocolorsCjsExports.magenta('Archived')
    }, {
      field: 'created_at',
      name: vendor.yoctocolorsCjsExports.magenta('Created at')
    }]
  };
  logger.logger.log(vendor.srcExports(options, [result.data]));
}

async function handleViewRepo(orgSlug, repoName, outputKind) {
  const data = await fetchViewRepo(orgSlug, repoName);
  await outputViewRepo(data, outputKind);
}

const CMD_NAME$b = 'view';
const description$e = 'View repositories in an organization';
const hidden$b = false;
const cmdRepositoryView = {
  description: description$e,
  hidden: hidden$b,
  run: run$e
};
async function run$e(argv, importMeta, {
  parentName
}) {
  const config = {
    commandName: CMD_NAME$b,
    description: description$e,
    hidden: hidden$b,
    flags: {
      ...flags.commonFlags,
      ...flags.outputFlags,
      interactive: {
        type: 'boolean',
        default: true,
        description: 'Allow for interactive elements, asking for input. Use --no-interactive to prevent any input questions, defaulting them to cancel/no.'
      },
      org: {
        type: 'string',
        description: 'Force override the organization slug, overrides the default org from config'
      }
    },
    help: (command, config) => `
    Usage
      $ ${command} [options] <REPO>

    API Token Requirements
      ${utils.getFlagApiRequirementsOutput(`${parentName}:${CMD_NAME$b}`)}

    Options
      ${utils.getFlagListOutput(config.flags)}

    Examples
      $ ${command} test-repo
      $ ${command} test-repo --json
  `
  };
  const cli = utils.meowOrExit({
    argv,
    config,
    parentName,
    importMeta
  });
  const {
    json,
    markdown,
    org: orgFlag
  } = cli.flags;
  const dryRun = !!cli.flags['dryRun'];
  const interactive = !!cli.flags['interactive'];
  const noLegacy = !cli.flags['repoName'];
  const [repoName = ''] = cli.input;
  const hasApiToken = utils.hasDefaultApiToken();
  const {
    0: orgSlug
  } = await utils.determineOrgSlug(String(orgFlag || ''), interactive, dryRun);
  const outputKind = utils.getOutputKind(json, markdown);
  const wasValidInput = utils.checkCommandInput(outputKind, {
    nook: true,
    test: noLegacy,
    message: `Legacy flags are no longer supported. See the ${utils.webLink(constants.V1_MIGRATION_GUIDE_URL, 'v1 migration guide')}.`,
    fail: `received legacy flags`
  }, {
    nook: true,
    test: !!orgSlug,
    message: 'Org name by default setting, --org, or auto-discovered',
    fail: 'missing'
  }, {
    test: !!repoName,
    message: 'Repository name as first argument',
    fail: 'missing'
  }, {
    nook: true,
    test: !json || !markdown,
    message: `The \`${constants.FLAG_JSON}\` and \`${constants.FLAG_MARKDOWN}\` flags can not be used at the same time`,
    fail: 'bad'
  }, {
    nook: true,
    test: hasApiToken,
    message: 'This command requires a Socket API token for access',
    fail: 'try `socket login`'
  });
  if (!wasValidInput) {
    return;
  }
  if (dryRun) {
    logger.logger.log(constants.default.DRY_RUN_BAILING_NOW);
    return;
  }
  await handleViewRepo(orgSlug, String(repoName), outputKind);
}

const description$d = 'Manage registered repositories';
const cmdRepository = {
  description: description$d,
  async run(argv, importMeta, {
    parentName
  }) {
    await utils.meowWithSubcommands({
      argv,
      name: `${parentName} repository`,
      importMeta,
      subcommands: {
        create: cmdRepositoryCreate,
        view: cmdRepositoryView,
        list: cmdRepositoryList,
        del: cmdRepositoryDel,
        update: cmdRepositoryUpdate
      }
    }, {
      description: description$d
    });
  }
};

const reachabilityFlags = {
  reachAnalysisMemoryLimit: {
    type: 'number',
    default: 8192,
    description: 'The maximum memory in MB to use for the reachability analysis. The default is 8192MB.'
  },
  reachAnalysisTimeout: {
    type: 'number',
    default: 0,
    description: 'Set timeout for the reachability analysis. Split analysis runs may cause the total scan time to exceed this timeout significantly.'
  },
  reachDisableAnalytics: {
    type: 'boolean',
    default: false,
    description: 'Disable reachability analytics sharing with Socket. Also disables caching-based optimizations.'
  },
  reachEcosystems: {
    type: 'string',
    isMultiple: true,
    description: 'List of ecosystems to conduct reachability analysis on, as either a comma separated value or as multiple flags. Defaults to all ecosystems.'
  },
  reachExcludePaths: {
    type: 'string',
    isMultiple: true,
    description: 'List of paths to exclude from reachability analysis, as either a comma separated value or as multiple flags.'
  },
  reachSkipCache: {
    type: 'boolean',
    default: false,
    description: 'Skip caching-based optimizations. By default, the reachability analysis will use cached configurations from previous runs to speed up the analysis.'
  }
};

async function suggestTarget() {
  // We could prefill this with sub-dirs of the current
  // dir ... but is that going to be useful?
  const proceed = await prompts.select({
    message: 'No TARGET given. Do you want to use the current directory?',
    choices: [{
      name: 'Yes',
      value: true,
      description: 'Target the current directory'
    }, {
      name: 'No',
      value: false,
      description: 'Do not use the current directory (this will end in a no-op)'
    }]
  });
  return proceed ? ['.'] : [];
}

const CMD_NAME$a = 'create';
const description$c = 'Create a new Socket scan and report';
const hidden$a = false;
const generalFlags$1 = {
  ...flags.commonFlags,
  ...flags.outputFlags,
  autoManifest: {
    type: 'boolean',
    description: 'Run `socket manifest auto` before collecting manifest files. This is necessary for languages like Scala, Gradle, and Kotlin, See `socket manifest auto --help`.'
  },
  branch: {
    type: 'string',
    default: '',
    description: 'Branch name',
    shortFlag: 'b'
  },
  commitHash: {
    type: 'string',
    default: '',
    description: 'Commit hash',
    shortFlag: 'ch'
  },
  commitMessage: {
    type: 'string',
    default: '',
    description: 'Commit message',
    shortFlag: 'm'
  },
  committers: {
    type: 'string',
    default: '',
    description: 'Committers',
    shortFlag: 'c'
  },
  cwd: {
    type: 'string',
    default: '',
    description: 'working directory, defaults to process.cwd()'
  },
  defaultBranch: {
    type: 'boolean',
    default: false,
    description: 'Set the default branch of the repository to the branch of this full-scan. Should only need to be done once, for example for the "main" or "master" branch.'
  },
  interactive: {
    type: 'boolean',
    default: true,
    description: 'Allow for interactive elements, asking for input. Use --no-interactive to prevent any input questions, defaulting them to cancel/no.'
  },
  pullRequest: {
    type: 'number',
    default: 0,
    description: 'Pull request number',
    shortFlag: 'pr'
  },
  org: {
    type: 'string',
    default: '',
    description: 'Force override the organization slug, overrides the default org from config'
  },
  reach: {
    type: 'boolean',
    default: false,
    description: 'Run tier 1 full application reachability analysis'
  },
  readOnly: {
    type: 'boolean',
    default: false,
    description: 'Similar to --dry-run except it can read from remote, stops before it would create an actual report'
  },
  repo: {
    type: 'string',
    shortFlag: 'r',
    description: 'Repository name'
  },
  report: {
    type: 'boolean',
    description: 'Wait for the scan creation to complete, then basically run `socket scan report` on it'
  },
  reportLevel: {
    type: 'string',
    default: constants.default.REPORT_LEVEL_ERROR,
    description: `Which policy level alerts should be reported (default '${constants.default.REPORT_LEVEL_ERROR}')`
  },
  setAsAlertsPage: {
    type: 'boolean',
    default: true,
    description: 'When true and if this is the "default branch" then this Scan will be the one reflected on your alerts page. See help for details. Defaults to true.',
    aliases: ['pendingHead']
  },
  tmp: {
    type: 'boolean',
    default: false,
    description: 'Set the visibility (true/false) of the scan in your dashboard.',
    shortFlag: 't'
  }
};
const cmdScanCreate = {
  description: description$c,
  hidden: hidden$a,
  run: run$d
};
async function run$d(argv, importMeta, {
  parentName
}) {
  const config = {
    commandName: CMD_NAME$a,
    description: description$c,
    hidden: hidden$a,
    flags: {
      ...generalFlags$1,
      ...reachabilityFlags
    },
    // TODO: Your project's "socket.yml" file's "projectIgnorePaths".
    help: command => `
    Usage
      $ ${command} [options] [TARGET...]

    API Token Requirements
      ${utils.getFlagApiRequirementsOutput(`${parentName}:${CMD_NAME$a}`)}

    Options
      ${utils.getFlagListOutput(generalFlags$1)}

    Reachability Options (when --reach is used)
      ${utils.getFlagListOutput(reachabilityFlags)}

    Uploads the specified dependency manifest files for Go, Gradle, JavaScript,
    Kotlin, Python, and Scala. Files like "package.json" and "${constants.REQUIREMENTS_TXT}".
    If any folder is specified, the ones found in there recursively are uploaded.

    Details on TARGET:

    - Defaults to the current dir (cwd) if none given
    - Multiple targets can be specified
    - If a target is a file, only that file is checked
    - If it is a dir, the dir is scanned for any supported manifest files
    - Dirs MUST be within the current dir (cwd), you can use --cwd to change it
    - Supports globbing such as "**/package.json", "**/${constants.REQUIREMENTS_TXT}", etc.
    - Ignores any file specified in your project's ".gitignore"
    - Also a sensible set of default ignores from the "ignore-by-default" module

    The --repo and --branch flags tell Socket to associate this Scan with that
    repo/branch. The names will show up on your dashboard on the Socket website.

    Note: for a first run you probably want to set --default-branch to indicate
          the default branch name, like "main" or "master".

    The ${utils.socketDashboardLink('/org/YOURORG/alerts', '"alerts page"')} will show
    the results from the last scan designated as the "pending head" on the branch
    configured on Socket to be the "default branch". When creating a scan the
    --set-as-alerts-page flag will default to true to update this. You can prevent
    this by using --no-set-as-alerts-page. This flag is ignored for any branch that
    is not designated as the "default branch". It is disabled when using --tmp.

    You can use \`socket scan setup\` to configure certain repo flag defaults.

    Examples
      $ ${command}
      $ ${command} ./proj --json
      $ ${command} --repo=test-repo --branch=main ./package.json
  `
  };
  const cli = utils.meowOrExit({
    argv,
    config,
    parentName,
    importMeta
  });
  const {
    commitHash,
    commitMessage,
    committers,
    cwd: cwdOverride,
    defaultBranch,
    interactive = true,
    json,
    markdown,
    org: orgFlag,
    pullRequest,
    reach,
    reachAnalysisMemoryLimit,
    reachAnalysisTimeout,
    reachDisableAnalytics,
    reachSkipCache,
    readOnly,
    reportLevel,
    setAsAlertsPage: pendingHeadFlag,
    tmp
  } = cli.flags;

  // Validate ecosystem values.
  const reachEcosystems = [];
  const reachEcosystemsRaw = utils.cmdFlagValueToArray(cli.flags['reachEcosystems']);
  const validEcosystems = utils.getEcosystemChoicesForMeow();
  for (const ecosystem of reachEcosystemsRaw) {
    if (!validEcosystems.includes(ecosystem)) {
      throw new Error(`Invalid ecosystem: "${ecosystem}". Valid values are: ${arrays.joinAnd(validEcosystems)}`);
    }
    reachEcosystems.push(ecosystem);
  }
  const dryRun = !!cli.flags['dryRun'];
  let {
    autoManifest,
    branch: branchName,
    repo: repoName,
    report
  } = cli.flags;
  let {
    0: orgSlug
  } = await utils.determineOrgSlug(String(orgFlag || ''), interactive, dryRun);
  const processCwd = process.cwd();
  const cwd = cwdOverride && cwdOverride !== '.' && cwdOverride !== processCwd ? path.resolve(processCwd, cwdOverride) : processCwd;
  const sockJson = await utils.readOrDefaultSocketJsonUp(cwd);

  // Note: This needs meow booleanDefault=undefined.
  if (typeof autoManifest !== 'boolean') {
    if (sockJson.defaults?.scan?.create?.autoManifest !== undefined) {
      autoManifest = sockJson.defaults.scan.create.autoManifest;
      logger.logger.info(`Using default --auto-manifest from ${constants.SOCKET_JSON}:`, autoManifest);
    } else {
      autoManifest = false;
    }
  }
  if (!branchName) {
    if (sockJson.defaults?.scan?.create?.branch) {
      branchName = sockJson.defaults.scan.create.branch;
      logger.logger.info(`Using default --branch from ${constants.SOCKET_JSON}:`, branchName);
    } else {
      branchName = (await utils.gitBranch(cwd)) || (await utils.detectDefaultBranch(cwd));
    }
  }
  if (!repoName) {
    if (sockJson.defaults?.scan?.create?.repo) {
      repoName = sockJson.defaults.scan.create.repo;
      logger.logger.info(`Using default --repo from ${constants.SOCKET_JSON}:`, repoName);
    } else {
      repoName = await utils.getRepoName(cwd);
    }
  }
  if (typeof report !== 'boolean') {
    if (sockJson.defaults?.scan?.create?.report !== undefined) {
      report = sockJson.defaults.scan.create.report;
      logger.logger.info(`Using default --report from ${constants.SOCKET_JSON}:`, report);
    } else {
      report = false;
    }
  }

  // If we updated any inputs then we should print the command line to repeat
  // the command without requiring user input, as a suggestion.
  let updatedInput = false;

  // Accept zero or more paths. Default to cwd() if none given.
  let targets = cli.input || [cwd];
  if (!targets.length && !dryRun && interactive) {
    targets = await suggestTarget();
    updatedInput = true;
  }

  // We're going to need an api token to suggest data because those suggestions
  // must come from data we already know. Don't error on missing api token yet.
  // If the api-token is not set, ignore it for the sake of suggestions.
  const hasApiToken = utils.hasDefaultApiToken();
  const outputKind = utils.getOutputKind(json, markdown);
  const pendingHead = tmp ? false : pendingHeadFlag;

  // If the current cwd is unknown and is used as a repo slug anyways, we will
  // first need to register the slug before we can use it.
  // Only do suggestions with an apiToken and when not in dryRun mode
  if (hasApiToken && !dryRun && interactive) {
    if (!orgSlug) {
      const suggestion = await utils.suggestOrgSlug();
      if (suggestion === undefined) {
        await outputCreateNewScan({
          ok: false,
          message: 'Canceled by user',
          cause: 'Org selector was canceled by user'
        }, {
          interactive: false,
          outputKind
        });
        return;
      }
      if (suggestion) {
        orgSlug = suggestion;
      }
      updatedInput = true;
    }
  }
  const detected = await detectManifestActions(sockJson, cwd);
  if (detected.count > 0 && !autoManifest) {
    logger.logger.info(`Detected ${detected.count} manifest targets we could try to generate. Please set the --auto-manifest flag if you want to include languages covered by \`socket manifest auto\` in the Scan.`);
  }
  if (updatedInput && orgSlug && targets.length) {
    logger.logger.info('Note: You can invoke this command next time to skip the interactive questions:');
    logger.logger.error('```');
    logger.logger.error(`    socket scan create [other flags...] ${orgSlug} ${targets.join(' ')}`);
    logger.logger.error('```');
    logger.logger.error('');
    logger.logger.info(`You can also run \`socket scan setup\` to persist these flag defaults to a ${constants.SOCKET_JSON} file.`);
    logger.logger.error('');
  }
  const reachExcludePaths = utils.cmdFlagValueToArray(cli.flags['reachExcludePaths']);

  // Validation helpers for better readability.
  const hasReachEcosystems = reachEcosystems.length > 0;
  const hasReachExcludePaths = reachExcludePaths.length > 0;
  const isUsingNonDefaultMemoryLimit = reachAnalysisMemoryLimit !== reachabilityFlags['reachAnalysisMemoryLimit']?.default;
  const isUsingNonDefaultTimeout = reachAnalysisTimeout !== reachabilityFlags['reachAnalysisTimeout']?.default;
  const isUsingNonDefaultAnalytics = reachDisableAnalytics !== reachabilityFlags['reachDisableAnalytics']?.default;
  const isUsingAnyReachabilityFlags = isUsingNonDefaultMemoryLimit || isUsingNonDefaultTimeout || isUsingNonDefaultAnalytics || hasReachEcosystems || hasReachExcludePaths || reachSkipCache;
  const wasValidInput = utils.checkCommandInput(outputKind, {
    nook: true,
    test: !!orgSlug,
    message: 'Org name by default setting, --org, or auto-discovered',
    fail: 'missing'
  }, {
    test: !!targets.length,
    message: 'At least one TARGET (e.g. `.` or `./package.json`)',
    fail: 'missing'
  }, {
    nook: true,
    test: !json || !markdown,
    message: 'The json and markdown flags cannot be both set, pick one',
    fail: 'omit one'
  }, {
    nook: true,
    test: hasApiToken,
    message: 'This command requires a Socket API token for access',
    fail: 'try `socket login`'
  }, {
    nook: true,
    test: !defaultBranch || !!branchName,
    message: 'When --default-branch is set, --branch is mandatory',
    fail: 'missing branch name'
  }, {
    nook: true,
    test: !pendingHead || !!branchName,
    message: 'When --pending-head is set, --branch is mandatory',
    fail: 'missing branch name'
  }, {
    nook: true,
    test: reach || !isUsingAnyReachabilityFlags,
    message: 'Reachability analysis flags require --reach to be enabled',
    fail: 'add --reach flag to use --reach-* options'
  });
  if (!wasValidInput) {
    return;
  }
  if (dryRun) {
    logger.logger.log(constants.default.DRY_RUN_BAILING_NOW);
    return;
  }
  await handleCreateNewScan({
    autoManifest: Boolean(autoManifest),
    branchName: branchName,
    commitHash: commitHash && String(commitHash) || '',
    commitMessage: commitMessage && String(commitMessage) || '',
    committers: committers && String(committers) || '',
    cwd,
    defaultBranch: Boolean(defaultBranch),
    interactive: Boolean(interactive),
    orgSlug,
    outputKind,
    pendingHead: Boolean(pendingHead),
    pullRequest: Number(pullRequest),
    reach: {
      runReachabilityAnalysis: Boolean(reach),
      reachDisableAnalytics: Boolean(reachDisableAnalytics),
      reachAnalysisTimeout: Number(reachAnalysisTimeout),
      reachAnalysisMemoryLimit: Number(reachAnalysisMemoryLimit),
      reachEcosystems,
      reachExcludePaths,
      reachSkipCache: Boolean(reachSkipCache)
    },
    readOnly: Boolean(readOnly),
    repoName,
    report,
    reportLevel,
    targets,
    tmp: Boolean(tmp)
  });
}

async function fetchDeleteOrgFullScan(orgSlug, scanId, options) {
  const {
    sdkOpts
  } = {
    __proto__: null,
    ...options
  };
  const sockSdkCResult = await utils.setupSdk(sdkOpts);
  if (!sockSdkCResult.ok) {
    return sockSdkCResult;
  }
  const sockSdk = sockSdkCResult.data;
  return await utils.handleApiCall(sockSdk.deleteOrgFullScan(orgSlug, scanId), {
    description: 'to delete a scan'
  });
}

async function outputDeleteScan(result, outputKind) {
  if (!result.ok) {
    process.exitCode = result.code ?? 1;
  }
  if (outputKind === 'json') {
    logger.logger.log(utils.serializeResultJson(result));
    return;
  }
  if (!result.ok) {
    logger.logger.fail(utils.failMsgWithBadge(result.message, result.cause));
    return;
  }
  logger.logger.success('Scan deleted successfully');
}

async function handleDeleteScan(orgSlug, scanId, outputKind) {
  const data = await fetchDeleteOrgFullScan(orgSlug, scanId);
  await outputDeleteScan(data, outputKind);
}

const CMD_NAME$9 = 'del';
const description$b = 'Delete a scan';
const hidden$9 = false;
const cmdScanDel = {
  description: description$b,
  hidden: hidden$9,
  run: run$c
};
async function run$c(argv, importMeta, {
  parentName
}) {
  const config = {
    commandName: CMD_NAME$9,
    description: description$b,
    hidden: hidden$9,
    flags: {
      ...flags.commonFlags,
      ...flags.outputFlags,
      interactive: {
        type: 'boolean',
        default: true,
        description: 'Allow for interactive elements, asking for input. Use --no-interactive to prevent any input questions, defaulting them to cancel/no.'
      },
      org: {
        type: 'string',
        description: 'Force override the organization slug, overrides the default org from config'
      }
    },
    help: (command, config) => `
    Usage
      $ ${command} [options] <SCAN_ID>

    API Token Requirements
      ${utils.getFlagApiRequirementsOutput(`${parentName}:${CMD_NAME$9}`)}

    Options
      ${utils.getFlagListOutput(config.flags)}

    Examples
      $ ${command} 000aaaa1-0000-0a0a-00a0-00a0000000a0
      $ ${command} 000aaaa1-0000-0a0a-00a0-00a0000000a0 --json
  `
  };
  const cli = utils.meowOrExit({
    argv,
    config,
    importMeta,
    parentName
  });
  const {
    json,
    markdown,
    org: orgFlag
  } = cli.flags;
  const dryRun = !!cli.flags['dryRun'];
  const interactive = !!cli.flags['interactive'];
  const [scanId = ''] = cli.input;
  const hasApiToken = utils.hasDefaultApiToken();
  const [orgSlug, defaultOrgSlug] = await utils.determineOrgSlug(String(orgFlag || ''), interactive, dryRun);
  const outputKind = utils.getOutputKind(json, markdown);
  const wasValidInput = utils.checkCommandInput(outputKind, {
    nook: !!defaultOrgSlug,
    test: !!orgSlug,
    message: 'Org name by default setting, --org, or auto-discovered',
    fail: 'missing'
  }, {
    test: !!scanId,
    message: 'Scan ID to delete',
    fail: 'missing'
  }, {
    nook: true,
    test: hasApiToken,
    message: 'This command requires a Socket API token for access',
    fail: 'try `socket login`'
  });
  if (!wasValidInput) {
    return;
  }
  if (dryRun) {
    logger.logger.log(constants.default.DRY_RUN_BAILING_NOW);
    return;
  }
  await handleDeleteScan(orgSlug, scanId, outputKind);
}

async function fetchDiffScan({
  id1,
  id2,
  orgSlug
}) {
  logger.logger.info('Scan ID 1:', id1);
  logger.logger.info('Scan ID 2:', id2);
  logger.logger.info('Note: this request may take some time if the scans are big');
  return await utils.queryApiSafeJson(`orgs/${orgSlug}/full-scans/diff?before=${encodeURIComponent(id1)}&after=${encodeURIComponent(id2)}`, 'a scan diff');
}

async function outputDiffScan(result, {
  depth,
  file,
  outputKind
}) {
  if (!result.ok) {
    process.exitCode = result.code ?? 1;
  }
  if (!result.ok) {
    if (outputKind === 'json') {
      logger.logger.log(utils.serializeResultJson(result));
      return;
    }
    logger.logger.fail(utils.failMsgWithBadge(result.message, result.cause));
    return;
  }
  const dashboardUrl = result.data.diff_report_url;
  const dashboardMessage = dashboardUrl ? `\n View this diff scan in the Socket dashboard: ${vendor.yoctocolorsCjsExports.cyan(dashboardUrl)}` : '';

  // When forcing json, or dumping to file, serialize to string such that it
  // won't get truncated. The only way to dump the full raw JSON to stdout is
  // to use `--json --file -` (the dash is a standard notation for stdout)
  if (outputKind === 'json' || file) {
    await handleJson(result, file, dashboardMessage);
    return;
  }
  if (outputKind === 'markdown') {
    await handleMarkdown(result.data);
    return;
  }

  // In this case neither the --json nor the --file flag was passed
  // Dump the JSON to CLI and let NodeJS deal with truncation

  logger.logger.log('Diff scan result:');
  logger.logger.log(require$$1.inspect(result.data, {
    showHidden: false,
    depth: depth > 0 ? depth : null,
    colors: true,
    maxArrayLength: null
  }));
  logger.logger.info(`\n 📝 To display the detailed report in the terminal, use the --json flag. For a friendlier report, use the --markdown flag.\n`);
  logger.logger.info(dashboardMessage);
}
async function handleJson(data, file, dashboardMessage) {
  const json = utils.serializeResultJson(data);
  if (file && file !== '-') {
    logger.logger.log(`Writing json to \`${file}\``);
    fs$1.writeFile(file, json, err => {
      if (err) {
        logger.logger.fail(`Writing to \`${file}\` failed...`);
        logger.logger.error(err);
      } else {
        logger.logger.success(`Data successfully written to \`${utils.fileLink(file)}\``);
      }
      logger.logger.error(dashboardMessage);
    });
  } else {
    // only .log goes to stdout
    logger.logger.info(`\n Diff scan result: \n`);
    logger.logger.log(json);
    logger.logger.info(dashboardMessage);
  }
}
async function handleMarkdown(data) {
  const SOCKET_SBOM_URL_PREFIX = `${constants.default.SOCKET_WEBSITE_URL}/dashboard/org/SocketDev/sbom/`;
  logger.logger.log('# Scan diff result');
  logger.logger.log('');
  logger.logger.log('This Socket.dev report shows the changes between two scans:');
  logger.logger.log(`- [${data.before.id}](${SOCKET_SBOM_URL_PREFIX}${data.before.id})`);
  logger.logger.log(`- [${data.after.id}](${SOCKET_SBOM_URL_PREFIX}${data.after.id})`);
  logger.logger.log('');
  logger.logger.log(`You can [view this report in your dashboard](${data.diff_report_url})`);
  logger.logger.log('');
  logger.logger.log('## Changes');
  logger.logger.log('');
  logger.logger.log(`- directDependenciesChanged: ${data.directDependenciesChanged}`);
  logger.logger.log(`- Added packages: ${data.artifacts.added.length}`);
  if (data.artifacts.added.length > 0) {
    data.artifacts.added.slice(0, 10).forEach(artifact => {
      logger.logger.log(`  - ${artifact.type} ${artifact.name}@${artifact.version}`);
    });
    if (data.artifacts.added.length > 10) {
      logger.logger.log(`  ... and ${data.artifacts.added.length - 10} more`);
    }
  }
  logger.logger.log(`- Removed packages: ${data.artifacts.removed.length}`);
  if (data.artifacts.removed.length > 0) {
    data.artifacts.removed.slice(0, 10).forEach(artifact => {
      logger.logger.log(`  - ${artifact.type} ${artifact.name}@${artifact.version}`);
    });
    if (data.artifacts.removed.length > 10) {
      logger.logger.log(`  ... and ${data.artifacts.removed.length - 10} more`);
    }
  }
  logger.logger.log(`- Replaced packages: ${data.artifacts.replaced.length}`);
  if (data.artifacts.replaced.length > 0) {
    data.artifacts.replaced.slice(0, 10).forEach(artifact => {
      logger.logger.log(`  - ${artifact.type} ${artifact.name}@${artifact.version}`);
    });
    if (data.artifacts.replaced.length > 10) {
      logger.logger.log(`  ... and ${data.artifacts.replaced.length - 10} more`);
    }
  }
  logger.logger.log(`- Updated packages: ${data.artifacts.updated.length}`);
  if (data.artifacts.updated.length > 0) {
    data.artifacts.updated.slice(0, 10).forEach(artifact => {
      logger.logger.log(`  - ${artifact.type} ${artifact.name}@${artifact.version}`);
    });
    if (data.artifacts.updated.length > 10) {
      logger.logger.log(`  ... and ${data.artifacts.updated.length - 10} more`);
    }
  }
  const unchanged = data.artifacts.unchanged ?? [];
  logger.logger.log(`- Unchanged packages: ${unchanged.length}`);
  if (unchanged.length > 0) {
    const firstUpToTen = unchanged.slice(0, 10);
    for (const artifact of firstUpToTen) {
      logger.logger.log(`  - ${artifact.type} ${artifact.name}@${artifact.version}`);
    }
    if (unchanged.length > 10) {
      logger.logger.log(`  ... and ${unchanged.length - 10} more`);
    }
  }
  logger.logger.log('');
  logger.logger.log(`## Scan ${data.before.id}`);
  logger.logger.log('');
  logger.logger.log('This Scan was considered to be the "base" / "from" / "before" Scan.');
  logger.logger.log('');
  for (const {
    0: key,
    1: value
  } of Object.entries(data.before)) {
    if (key === 'pull_request' && !value) {
      continue;
    }
    if (!['id', 'organization_id', 'repository_id'].includes(key)) {
      logger.logger.group(`- ${key === 'repository_slug' ? 'repo' : key === 'organization_slug' ? 'org' : key}: ${value}`);
      logger.logger.groupEnd();
    }
  }
  logger.logger.log('');
  logger.logger.log(`## Scan ${data.after.id}`);
  logger.logger.log('');
  logger.logger.log('This Scan was considered to be the "head" / "to" / "after" Scan.');
  logger.logger.log('');
  for (const {
    0: key,
    1: value
  } of Object.entries(data.after)) {
    if (key === 'pull_request' && !value) {
      continue;
    }
    if (!['id', 'organization_id', 'repository_id'].includes(key)) {
      logger.logger.group(`- ${key === 'repository_slug' ? 'repo' : key === 'organization_slug' ? 'org' : key}: ${value}`);
      logger.logger.groupEnd();
    }
  }
  logger.logger.log('');
}

async function handleDiffScan({
  depth,
  file,
  id1,
  id2,
  orgSlug,
  outputKind
}) {
  const data = await fetchDiffScan({
    id1,
    id2,
    orgSlug
  });
  await outputDiffScan(data, {
    depth,
    file,
    outputKind
  });
}

const CMD_NAME$8 = 'diff';
const description$a = 'See what changed between two Scans';
const hidden$8 = false;
const cmdScanDiff = {
  description: description$a,
  hidden: hidden$8,
  run: run$b
};
async function run$b(argv, importMeta, {
  parentName
}) {
  const config = {
    commandName: CMD_NAME$8,
    description: description$a,
    hidden: hidden$8,
    flags: {
      ...flags.commonFlags,
      ...flags.outputFlags,
      depth: {
        type: 'number',
        default: 2,
        description: 'Max depth of JSON to display before truncating, use zero for no limit (without --json/--file)'
      },
      file: {
        type: 'string',
        shortFlag: 'f',
        default: '',
        description: 'Path to a local file where the output should be saved. Use `-` to force stdout.'
      },
      interactive: {
        type: 'boolean',
        default: true,
        description: 'Allow for interactive elements, asking for input. Use --no-interactive to prevent any input questions, defaulting them to cancel/no.'
      },
      org: {
        type: 'string',
        description: 'Force override the organization slug, overrides the default org from config'
      }
    },
    help: (command, config) => `
    Usage
      $ ${command} [options] <SCAN_ID1> <SCAN_ID2>

    API Token Requirements
      ${utils.getFlagApiRequirementsOutput(`${parentName}:${CMD_NAME$8}`)}

    This command displays the package changes between two scans. The full output
    can be pretty large depending on the size of your repo and time range. It is
    best stored to disk (with --json) to be further analyzed by other tools.

    Note: While it will work in any order, the first Scan ID is assumed to be the
          older ID, even if it is a newer Scan. This is only relevant for the
          added/removed list (similar to diffing two files with git).

    Options
      ${utils.getFlagListOutput(config.flags)}

    Examples
      $ ${command} aaa0aa0a-aaaa-0000-0a0a-0000000a00a0 aaa1aa1a-aaaa-1111-1a1a-1111111a11a1
      $ ${command} aaa0aa0a-aaaa-0000-0a0a-0000000a00a0 aaa1aa1a-aaaa-1111-1a1a-1111111a11a1 --json
  `
  };
  const cli = utils.meowOrExit({
    argv,
    config,
    importMeta,
    parentName
  });
  const SOCKET_SBOM_URL_PREFIX = `${constants.default.SOCKET_WEBSITE_URL}/dashboard/org/SocketDev/sbom/`;
  const SOCKET_SBOM_URL_PREFIX_LENGTH = SOCKET_SBOM_URL_PREFIX.length;
  const {
    depth,
    dryRun,
    file,
    json,
    markdown,
    org: orgFlag
  } = cli.flags;
  const interactive = !!cli.flags['interactive'];
  let [id1 = '', id2 = ''] = cli.input;
  // Support dropping in full socket urls to an sbom.
  if (id1.startsWith(SOCKET_SBOM_URL_PREFIX)) {
    id1 = id1.slice(SOCKET_SBOM_URL_PREFIX_LENGTH);
  }
  if (id2.startsWith(SOCKET_SBOM_URL_PREFIX)) {
    id2 = id2.slice(SOCKET_SBOM_URL_PREFIX_LENGTH);
  }
  const hasApiToken = utils.hasDefaultApiToken();
  const {
    0: orgSlug
  } = await utils.determineOrgSlug(String(orgFlag || ''), interactive, dryRun);
  const outputKind = utils.getOutputKind(json, markdown);
  const wasValidInput = utils.checkCommandInput(outputKind, {
    test: !!(id1 && id2),
    message: 'Specify two Scan IDs.\nA Scan ID looks like `aaa0aa0a-aaaa-0000-0a0a-0000000a00a0`.',
    fail: !id1 && !id2 ? 'missing both Scan IDs' : !id2 ? 'missing second Scan ID' : 'missing first Scan ID' // Not sure how this can happen but ok.
  }, {
    test: !!orgSlug,
    nook: true,
    message: 'Org name by default setting, --org, or auto-discovered',
    fail: 'missing'
  }, {
    nook: true,
    test: !json || !markdown,
    message: `The \`${constants.FLAG_JSON}\` and \`${constants.FLAG_MARKDOWN}\` flags can not be used at the same time`,
    fail: 'bad'
  }, {
    nook: true,
    test: hasApiToken,
    message: 'This command requires a Socket API token for access',
    fail: 'try `socket login`'
  });
  if (!wasValidInput) {
    return;
  }
  if (dryRun) {
    logger.logger.log(constants.default.DRY_RUN_BAILING_NOW);
    return;
  }
  await handleDiffScan({
    id1,
    id2,
    depth,
    orgSlug,
    outputKind,
    file
  });
}

async function createScanFromGithub({
  all,
  githubApiUrl,
  githubToken,
  interactive,
  orgGithub,
  orgSlug,
  outputKind,
  repos
}) {
  let targetRepos = repos.trim().split(',').map(r => r.trim()).filter(Boolean);
  if (all || !targetRepos.length) {
    // Fetch from Socket API
    const result = await fetchListAllRepos(orgSlug, {
      direction: 'asc',
      sort: 'name'
    });
    if (!result.ok) {
      return result;
    }
    targetRepos = result.data.results.map(obj => obj.slug || '');
  }
  targetRepos = targetRepos.map(s => s.trim()).filter(Boolean);
  logger.logger.info(`Have ${targetRepos.length} repo names to Scan!`);
  logger.logger.log('');
  if (!targetRepos.filter(Boolean).length) {
    return {
      ok: false,
      message: 'No repo found',
      cause: 'You did not set the --repos value and/or the server responded with zero repos when asked for some. Unable to proceed.'
    };
  }

  // Non-interactive or explicitly requested; just do it.
  if (interactive && targetRepos.length > 1 && !all && !repos) {
    const which = await selectFocus(targetRepos);
    if (!which.ok) {
      return which;
    }
    targetRepos = which.data;
  }

  // 10 is an arbitrary number. Maybe confirm whenever count>1 ?
  // Do not ask to confirm when the list was given explicit.
  if (interactive && (all || !repos) && targetRepos.length > 10) {
    const sure = await makeSure(targetRepos.length);
    if (!sure.ok) {
      return sure;
    }
  }
  let scansCreated = 0;
  for (const repoSlug of targetRepos) {
    // eslint-disable-next-line no-await-in-loop
    const scanCResult = await scanRepo(repoSlug, {
      githubApiUrl,
      githubToken,
      orgSlug,
      orgGithub,
      outputKind,
      repos
    });
    if (scanCResult.ok) {
      const {
        scanCreated
      } = scanCResult.data;
      if (scanCreated) {
        scansCreated += 1;
      }
    }
  }
  logger.logger.success(targetRepos.length, 'GitHub repos detected');
  logger.logger.success(scansCreated, 'with supported Manifest files');
  return {
    ok: true,
    data: undefined
  };
}
async function scanRepo(repoSlug, {
  githubApiUrl,
  githubToken,
  orgGithub,
  orgSlug,
  outputKind,
  repos
}) {
  logger.logger.info(`Requesting repo details from GitHub API for: \`${orgGithub}/${repoSlug}\`...`);
  logger.logger.group();
  const result = await scanOneRepo(repoSlug, {
    githubApiUrl,
    githubToken,
    orgSlug,
    orgGithub,
    outputKind});
  logger.logger.groupEnd();
  logger.logger.log('');
  return result;
}
async function scanOneRepo(repoSlug, {
  githubApiUrl,
  githubToken,
  orgGithub,
  orgSlug,
  outputKind
}) {
  const repoResult = await getRepoDetails({
    orgGithub,
    repoSlug,
    githubApiUrl,
    githubToken
  });
  if (!repoResult.ok) {
    return repoResult;
  }
  const {
    defaultBranch,
    repoApiUrl
  } = repoResult.data;
  logger.logger.info(`Default branch: \`${defaultBranch}\``);
  const treeResult = await getRepoBranchTree({
    defaultBranch,
    githubToken,
    orgGithub,
    repoSlug,
    repoApiUrl
  });
  if (!treeResult.ok) {
    return treeResult;
  }
  const files = treeResult.data;
  if (!files.length) {
    logger.logger.warn('No files were reported for the default branch. Moving on to next repo.');
    return {
      ok: true,
      data: {
        scanCreated: false
      }
    };
  }
  const tmpDir = fs$1.mkdtempSync(path.join(os.tmpdir(), repoSlug));
  require$$9.debugFn('notice', 'init: temp dir for scan root', tmpDir);
  const downloadResult = await testAndDownloadManifestFiles({
    files,
    tmpDir,
    repoSlug,
    defaultBranch,
    orgGithub,
    repoApiUrl,
    githubToken
  });
  if (!downloadResult.ok) {
    return downloadResult;
  }
  const commitResult = await getLastCommitDetails({
    orgGithub,
    repoSlug,
    defaultBranch,
    repoApiUrl,
    githubToken
  });
  if (!commitResult.ok) {
    return commitResult;
  }
  const {
    lastCommitMessage,
    lastCommitSha,
    lastCommitter
  } = commitResult.data;

  // Make request for full scan
  // I think we can just kick off the socket scan create command now...

  await handleCreateNewScan({
    autoManifest: false,
    branchName: defaultBranch,
    commitHash: lastCommitSha,
    commitMessage: lastCommitMessage || '',
    committers: lastCommitter || '',
    cwd: tmpDir,
    defaultBranch: true,
    interactive: false,
    orgSlug,
    outputKind,
    pendingHead: true,
    pullRequest: 0,
    reach: {
      runReachabilityAnalysis: false,
      reachDisableAnalytics: false,
      reachAnalysisTimeout: 0,
      reachAnalysisMemoryLimit: 0,
      reachEcosystems: [],
      reachExcludePaths: [],
      reachSkipCache: false
    },
    readOnly: false,
    repoName: repoSlug,
    report: false,
    reportLevel: constants.default.REPORT_LEVEL_ERROR,
    targets: ['.'],
    tmp: false
  });
  return {
    ok: true,
    data: {
      scanCreated: true
    }
  };
}
async function testAndDownloadManifestFiles({
  defaultBranch,
  files,
  githubToken,
  orgGithub,
  repoApiUrl,
  repoSlug,
  tmpDir
}) {
  logger.logger.info(`File tree for ${defaultBranch} contains`, files.length, `entries. Searching for supported manifest files...`);
  logger.logger.group();
  let fileCount = 0;
  let firstFailureResult;
  for (const file of files) {
    // eslint-disable-next-line no-await-in-loop
    const result = await testAndDownloadManifestFile({
      file,
      tmpDir,
      defaultBranch,
      repoApiUrl,
      githubToken
    });
    if (result.ok) {
      if (result.data.isManifest) {
        fileCount += 1;
      }
    } else if (!firstFailureResult) {
      firstFailureResult = result;
    }
  }
  logger.logger.groupEnd();
  logger.logger.info('Found and downloaded', fileCount, 'manifest files');
  if (!fileCount) {
    if (firstFailureResult) {
      logger.logger.fail('While no supported manifest files were downloaded, at least one error encountered trying to do so. Showing the first error.');
      return firstFailureResult;
    }
    return {
      ok: false,
      message: 'No manifest files found',
      cause: `No supported manifest files were found in the latest commit on the branch ${defaultBranch} for repo ${orgGithub}/${repoSlug}. Skipping full scan.`
    };
  }
  return {
    ok: true,
    data: undefined
  };
}
async function testAndDownloadManifestFile({
  defaultBranch,
  file,
  githubToken,
  repoApiUrl,
  tmpDir
}) {
  require$$9.debugFn('notice', 'testing: file', file);
  const supportedFilesCResult = await fetchSupportedScanFileNames();
  const supportedFiles = supportedFilesCResult.ok ? supportedFilesCResult.data : undefined;
  if (!supportedFiles || !utils.isReportSupportedFile(file, supportedFiles)) {
    require$$9.debugFn('notice', 'skip: not a known pattern');
    // Not an error.
    return {
      ok: true,
      data: {
        isManifest: false
      }
    };
  }
  require$$9.debugFn('notice', 'found: manifest file, going to attempt to download it;', file);
  const result = await downloadManifestFile({
    file,
    tmpDir,
    defaultBranch,
    repoApiUrl,
    githubToken
  });
  return result.ok ? {
    ok: true,
    data: {
      isManifest: true
    }
  } : result;
}
async function downloadManifestFile({
  defaultBranch,
  file,
  githubToken,
  repoApiUrl,
  tmpDir
}) {
  require$$9.debugFn('notice', 'request: download url from GitHub');
  const fileUrl = `${repoApiUrl}/contents/${file}?ref=${defaultBranch}`;
  require$$9.debugDir('inspect', {
    fileUrl
  });
  const downloadUrlResponse = await fetch(fileUrl, {
    method: 'GET',
    headers: {
      Authorization: `Bearer ${githubToken}`
    }
  });
  require$$9.debugFn('notice', 'complete: request');
  const downloadUrlText = await downloadUrlResponse.text();
  require$$9.debugFn('inspect', 'response: raw download url', downloadUrlText);
  let downloadUrl;
  try {
    downloadUrl = JSON.parse(downloadUrlText).download_url;
  } catch {
    logger.logger.fail(`GitHub response contained invalid JSON for download url for: ${file}`);
    return {
      ok: false,
      message: 'Invalid JSON response',
      cause: `Server responded with invalid JSON for download url ${downloadUrl}`
    };
  }
  const localPath = path.join(tmpDir, file);
  require$$9.debugFn('notice', 'download: manifest file started', downloadUrl, '->', localPath);

  // Now stream the file to that file...
  const result = await streamDownloadWithFetch(localPath, downloadUrl);
  if (!result.ok) {
    // Do we proceed? Bail? Hrm...
    logger.logger.fail(`Failed to download manifest file, skipping to next file. File: ${file}`);
    return result;
  }
  require$$9.debugFn('notice', 'download: manifest file completed');
  return {
    ok: true,
    data: undefined
  };
}

// Courtesy of gemini:
async function streamDownloadWithFetch(localPath, downloadUrl) {
  let response; // Declare response here to access it in catch if needed

  try {
    response = await fetch(downloadUrl);
    if (!response.ok) {
      const errorMsg = `Download failed due to bad server response: ${response.status} ${response.statusText} for ${downloadUrl}`;
      logger.logger.fail(errorMsg);
      return {
        ok: false,
        message: 'Download Failed',
        cause: errorMsg
      };
    }
    if (!response.body) {
      logger.logger.fail(`Download failed because the server response was empty, for ${downloadUrl}`);
      return {
        ok: false,
        message: 'Download Failed',
        cause: 'Response body is null or undefined.'
      };
    }

    // Make sure the dir exists. It may be nested and we need to construct that
    // before starting the download.
    const dir = path.dirname(localPath);
    if (!fs$1.existsSync(dir)) {
      fs$1.mkdirSync(dir, {
        recursive: true
      });
    }
    const fileStream = fs$1.createWriteStream(localPath);

    // Using stream.pipeline for better error handling and cleanup

    await promises.pipeline(response.body, fileStream);
    // 'pipeline' will automatically handle closing streams and propagating errors.
    // It resolves when the piping is fully complete and fileStream is closed.
    return {
      ok: true,
      data: localPath
    };
  } catch (e) {
    logger.logger.fail('An error was thrown while trying to download a manifest file... url:', downloadUrl);
    require$$9.debugDir('error', e);

    // If an error occurs and fileStream was created, attempt to clean up.
    if (fs$1.existsSync(localPath)) {
      // Check if fileStream was even opened before trying to delete
      // This check might be too simplistic depending on when error occurs
      try {
        await fs$1.promises.unlink(localPath);
      } catch (e) {
        logger.logger.fail(utils.formatErrorWithDetail(`Error deleting partial file ${localPath}`, e));
      }
    }
    // Construct a more informative error message
    let detailedError = `Error during download of ${downloadUrl}: ${e.message}`;
    if (e.cause) {
      // Include cause if available (e.g., from network errors)
      detailedError += `\nCause: ${e.cause}`;
    }
    if (response && !response.ok) {
      // If error was due to bad HTTP status
      detailedError += ` (HTTP Status: ${response.status} ${response.statusText})`;
    }
    require$$9.debugFn('error', detailedError);
    return {
      ok: false,
      message: 'Download Failed',
      cause: detailedError
    };
  }
}
async function getLastCommitDetails({
  defaultBranch,
  githubToken,
  orgGithub,
  repoApiUrl,
  repoSlug
}) {
  logger.logger.info(`Requesting last commit for default branch ${defaultBranch} for ${orgGithub}/${repoSlug}...`);
  const commitApiUrl = `${repoApiUrl}/commits?sha=${defaultBranch}&per_page=1`;
  require$$9.debugFn('inspect', 'url: commit', commitApiUrl);
  const commitResponse = await fetch(commitApiUrl, {
    headers: {
      Authorization: `Bearer ${githubToken}`
    }
  });
  const commitText = await commitResponse.text();
  require$$9.debugFn('inspect', 'response: commit', commitText);
  let lastCommit;
  try {
    lastCommit = JSON.parse(commitText)?.[0];
  } catch {
    logger.logger.fail(`GitHub response contained invalid JSON for last commit`);
    logger.logger.error(commitText);
    return {
      ok: false,
      message: 'Invalid JSON response',
      cause: `Server responded with invalid JSON for last commit of repo ${repoSlug}`
    };
  }
  const lastCommitSha = lastCommit.sha;
  const lastCommitter = Array.from(new Set([lastCommit.commit.author.name, lastCommit.commit.committer.name]))[0];
  const lastCommitMessage = lastCommit.message;
  if (!lastCommitSha) {
    return {
      ok: false,
      message: 'Missing commit SHA',
      cause: 'Unable to get last commit for repo'
    };
  }
  if (!lastCommitter) {
    return {
      ok: false,
      message: 'Missing committer',
      cause: 'Last commit does not have information about who made the commit'
    };
  }
  return {
    ok: true,
    data: {
      lastCommitSha,
      lastCommitter,
      lastCommitMessage
    }
  };
}
async function selectFocus(repos) {
  const proceed = await prompts.select({
    message: 'Please select the repo to process:',
    choices: repos.map(slug => ({
      name: slug,
      value: slug,
      description: `Create scan for the ${slug} repo through GitHub`
    })).concat({
      name: '(Exit)',
      value: '',
      description: 'Cancel this action and exit'
    })
  });
  if (!proceed) {
    return {
      ok: false,
      message: 'Canceled by user',
      cause: 'User chose to cancel the action'
    };
  }
  return {
    ok: true,
    data: [proceed]
  };
}
async function makeSure(count) {
  if (!(await prompts.confirm({
    message: `Are you sure you want to run this for ${count} repos?`,
    default: false
  }))) {
    return {
      ok: false,
      message: 'User canceled',
      cause: 'Action canceled by user'
    };
  }
  return {
    ok: true,
    data: undefined
  };
}
async function getRepoDetails({
  githubApiUrl,
  githubToken,
  orgGithub,
  repoSlug
}) {
  const repoApiUrl = `${githubApiUrl}/repos/${orgGithub}/${repoSlug}`;
  require$$9.debugDir('inspect', {
    repoApiUrl
  });
  const repoDetailsResponse = await fetch(repoApiUrl, {
    method: 'GET',
    headers: {
      Authorization: `Bearer ${githubToken}`
    }
  });
  logger.logger.success(`Request completed.`);
  const repoDetailsText = await repoDetailsResponse.text();
  require$$9.debugFn('inspect', 'response: repo', repoDetailsText);
  let repoDetails;
  try {
    repoDetails = JSON.parse(repoDetailsText);
  } catch {
    logger.logger.fail(`GitHub response contained invalid JSON for repo ${repoSlug}`);
    logger.logger.error(repoDetailsText);
    return {
      ok: false,
      message: 'Invalid JSON response',
      cause: `Server responded with invalid JSON for repo ${repoSlug}`
    };
  }
  const defaultBranch = repoDetails.default_branch;
  if (!defaultBranch) {
    return {
      ok: false,
      message: 'Default Branch Not Found',
      cause: `Repo ${repoSlug} does not have a default branch set or it was not reported`
    };
  }
  return {
    ok: true,
    data: {
      defaultBranch,
      repoDetails,
      repoApiUrl
    }
  };
}
async function getRepoBranchTree({
  defaultBranch,
  githubToken,
  orgGithub,
  repoApiUrl,
  repoSlug
}) {
  logger.logger.info(`Requesting default branch file tree; branch \`${defaultBranch}\`, repo \`${orgGithub}/${repoSlug}\`...`);
  const treeApiUrl = `${repoApiUrl}/git/trees/${defaultBranch}?recursive=1`;
  require$$9.debugFn('inspect', 'url: tree', treeApiUrl);
  const treeResponse = await fetch(treeApiUrl, {
    method: 'GET',
    headers: {
      Authorization: `Bearer ${githubToken}`
    }
  });
  const treeText = await treeResponse.text();
  require$$9.debugFn('inspect', 'response: tree', treeText);
  let treeDetails;
  try {
    treeDetails = JSON.parse(treeText);
  } catch {
    logger.logger.fail(`GitHub response contained invalid JSON for default branch of repo ${repoSlug}`);
    logger.logger.error(treeText);
    return {
      ok: false,
      message: 'Invalid JSON response',
      cause: `Server responded with invalid JSON for repo ${repoSlug}`
    };
  }
  if (treeDetails.message) {
    if (treeDetails.message === 'Git Repository is empty.') {
      logger.logger.warn(`GitHub reports the default branch of repo ${repoSlug} to be empty. Moving on to next repo.`);
      return {
        ok: true,
        data: []
      };
    }
    logger.logger.fail('Negative response from GitHub:', treeDetails.message);
    return {
      ok: false,
      message: 'Unexpected error response',
      cause: `GitHub responded with an unexpected error while asking for details on the default branch: ${treeDetails.message}`
    };
  }
  if (!treeDetails.tree || !Array.isArray(treeDetails.tree)) {
    require$$9.debugDir('inspect', {
      treeDetails: {
        tree: treeDetails.tree
      }
    });
    return {
      ok: false,
      message: `Tree response for default branch ${defaultBranch} for ${orgGithub}/${repoSlug} was not a list`
    };
  }
  const files = treeDetails.tree.filter(obj => obj.type === 'blob').map(obj => obj.path);
  return {
    ok: true,
    data: files
  };
}

async function outputScanGithub(result, outputKind) {
  if (outputKind === 'json') {
    logger.logger.log(utils.serializeResultJson(result));
    return;
  }
  if (!result.ok) {
    logger.logger.fail(utils.failMsgWithBadge(result.message, result.cause));
    return;
  }
  logger.logger.log('');
  logger.logger.success('Finished!');
}

async function handleCreateGithubScan({
  all,
  githubApiUrl,
  githubToken,
  interactive,
  orgGithub,
  orgSlug,
  outputKind,
  repos
}) {
  const ghScanCResult = await createScanFromGithub({
    all: Boolean(all),
    githubApiUrl,
    githubToken,
    interactive: Boolean(interactive),
    orgSlug,
    orgGithub,
    outputKind,
    repos: String(repos || '')
  });
  await outputScanGithub(ghScanCResult, outputKind);
}

const CMD_NAME$7 = 'github';
const DEFAULT_GITHUB_URL = 'https://api.github.com';
const description$9 = 'Create a scan for given GitHub repo';
const hidden$7 = true;
const cmdScanGithub = {
  description: description$9,
  hidden: hidden$7,
  run: run$a
};
async function run$a(argv, importMeta, {
  parentName
}) {
  const config = {
    commandName: CMD_NAME$7,
    description: description$9,
    hidden: hidden$7,
    flags: {
      ...flags.commonFlags,
      ...flags.outputFlags,
      all: {
        type: 'boolean',
        description: 'Apply for all known repositories reported by the Socket API. Supersedes `repos`.'
      },
      githubToken: {
        type: 'string',
        default: constants.default.ENV.SOCKET_CLI_GITHUB_TOKEN,
        description: 'Required GitHub token for authentication.\nMay set environment variable GITHUB_TOKEN or SOCKET_CLI_GITHUB_TOKEN instead.'
      },
      githubApiUrl: {
        type: 'string',
        default: DEFAULT_GITHUB_URL,
        description: `Base URL of the GitHub API (default: ${DEFAULT_GITHUB_URL})`
      },
      interactive: {
        type: 'boolean',
        default: true,
        description: 'Allow for interactive elements, asking for input. Use --no-interactive to prevent any input questions, defaulting them to cancel/no.'
      },
      org: {
        type: 'string',
        default: '',
        description: 'Force override the organization slug, overrides the default org from config'
      },
      orgGithub: {
        type: 'string',
        default: '',
        description: 'Alternate GitHub Org if the name is different than the Socket Org'
      },
      repos: {
        type: 'string',
        default: '',
        description: 'List of repos to target in a comma-separated format (e.g., repo1,repo2). If not specified, the script will pull the list from Socket and ask you to pick one. Use --all to use them all.'
      }
    },
    help: (command, config) => `
    Usage
      $ ${command} [options] [CWD=.]

    API Token Requirements
      ${utils.getFlagApiRequirementsOutput(`${parentName}:${CMD_NAME$7}`)}

    This is similar to the \`socket scan create\` command except it pulls the files
    from GitHub. See the help for that command for more details.

    A GitHub Personal Access Token (PAT) will at least need read access to the repo
    ("contents", read-only) for this command to work.

    Note: This command cannot run the \`socket manifest auto\` things because that
    requires local access to the repo while this command runs entirely through the
    GitHub for file access.

    You can use \`socket scan setup\` to configure certain repo flag defaults.

    Options
      ${utils.getFlagListOutput(config.flags)}

    Examples
      $ ${command}
      $ ${command} ./proj
  `
  };
  const cli = utils.meowOrExit({
    argv,
    config,
    importMeta,
    parentName
  });
  const {
    githubToken = constants.default.ENV.SOCKET_CLI_GITHUB_TOKEN,
    interactive = true,
    json,
    markdown,
    org: orgFlag
  } = cli.flags;
  const dryRun = !!cli.flags['dryRun'];
  let {
    all,
    githubApiUrl,
    orgGithub,
    repos
  } = cli.flags;
  let [cwd = '.'] = cli.input;
  // Note: path.resolve vs .join:
  // If given path is absolute then cwd should not affect it.
  cwd = path.resolve(process.cwd(), cwd);
  let {
    0: orgSlug
  } = await utils.determineOrgSlug(String(orgFlag || ''), interactive, dryRun);
  const sockJson = utils.readOrDefaultSocketJson(cwd);
  if (all === undefined) {
    if (sockJson.defaults?.scan?.github?.all !== undefined) {
      all = sockJson.defaults?.scan?.github?.all;
    } else {
      all = false;
    }
  }
  if (!githubApiUrl) {
    if (sockJson.defaults?.scan?.github?.githubApiUrl !== undefined) {
      githubApiUrl = sockJson.defaults.scan.github.githubApiUrl;
    } else {
      githubApiUrl = DEFAULT_GITHUB_URL;
    }
  }
  if (!orgGithub) {
    if (sockJson.defaults?.scan?.github?.orgGithub !== undefined) {
      orgGithub = sockJson.defaults.scan.github.orgGithub;
    } else {
      // Default to Socket org slug. Often that's fine. Vanity and all that.
      orgGithub = orgSlug;
    }
  }
  if (!all && !repos) {
    if (sockJson.defaults?.scan?.github?.repos !== undefined) {
      repos = sockJson.defaults.scan.github.repos;
    } else {
      repos = '';
    }
  }

  // We will also be needing that GitHub token.
  const hasGithubApiToken = !!githubToken;

  // We're going to need an api token to suggest data because those suggestions
  // must come from data we already know. Don't error on missing api token yet.
  // If the api-token is not set, ignore it for the sake of suggestions.
  const hasSocketApiToken = utils.hasDefaultApiToken();
  const outputKind = utils.getOutputKind(json, markdown);

  // If the current cwd is unknown and is used as a repo slug anyways, we will
  // first need to register the slug before we can use it.
  // Only do suggestions with an apiToken and when not in dryRun mode
  if (hasSocketApiToken && !dryRun && interactive) {
    if (!orgSlug) {
      const suggestion = await utils.suggestOrgSlug();
      if (suggestion === undefined) {
        await outputScanGithub({
          ok: false,
          message: 'Canceled by user',
          cause: 'Org selector was canceled by user'
        }, outputKind);
        return;
      }
      if (suggestion) {
        orgSlug = suggestion;
      }
    }
  }
  const wasValidInput = utils.checkCommandInput(outputKind, {
    nook: true,
    test: !json || !markdown,
    message: 'The json and markdown flags cannot be both set, pick one',
    fail: 'omit one'
  }, {
    nook: true,
    test: hasSocketApiToken,
    message: 'This command requires a Socket API token for access',
    fail: 'try `socket login`'
  }, {
    test: hasGithubApiToken,
    message: 'This command requires a GitHub API token for access',
    fail: 'missing'
  });
  if (!wasValidInput) {
    return;
  }

  // Note exiting earlier to skirt a hidden auth requirement
  if (dryRun) {
    logger.logger.log(constants.default.DRY_RUN_BAILING_NOW);
    return;
  }
  await handleCreateGithubScan({
    all: Boolean(all),
    githubApiUrl,
    githubToken,
    interactive: Boolean(interactive),
    orgSlug,
    orgGithub,
    outputKind,
    repos
  });
}

async function fetchOrgFullScanList(config, options) {
  const {
    sdkOpts
  } = {
    __proto__: null,
    ...options
  };
  const sockSdkCResult = await utils.setupSdk(sdkOpts);
  if (!sockSdkCResult.ok) {
    return sockSdkCResult;
  }
  const sockSdk = sockSdkCResult.data;
  const {
    branch,
    direction,
    from_time,
    orgSlug,
    page,
    perPage,
    repo,
    sort
  } = {
    __proto__: null,
    ...config
  };
  return await utils.handleApiCall(sockSdk.getOrgFullScanList(orgSlug, {
    ...(branch ? {
      branch
    } : {}),
    ...(repo ? {
      repo
    } : {}),
    sort,
    direction,
    from: from_time,
    page: String(page),
    per_page: String(perPage)
  }), {
    description: 'list of scans'
  });
}

// @ts-ignore
async function outputListScans(result, outputKind) {
  if (!result.ok) {
    process.exitCode = result.code ?? 1;
  }
  if (outputKind === 'json') {
    logger.logger.log(utils.serializeResultJson(result));
    return;
  }
  if (!result.ok) {
    logger.logger.fail(utils.failMsgWithBadge(result.message, result.cause));
    return;
  }
  const options = {
    columns: [{
      field: 'id',
      name: vendor.yoctocolorsCjsExports.magenta('ID')
    }, {
      field: 'report_url',
      name: vendor.yoctocolorsCjsExports.magenta('Scan URL')
    }, {
      field: 'repo',
      name: vendor.yoctocolorsCjsExports.magenta('Repo')
    }, {
      field: 'branch',
      name: vendor.yoctocolorsCjsExports.magenta('Branch')
    }, {
      field: 'created_at',
      name: vendor.yoctocolorsCjsExports.magenta('Created at')
    }]
  };
  const formattedResults = result.data.results.map(d => {
    return {
      id: d.id,
      report_url: vendor.yoctocolorsCjsExports.underline(`${d.html_report_url}`),
      created_at: d.created_at ? new Date(d.created_at).toLocaleDateString('en-us', {
        year: 'numeric',
        month: 'numeric',
        day: 'numeric'
      }) : '',
      repo: d.repo,
      branch: d.branch
    };
  });
  logger.logger.log(vendor.srcExports(options, formattedResults));
}

async function handleListScans({
  branch,
  direction,
  from_time,
  orgSlug,
  outputKind,
  page,
  perPage,
  repo,
  sort
}) {
  const data = await fetchOrgFullScanList({
    branch,
    direction,
    from_time,
    orgSlug,
    page,
    perPage,
    repo,
    sort
  });
  await outputListScans(data, outputKind);
}

const CMD_NAME$6 = 'list';
const description$8 = 'List the scans for an organization';
const hidden$6 = false;
const cmdScanList = {
  description: description$8,
  hidden: hidden$6,
  run: run$9
};
async function run$9(argv, importMeta, {
  parentName
}) {
  const config = {
    commandName: CMD_NAME$6,
    description: description$8,
    hidden: hidden$6,
    flags: {
      ...flags.commonFlags,
      ...flags.outputFlags,
      branch: {
        type: 'string',
        description: 'Filter to show only scans with this branch name'
      },
      direction: {
        type: 'string',
        shortFlag: 'd',
        default: 'desc',
        description: 'Direction option (`desc` or `asc`) - Default is `desc`'
      },
      fromTime: {
        type: 'string',
        shortFlag: 'f',
        default: '',
        description: 'From time - as a unix timestamp'
      },
      interactive: {
        type: 'boolean',
        default: true,
        description: 'Allow for interactive elements, asking for input. Use --no-interactive to prevent any input questions, defaulting them to cancel/no.'
      },
      page: {
        type: 'number',
        shortFlag: 'p',
        default: 1,
        description: 'Page number - Default is 1'
      },
      perPage: {
        type: 'number',
        shortFlag: 'pp',
        default: 30,
        description: 'Results per page - Default is 30'
      },
      org: {
        type: 'string',
        description: 'Force override the organization slug, overrides the default org from config'
      },
      sort: {
        type: 'string',
        shortFlag: 's',
        default: 'created_at',
        description: 'Sorting option (`name` or `created_at`) - default is `created_at`'
      },
      untilTime: {
        type: 'string',
        shortFlag: 'u',
        default: '',
        description: 'Until time - as a unix timestamp'
      }
    },
    help: (command, config) => `
    Usage
      $ ${command} [options] [REPO [BRANCH]]

    API Token Requirements
      ${utils.getFlagApiRequirementsOutput(`${parentName}:${CMD_NAME$6}`)}

    Optionally filter by REPO. If you specify a repo, you can also specify a
    branch to filter by. (Note: If you don't specify a repo then you must use
    \`--branch\` to filter by branch across all repos).

    Options
      ${utils.getFlagListOutput(config.flags)}

    Examples
      $ ${command}
      $ ${command} webtools badbranch --markdown
  `
  };
  const cli = utils.meowOrExit({
    argv,
    config,
    importMeta,
    parentName
  });
  const {
    branch: branchFlag,
    json,
    markdown,
    org: orgFlag
  } = cli.flags;
  const dryRun = !!cli.flags['dryRun'];
  const interactive = !!cli.flags['interactive'];
  const noLegacy = !cli.flags['repo'];
  const [repo = '', branchArg = ''] = cli.input;
  const branch = String(branchFlag || branchArg || '');
  const hasApiToken = utils.hasDefaultApiToken();
  const {
    0: orgSlug
  } = await utils.determineOrgSlug(String(orgFlag || ''), interactive, dryRun);
  const outputKind = utils.getOutputKind(json, markdown);
  const wasValidInput = utils.checkCommandInput(outputKind, {
    nook: true,
    test: noLegacy,
    message: `Legacy flags are no longer supported. See the ${utils.webLink(constants.V1_MIGRATION_GUIDE_URL, 'v1 migration guide')}.`,
    fail: `received legacy flags`
  }, {
    nook: true,
    test: !!orgSlug,
    message: 'Org name by default setting, --org, or auto-discovered',
    fail: 'dot is an invalid org, most likely you forgot the org name here?'
  }, {
    nook: true,
    test: !json || !markdown,
    message: 'The json and markdown flags cannot be both set, pick one',
    fail: 'omit one'
  }, {
    nook: true,
    test: hasApiToken,
    message: 'This command requires a Socket API token for access',
    fail: 'try `socket login`'
  }, {
    nook: true,
    test: !branchFlag || !branchArg,
    message: 'You should not set --branch and also give a second arg for branch name',
    fail: 'received flag and second arg'
  });
  if (!wasValidInput) {
    return;
  }
  if (dryRun) {
    logger.logger.log(constants.default.DRY_RUN_BAILING_NOW);
    return;
  }
  await handleListScans({
    branch: branch ? String(branch) : '',
    direction: String(cli.flags['direction'] || ''),
    from_time: String(cli.flags['fromTime'] || ''),
    orgSlug,
    outputKind,
    page: Number(cli.flags['page'] || 1),
    perPage: Number(cli.flags['perPage'] || 30),
    repo: repo ? String(repo) : '',
    sort: String(cli.flags['sort'] || '')
  });
}

async function fetchScanMetadata(orgSlug, scanId, options) {
  const {
    sdkOpts
  } = {
    __proto__: null,
    ...options
  };
  const sockSdkCResult = await utils.setupSdk(sdkOpts);
  if (!sockSdkCResult.ok) {
    return sockSdkCResult;
  }
  const sockSdk = sockSdkCResult.data;
  return await utils.handleApiCall(sockSdk.getOrgFullScanMetadata(orgSlug, scanId), {
    description: 'meta data for a full scan'
  });
}

async function outputScanMetadata(result, scanId, outputKind) {
  if (!result.ok) {
    process.exitCode = result.code ?? 1;
  }
  if (outputKind === 'json') {
    logger.logger.log(utils.serializeResultJson(result));
    return;
  }
  if (!result.ok) {
    logger.logger.fail(utils.failMsgWithBadge(result.message, result.cause));
    return;
  }
  if (outputKind === 'markdown') {
    logger.logger.log('# Scan meta data\n');
  }
  logger.logger.log(`Scan ID: ${scanId}\n`);
  for (const {
    0: key,
    1: value
  } of Object.entries(result.data)) {
    if (['id', 'updated_at', 'organization_id', 'repository_id', 'commit_hash', 'html_report_url'].includes(key)) {
      continue;
    }
    logger.logger.log(`- ${key}:`, value);
  }
  if (outputKind === 'markdown') {
    logger.logger.log(`\nYou can view this report at: [${result.data.html_report_url}](${result.data.html_report_url})\n`);
  } else {
    logger.logger.log(`\nYou can view this report at: ${result.data.html_report_url}]\n`);
  }
}

async function handleOrgScanMetadata(orgSlug, scanId, outputKind) {
  const data = await fetchScanMetadata(orgSlug, scanId);
  await outputScanMetadata(data, scanId, outputKind);
}

const CMD_NAME$5 = 'metadata';
const description$7 = "Get a scan's metadata";
const hidden$5 = false;
const cmdScanMetadata = {
  description: description$7,
  hidden: hidden$5,
  run: run$8
};
async function run$8(argv, importMeta, {
  parentName
}) {
  const config = {
    commandName: CMD_NAME$5,
    description: description$7,
    hidden: hidden$5,
    flags: {
      ...flags.commonFlags,
      ...flags.outputFlags,
      interactive: {
        type: 'boolean',
        default: true,
        description: 'Allow for interactive elements, asking for input. Use --no-interactive to prevent any input questions, defaulting them to cancel/no.'
      },
      org: {
        type: 'string',
        description: 'Force override the organization slug, overrides the default org from config'
      }
    },
    help: (command, config) => `
    Usage
      $ ${command} [options] <SCAN_ID>

    API Token Requirements
      ${utils.getFlagApiRequirementsOutput(`${parentName}:${CMD_NAME$5}`)}

    Options
      ${utils.getFlagListOutput(config.flags)}

    Examples
      $ ${command} 000aaaa1-0000-0a0a-00a0-00a0000000a0
      $ ${command} 000aaaa1-0000-0a0a-00a0-00a0000000a0 --json
  `
  };
  const cli = utils.meowOrExit({
    argv,
    config,
    importMeta,
    parentName
  });
  const {
    json,
    markdown,
    org: orgFlag
  } = cli.flags;
  const dryRun = !!cli.flags['dryRun'];
  const interactive = !!cli.flags['interactive'];
  const [scanId = ''] = cli.input;
  const hasApiToken = utils.hasDefaultApiToken();
  const {
    0: orgSlug
  } = await utils.determineOrgSlug(String(orgFlag || ''), interactive, dryRun);
  const outputKind = utils.getOutputKind(json, markdown);
  const wasValidInput = utils.checkCommandInput(outputKind, {
    nook: true,
    test: !!orgSlug,
    message: 'Org name by default setting, --org, or auto-discovered',
    fail: orgSlug === '.' ? 'dot is an invalid org, most likely you forgot the org name here?' : 'missing'
  }, {
    test: !!scanId,
    message: 'Scan ID to inspect as argument',
    fail: 'missing'
  }, {
    nook: true,
    test: !json || !markdown,
    message: 'The json and markdown flags cannot be both set, pick one',
    fail: 'omit one'
  }, {
    nook: true,
    test: hasApiToken,
    message: 'This command requires a Socket API token for access',
    fail: 'try `socket login`'
  });
  if (!wasValidInput) {
    return;
  }
  if (dryRun) {
    logger.logger.log(constants.default.DRY_RUN_BAILING_NOW);
    return;
  }
  await handleOrgScanMetadata(orgSlug, scanId, outputKind);
}

async function outputScanReach(result, {
  cwd,
  outputKind
}) {
  if (!result.ok) {
    process.exitCode = result.code ?? 1;
  }
  if (outputKind === 'json') {
    logger.logger.log(utils.serializeResultJson(result));
    return;
  }
  if (!result.ok) {
    logger.logger.fail(utils.failMsgWithBadge(result.message, result.cause));
    return;
  }
  logger.logger.log('');
  logger.logger.success('Reachability analysis completed successfully!');
  logger.logger.info(`Reachability report has been written to: ${path.join(cwd, constants.default.DOT_SOCKET_DOT_FACTS_JSON)}`);
}

async function handleScanReach({
  cwd,
  interactive: _interactive,
  orgSlug,
  outputKind,
  reachabilityOptions,
  targets
}) {
  const {
    spinner
  } = constants.default;

  // Get supported file names
  const supportedFilesCResult = await fetchSupportedScanFileNames({
    spinner
  });
  if (!supportedFilesCResult.ok) {
    await outputScanReach(supportedFilesCResult, {
      cwd,
      outputKind
    });
    return;
  }
  spinner.start('Searching for local manifest files to include in reachability analysis...');
  const supportedFiles = supportedFilesCResult.data;
  const packagePaths = await utils.getPackageFilesForScan(targets, supportedFiles, {
    cwd
  });
  spinner.successAndStop(`Found ${packagePaths.length} ${words.pluralize('manifest file', packagePaths.length)} for reachability analysis.`);
  const wasValidInput = utils.checkCommandInput(outputKind, {
    nook: true,
    test: packagePaths.length > 0,
    fail: 'found no eligible files to analyze',
    message: 'TARGET (file/dir) must contain matching / supported file types for reachability analysis'
  });
  if (!wasValidInput) {
    return;
  }
  logger.logger.success(`Found ${packagePaths.length} local ${words.pluralize('file', packagePaths.length)}`);
  spinner.start('Running reachability analysis...');
  const result = await performReachabilityAnalysis({
    cwd,
    orgSlug,
    packagePaths,
    reachabilityOptions,
    spinner,
    uploadManifests: true
  });
  spinner.stop();
  await outputScanReach(result, {
    cwd,
    outputKind
  });
}

const CMD_NAME$4 = 'reach';
const description$6 = 'Compute tier 1 reachability';
const hidden$4 = true;
const generalFlags = {
  ...flags.commonFlags,
  ...flags.outputFlags,
  cwd: {
    type: 'string',
    default: '',
    description: 'working directory, defaults to process.cwd()'
  },
  org: {
    type: 'string',
    default: '',
    description: 'Force override the organization slug, overrides the default org from config'
  }
};
const cmdScanReach = {
  description: description$6,
  hidden: hidden$4,
  run: run$7
};
async function run$7(argv, importMeta, {
  parentName
}) {
  const config = {
    commandName: CMD_NAME$4,
    description: description$6,
    hidden: hidden$4,
    flags: {
      ...generalFlags,
      ...reachabilityFlags
    },
    help: command => `
    Usage
      $ ${command} [options] [CWD=.]

    API Token Requirements
      ${utils.getFlagApiRequirementsOutput(`${parentName}:${CMD_NAME$4}`)}

    Options
      ${utils.getFlagListOutput(generalFlags)}

    Reachability Options
      ${utils.getFlagListOutput(reachabilityFlags)}

    Runs the Socket reachability analysis without creating a scan in Socket.
    The output is written to .socket.facts.json in the current working directory.

    Note: Manifest files are uploaded to Socket's backend services because the
    reachability analysis requires creating a Software Bill of Materials (SBOM)
    from these files before the analysis can run.

    Examples
      $ ${command}
      $ ${command} ./proj
      $ ${command} ./proj --reach-ecosystems npm,pypi
  `
  };
  const cli = utils.meowOrExit({
    argv,
    config,
    importMeta,
    parentName
  });
  const {
    cwd: cwdOverride,
    interactive = true,
    json,
    markdown,
    org: orgFlag,
    reachAnalysisMemoryLimit,
    reachAnalysisTimeout,
    reachDisableAnalytics,
    reachSkipCache
  } = cli.flags;
  const dryRun = !!cli.flags['dryRun'];

  // Process comma-separated values for isMultiple flags.
  const reachEcosystemsRaw = utils.cmdFlagValueToArray(cli.flags['reachEcosystems']);
  const reachExcludePaths = utils.cmdFlagValueToArray(cli.flags['reachExcludePaths']);

  // Validate ecosystem values.
  const reachEcosystems = [];
  const validEcosystems = utils.getEcosystemChoicesForMeow();
  for (const ecosystem of reachEcosystemsRaw) {
    if (!validEcosystems.includes(ecosystem)) {
      throw new Error(`Invalid ecosystem: "${ecosystem}". Valid values are: ${arrays.joinAnd(validEcosystems)}`);
    }
    reachEcosystems.push(ecosystem);
  }
  const processCwd = process.cwd();
  const cwd = cwdOverride && cwdOverride !== '.' && cwdOverride !== processCwd ? path.resolve(processCwd, cwdOverride) : processCwd;

  // Accept zero or more paths. Default to cwd() if none given.
  let targets = cli.input || [cwd];

  // Use suggestTarget if no targets specified and in interactive mode
  if (!targets.length && !dryRun && interactive) {
    targets = await suggestTarget();
  }
  const {
    0: orgSlug
  } = await utils.determineOrgSlug(orgFlag, interactive, dryRun);
  const hasApiToken = utils.hasDefaultApiToken();
  const outputKind = utils.getOutputKind(json, markdown);
  const wasValidInput = utils.checkCommandInput(outputKind, {
    nook: true,
    test: !!orgSlug,
    message: 'Org name by default setting, --org, or auto-discovered',
    fail: 'missing'
  }, {
    nook: true,
    test: hasApiToken,
    message: 'This command requires an API token for access',
    fail: 'try `socket login`'
  }, {
    nook: true,
    test: !json || !markdown,
    message: 'The json and markdown flags cannot be both set, pick one',
    fail: 'omit one'
  });
  if (!wasValidInput) {
    return;
  }
  if (dryRun) {
    logger.logger.log(constants.default.DRY_RUN_BAILING_NOW);
    return;
  }
  await handleScanReach({
    cwd,
    orgSlug,
    outputKind,
    targets,
    interactive,
    reachabilityOptions: {
      reachAnalysisTimeout: Number(reachAnalysisTimeout),
      reachAnalysisMemoryLimit: Number(reachAnalysisMemoryLimit),
      reachDisableAnalytics: Boolean(reachDisableAnalytics),
      reachEcosystems,
      reachExcludePaths,
      reachSkipCache: Boolean(reachSkipCache)
    }
  });
}

const CMD_NAME$3 = 'report';
const description$5 = 'Check whether a scan result passes the organizational policies (security, license)';
const hidden$3 = false;
const cmdScanReport = {
  description: description$5,
  hidden: hidden$3,
  run: run$6
};
async function run$6(argv, importMeta, {
  parentName
}) {
  const config = {
    commandName: CMD_NAME$3,
    description: description$5,
    hidden: hidden$3,
    flags: {
      ...flags.commonFlags,
      ...flags.outputFlags,
      fold: {
        type: 'string',
        default: constants.default.FOLD_SETTING_NONE,
        description: `Fold reported alerts to some degree (default '${constants.default.FOLD_SETTING_NONE}')`
      },
      interactive: {
        type: 'boolean',
        default: true,
        description: 'Allow for interactive elements, asking for input. Use --no-interactive to prevent any input questions, defaulting them to cancel/no.'
      },
      org: {
        type: 'string',
        description: 'Force override the organization slug, overrides the default org from config'
      },
      reportLevel: {
        type: 'string',
        default: constants.default.REPORT_LEVEL_WARN,
        description: `Which policy level alerts should be reported (default '${constants.default.REPORT_LEVEL_WARN}')`
      },
      short: {
        type: 'boolean',
        default: false,
        description: 'Report only the healthy status'
      },
      license: {
        type: 'boolean',
        default: false,
        description: 'Also report the license policy status. Default: false'
      }
    },
    help: (command, config) => `
    Usage
      $ ${command} [options] <SCAN_ID> [OUTPUT_PATH]

    API Token Requirements
      ${utils.getFlagApiRequirementsOutput(`${parentName}:${CMD_NAME$3}`)}

    Options
      ${utils.getFlagListOutput(config.flags)}

    When no output path is given the contents is sent to stdout.

    By default the result is a nested object that looks like this:
      \`{
        [ecosystem]: {
          [pkgName]: {
            [version]: {
              [file]: {
                [line:col]: alert
      }}}}\`
    So one alert for each occurrence in every file, version, etc, a huge response.

    You can --fold these up to given level: 'pkg', 'version', 'file', and 'none'.
    For example: \`socket scan report --fold=version\` will dedupe alerts to only
    show one alert of a particular kind, no matter how often it was found in a
    file or in how many files it was found. At most one per version that has it.

    By default only the warn and error policy level alerts are reported. You can
    override this and request more ('defer' < 'ignore' < 'monitor' < 'warn' < 'error')

    Short responses look like this:
      --json:     \`{healthy:bool}\`
      --markdown: \`healthy = bool\`
      neither:    \`OK/ERR\`

    Examples
      $ ${command} 000aaaa1-0000-0a0a-00a0-00a0000000a0 --json --fold=version
      $ ${command} 000aaaa1-0000-0a0a-00a0-00a0000000a0 --license --markdown --short
  `
  };
  const cli = utils.meowOrExit({
    argv,
    config,
    importMeta,
    parentName
  });
  const {
    json,
    markdown,
    org: orgFlag
  } = cli.flags;
  const dryRun = !!cli.flags['dryRun'];
  const fold = cli.flags['fold'];
  const interactive = !!cli.flags['interactive'];
  const includeLicensePolicy = !!cli.flags['license'];
  const reportLevel = cli.flags['reportLevel'];
  const short = !!cli.flags['short'];
  const [scanId = '', filepath = ''] = cli.input;
  const hasApiToken = utils.hasDefaultApiToken();
  const {
    0: orgSlug
  } = await utils.determineOrgSlug(String(orgFlag || ''), interactive, dryRun);
  const outputKind = utils.getOutputKind(json, markdown);
  const wasValidInput = utils.checkCommandInput(outputKind, {
    nook: true,
    test: !!orgSlug,
    message: 'Org name by default setting, --org, or auto-discovered',
    fail: 'dot is an invalid org, most likely you forgot the org name here?'
  }, {
    test: !!scanId,
    message: 'Scan ID to report on',
    fail: 'missing'
  }, {
    nook: true,
    test: !json || !markdown,
    message: 'The json and markdown flags cannot be both set, pick one',
    fail: 'omit one'
  }, {
    nook: true,
    test: hasApiToken,
    message: 'This command requires a Socket API token for access',
    fail: 'try `socket login`'
  });
  if (!wasValidInput) {
    return;
  }
  if (dryRun) {
    logger.logger.log(constants.default.DRY_RUN_BAILING_NOW);
    return;
  }
  await handleScanReport({
    orgSlug,
    scanId,
    includeLicensePolicy,
    outputKind,
    filepath,
    fold,
    short,
    reportLevel
  });
}

async function outputScanConfigResult(result) {
  if (!result.ok) {
    process.exitCode = result.code ?? 1;
  }
  if (!result.ok) {
    logger.logger.fail(utils.failMsgWithBadge(result.message, result.cause));
    return;
  }
  logger.logger.log('');
  logger.logger.log('Finished');
  logger.logger.log('');
}

async function setupScanConfig(cwd, defaultOnReadError = false) {
  const jsonPath = path.join(cwd, constants.SOCKET_JSON);
  if (fs$1.existsSync(jsonPath)) {
    logger.logger.info(`Found ${constants.SOCKET_JSON} at ${jsonPath}`);
  } else {
    logger.logger.info(`No ${constants.SOCKET_JSON} found at ${cwd}, will generate a new one`);
  }
  logger.logger.log('');
  logger.logger.log('Note: This tool will set up flag and argument defaults for certain');
  logger.logger.log('      CLI commands. You can still override them by explicitly');
  logger.logger.log('      setting the flag. It is meant to be a convenience tool.');
  logger.logger.log('');
  logger.logger.log(`This command will generate a \`${constants.SOCKET_JSON}\` file in the target cwd.`);
  logger.logger.log('You can choose to add this file to your repo (handy for collab)');
  logger.logger.log('or to add it to the ignored files, or neither. This file is only');
  logger.logger.log('used in CLI workflows.');
  logger.logger.log('');
  logger.logger.log('Note: For details on a flag you can run `socket <cmd> --help`');
  logger.logger.log('');
  const sockJsonCResult = utils.readSocketJsonSync(cwd, defaultOnReadError);
  if (!sockJsonCResult.ok) {
    return sockJsonCResult;
  }
  const sockJson = sockJsonCResult.data;
  if (!sockJson.defaults) {
    sockJson.defaults = {};
  }
  if (!sockJson.defaults.scan) {
    sockJson.defaults.scan = {};
  }
  const targetCommand = await prompts.select({
    message: 'Which scan command do you want to configure?',
    choices: [{
      name: 'socket scan create',
      value: 'create'
    }, {
      name: 'socket scan github',
      value: 'github'
    }, {
      name: '(cancel)',
      value: '',
      description: 'Exit configurator, make no changes'
    }]
  });
  switch (targetCommand) {
    case 'create':
      {
        if (!sockJson.defaults.scan.create) {
          sockJson.defaults.scan.create = {};
        }
        const result = await configureScan(sockJson.defaults.scan.create, cwd);
        if (!result.ok || result.data.canceled) {
          return result;
        }
        break;
      }
    case 'github':
      {
        if (!sockJson.defaults.scan.github) {
          sockJson.defaults.scan.github = {};
        }
        const result = await configureGithub(sockJson.defaults.scan.github);
        if (!result.ok || result.data.canceled) {
          return result;
        }
        break;
      }
    default:
      {
        return canceledByUser();
      }
  }
  logger.logger.log('');
  logger.logger.log(`Setup complete. Writing ${constants.SOCKET_JSON}`);
  logger.logger.log('');
  if (await prompts.select({
    message: `Do you want to write the new config to ${jsonPath} ?`,
    choices: [{
      name: 'yes',
      value: true,
      description: 'Update config'
    }, {
      name: 'no',
      value: false,
      description: 'Do not update the config'
    }]
  })) {
    return await utils.writeSocketJson(cwd, sockJson);
  }
  return canceledByUser();
}
async function configureScan(config, cwd = process.cwd()) {
  const defaultRepoName = await prompts.input({
    message: '(--repo) What repo name (slug) should be reported to Socket for this dir?',
    default: config.repo || (await utils.getRepoName(cwd)),
    required: false
    // validate: async string => bool
  });
  if (defaultRepoName === undefined) {
    return canceledByUser();
  }
  if (defaultRepoName) {
    // Store it even if it's constants.SOCKET_DEFAULT_REPOSITORY because if we
    // change this default then an existing user probably would not expect the change.
    config.repo = defaultRepoName;
  } else {
    delete config.repo;
  }
  const defaultBranchName = await prompts.input({
    message: '(--branch) What branch name (slug) should be reported to Socket for this dir?',
    default: config.branch || (await utils.gitBranch(cwd)) || (await utils.detectDefaultBranch(cwd)),
    required: false
    // validate: async string => bool
  });
  if (defaultBranchName === undefined) {
    return canceledByUser();
  }
  if (defaultBranchName) {
    // Store it even if it's constants.SOCKET_DEFAULT_BRANCH because if we change
    // this default then an existing user probably would not expect the change.
    config.branch = defaultBranchName;
  } else {
    delete config.branch;
  }
  const autoManifest = await prompts.select({
    message: '(--auto-manifest) Do you want to run `socket manifest auto` before creating a scan? You would need this for sbt, gradle, etc.',
    choices: [{
      name: 'no',
      value: 'no',
      description: 'Do not generate local manifest files'
    }, {
      name: 'yes',
      value: 'yes',
      description: 'Locally generate manifest files for languages like gradle, sbt, and conda (see `socket manifest auto`), before creating a scan'
    }, {
      name: '(leave default)',
      value: '',
      description: 'Do not store a setting for this'
    }],
    default: config.autoManifest === true ? 'yes' : config.autoManifest === false ? 'no' : ''
  });
  if (autoManifest === undefined) {
    return canceledByUser();
  }
  if (autoManifest === 'yes') {
    config.autoManifest = true;
  } else if (autoManifest === 'no') {
    config.autoManifest = false;
  } else {
    delete config.autoManifest;
  }
  const alwaysReport = await prompts.select({
    message: '(--report) Do you want to enable --report by default?',
    choices: [{
      name: 'no',
      value: 'no',
      description: 'Do not wait for Scan result and report by default'
    }, {
      name: 'yes',
      value: 'yes',
      description: 'After submitting a Scan request, wait for scan to complete, then show a report (like --report would)'
    }, {
      name: '(leave default)',
      value: '',
      description: 'Do not store a setting for this'
    }],
    default: config.report === true ? 'yes' : config.report === false ? 'no' : ''
  });
  if (alwaysReport === undefined) {
    return canceledByUser();
  }
  if (alwaysReport === 'yes') {
    config.report = true;
  } else if (alwaysReport === 'no') {
    config.report = false;
  } else {
    delete config.report;
  }
  return notCanceled();
}
async function configureGithub(config) {
  // Do not store the GitHub API token. Just leads to a security rabbit hole.

  const all = await prompts.select({
    message: '(--all) Do you by default want to fetch all repos from the GitHub API and scan all known repos?',
    choices: [{
      name: 'no',
      value: 'no',
      description: 'Fetch repos if not given and ask which repo to run on'
    }, {
      name: 'yes',
      value: 'yes',
      description: 'Run on all remote repos by default'
    }, {
      name: '(leave default)',
      value: '',
      description: 'Do not store a setting for this'
    }],
    default: config.all === true ? 'yes' : config.all === false ? 'no' : ''
  });
  if (all === undefined) {
    return canceledByUser();
  }
  if (all === 'yes') {
    config.all = true;
  } else if (all === 'no') {
    config.all = false;
  } else {
    delete config.all;
  }
  if (!all) {
    const defaultRepos = await prompts.input({
      message: '(--repos) Please enter the default repos to run this on, leave empty (backspace) to fetch from GitHub and ask interactive',
      default: config.repos,
      required: false
      // validate: async string => bool
    });
    if (defaultRepos === undefined) {
      return canceledByUser();
    }
    if (defaultRepos) {
      config.repos = defaultRepos;
    } else {
      delete config.repos;
    }
  }
  const defaultGithubApiUrl = await prompts.input({
    message: '(--github-api-url) Do you want to override the default github url?',
    default: config.githubApiUrl || constants.default.ENV.GITHUB_API_URL,
    required: false
    // validate: async string => bool
  });
  if (defaultGithubApiUrl === undefined) {
    return canceledByUser();
  }
  if (defaultGithubApiUrl && defaultGithubApiUrl !== constants.default.ENV.GITHUB_API_URL) {
    config.githubApiUrl = defaultGithubApiUrl;
  } else {
    delete config.githubApiUrl;
  }
  const defaultOrgGithub = await prompts.input({
    message: '(--org-github) Do you want to change the org slug that is used when talking to the GitHub API? Defaults to your Socket org slug.',
    default: config.orgGithub || '',
    required: false
    // validate: async string => bool
  });
  if (defaultOrgGithub === undefined) {
    return canceledByUser();
  }
  if (defaultOrgGithub) {
    config.orgGithub = defaultOrgGithub;
  } else {
    delete config.orgGithub;
  }
  return notCanceled();
}
function canceledByUser() {
  logger.logger.log('');
  logger.logger.info('User canceled');
  logger.logger.log('');
  return {
    ok: true,
    data: {
      canceled: true
    }
  };
}
function notCanceled() {
  return {
    ok: true,
    data: {
      canceled: false
    }
  };
}

async function handleScanConfig(cwd, defaultOnReadError = false) {
  const result = await setupScanConfig(cwd, defaultOnReadError);
  await outputScanConfigResult(result);
}

const config$2 = {
  commandName: 'setup',
  description: 'Start interactive configurator to customize default flag values for `socket scan` in this dir',
  hidden: false,
  flags: {
    ...flags.commonFlags,
    defaultOnReadError: {
      type: 'boolean',
      description: `If reading the ${constants.SOCKET_JSON} fails, just use a default config? Warning: This might override the existing json file!`
    }
  },
  help: (command, config) => `
    Usage
      $ ${command} [options] [CWD=.]

    Options
      ${utils.getFlagListOutput(config.flags)}

    Interactive configurator to create a local json file in the target directory
    that helps to set flag defaults for \`socket scan create\`.

    This helps to configure the (Socket reported) repo and branch names, as well
    as which branch name is the "default branch" (main, master, etc). This way
    you don't have to specify these flags when creating a scan in this dir.

    This generated configuration file will only be used locally by the CLI. You
    can commit it to the repo (useful for collaboration) or choose to add it to
    your .gitignore all the same. Only this CLI will use it.

    Examples

      $ ${command}
      $ ${command} ./proj
  `
};
const cmdScanSetup = {
  description: config$2.description,
  hidden: config$2.hidden,
  run: run$5
};
async function run$5(argv, importMeta, {
  parentName
}) {
  const cli = utils.meowOrExit({
    argv,
    config: config$2,
    parentName,
    importMeta
  });
  const dryRun = !!cli.flags['dryRun'];
  if (dryRun) {
    logger.logger.log(constants.default.DRY_RUN_BAILING_NOW);
    return;
  }
  const {
    defaultOnReadError = false
  } = cli.flags;
  let [cwd = '.'] = cli.input;
  // Note: path.resolve vs .join:
  // If given path is absolute then cwd should not affect it.
  cwd = path.resolve(process.cwd(), cwd);
  await handleScanConfig(cwd, Boolean(defaultOnReadError));
}

async function fetchScan(orgSlug, scanId) {
  const result = await utils.queryApiSafeText(`orgs/${orgSlug}/full-scans/${encodeURIComponent(scanId)}`, 'a scan');
  if (!result.ok) {
    return result;
  }
  const jsonsString = result.data;

  // This is nd-json; each line is a json object
  const lines = jsonsString.split('\n').filter(Boolean);
  let ok = true;
  const data = lines.map(line => {
    try {
      return JSON.parse(line);
    } catch (e) {
      ok = false;
      require$$9.debugFn('error', 'Failed to parse scan result line as JSON');
      require$$9.debugDir('error', {
        error: e,
        line
      });
      return undefined;
    }
  });
  if (ok) {
    return {
      ok: true,
      data
    };
  }
  return {
    ok: false,
    message: 'Invalid Socket API response',
    cause: 'The Socket API responded with at least one line that was not valid JSON. Please report if this persists.'
  };
}

async function outputScanView(result, orgSlug, scanId, filePath, outputKind) {
  if (!result.ok) {
    process.exitCode = result.code ?? 1;
  }
  if (!result.ok) {
    if (outputKind === 'json') {
      logger.logger.log(utils.serializeResultJson(result));
      return;
    }
    logger.logger.fail(utils.failMsgWithBadge(result.message, result.cause));
    return;
  }
  if (outputKind === 'json' || outputKind === 'text' && filePath && filePath.endsWith('.json')) {
    const json = utils.serializeResultJson(result);
    if (filePath && filePath !== '-') {
      logger.logger.info('Writing json results to', filePath);
      try {
        await fs.writeFile(filePath, json, 'utf8');
        logger.logger.info(`Data successfully written to ${utils.fileLink(filePath)}`);
      } catch (e) {
        process.exitCode = 1;
        logger.logger.fail('There was an error trying to write the markdown to disk');
        logger.logger.error(e);
        logger.logger.log(utils.serializeResultJson({
          ok: false,
          message: 'File Write Failure',
          cause: 'Failed to write json to disk'
        }));
      }
      return;
    }
    logger.logger.log(json);
    return;
  }
  const display = result.data.map(art => {
    const author = Array.isArray(art.author) ? `${art.author[0]}${art.author.length > 1 ? ' et.al.' : ''}` : art.author;
    return {
      type: art.type,
      name: art.name,
      version: art.version,
      author,
      score: JSON.stringify(art.score)
    };
  });
  const md = utils.mdTable(display, ['type', 'version', 'name', 'author', 'score']);
  const report = `
# Scan Details

These are the artifacts and their scores found.

Scan ID: ${scanId}

${md}

View this report at: ${constants.default.SOCKET_WEBSITE_URL}/dashboard/org/${orgSlug}/sbom/${scanId}
  `.trim() + '\n';
  if (filePath && filePath !== '-') {
    try {
      await fs.writeFile(filePath, report, 'utf8');
      logger.logger.log(`Data successfully written to ${utils.fileLink(filePath)}`);
    } catch (e) {
      process.exitCode = 1;
      logger.logger.fail('There was an error trying to write the markdown to disk');
      logger.logger.error(e);
    }
  } else {
    logger.logger.log(report);
  }
}

async function handleScanView(orgSlug, scanId, filePath, outputKind) {
  const data = await fetchScan(orgSlug, scanId);
  await outputScanView(data, orgSlug, scanId, filePath, outputKind);
}

async function streamScan(orgSlug, scanId, options) {
  const {
    file,
    sdkOpts
  } = {
    __proto__: null,
    ...options
  };
  const sockSdkCResult = await utils.setupSdk(sdkOpts);
  if (!sockSdkCResult.ok) {
    return sockSdkCResult;
  }
  const sockSdk = sockSdkCResult.data;
  logger.logger.info('Requesting data from API...');

  // Note: this will write to stdout or target file. It's not a noop
  return await utils.handleApiCall(sockSdk.getOrgFullScan(orgSlug, scanId, file === '-' ? undefined : file), {
    description: 'a scan'
  });
}

const CMD_NAME$2 = 'view';
const description$4 = 'View the raw results of a scan';
const hidden$2 = false;
const cmdScanView = {
  description: description$4,
  hidden: hidden$2,
  run: run$4
};
async function run$4(argv, importMeta, {
  parentName
}) {
  const config = {
    commandName: CMD_NAME$2,
    description: description$4,
    hidden: hidden$2,
    flags: {
      ...flags.commonFlags,
      ...flags.outputFlags,
      stream: {
        type: 'boolean',
        default: false,
        description: 'Only valid with --json. Streams the response as "ndjson" (chunks of valid json blobs).'
      },
      interactive: {
        type: 'boolean',
        default: true,
        description: 'Allow for interactive elements, asking for input. Use --no-interactive to prevent any input questions, defaulting them to cancel/no.'
      },
      org: {
        type: 'string',
        description: 'Force override the organization slug, overrides the default org from config'
      }
    },
    help: (command, config) => `
    Usage
      $ ${command} [options] <SCAN_ID> [OUTPUT_FILE]

    API Token Requirements
      ${utils.getFlagApiRequirementsOutput(`${parentName}:${CMD_NAME$2}`)}

    When no output path is given the contents is sent to stdout.

    Options
      ${utils.getFlagListOutput(config.flags)}

    Examples
      $ ${command} 000aaaa1-0000-0a0a-00a0-00a0000000a0
      $ ${command} 000aaaa1-0000-0a0a-00a0-00a0000000a0 ./stream.txt
  `
  };
  const cli = utils.meowOrExit({
    argv,
    config,
    importMeta,
    parentName
  });
  const {
    json,
    markdown,
    org: orgFlag,
    stream
  } = cli.flags;
  const dryRun = !!cli.flags['dryRun'];
  const interactive = !!cli.flags['interactive'];
  const [scanId = '', file = ''] = cli.input;
  const hasApiToken = utils.hasDefaultApiToken();
  const {
    0: orgSlug
  } = await utils.determineOrgSlug(String(orgFlag || ''), interactive, dryRun);
  const outputKind = utils.getOutputKind(json, markdown);
  const wasValidInput = utils.checkCommandInput(outputKind, {
    nook: true,
    test: !!orgSlug,
    message: 'Org name by default setting, --org, or auto-discovered',
    fail: 'dot is an invalid org, most likely you forgot the org name here?'
  }, {
    test: !!scanId,
    message: 'Scan ID to view',
    fail: 'missing'
  }, {
    nook: true,
    test: !json || !markdown,
    message: `The \`${constants.FLAG_JSON}\` and \`${constants.FLAG_MARKDOWN}\` flags can not be used at the same time`,
    fail: 'bad'
  }, {
    nook: true,
    test: hasApiToken,
    message: 'This command requires a Socket API token for access',
    fail: 'try `socket login`'
  }, {
    nook: true,
    test: !stream || !!json,
    message: 'You can only use --stream when using --json',
    fail: 'Either remove --stream or add --json'
  });
  if (!wasValidInput) {
    return;
  }
  if (dryRun) {
    logger.logger.log(constants.default.DRY_RUN_BAILING_NOW);
    return;
  }
  if (json && stream) {
    await streamScan(orgSlug, scanId, {
      file
    });
  } else {
    await handleScanView(orgSlug, scanId, file, outputKind);
  }
}

const description$3 = 'Manage Socket scans';
const cmdScan = {
  description: description$3,
  async run(argv, importMeta, {
    parentName
  }) {
    await utils.meowWithSubcommands({
      argv,
      name: `${parentName} scan`,
      importMeta,
      subcommands: {
        create: cmdScanCreate,
        del: cmdScanDel,
        diff: cmdScanDiff,
        github: cmdScanGithub,
        list: cmdScanList,
        metadata: cmdScanMetadata,
        reach: cmdScanReach,
        report: cmdScanReport,
        setup: cmdScanSetup,
        view: cmdScanView
      }
    }, {
      aliases: {
        meta: {
          description: cmdScanMetadata.description,
          hidden: true,
          argv: ['metadata']
        },
        reachability: {
          description: cmdScanReach.description,
          hidden: true,
          argv: ['reach']
        }
      },
      description: description$3
    });
  }
};

async function fetchThreatFeed({
  direction,
  ecosystem,
  filter,
  orgSlug,
  page,
  perPage,
  pkg,
  version
}) {
  const queryParams = new URLSearchParams([['direction', direction], ['ecosystem', ecosystem], filter ? ['filter', filter] : ['', ''], ['page_cursor', page], ['per_page', String(perPage)], pkg ? ['name', pkg] : ['', ''], version ? ['version', version] : ['', '']]);
  return await utils.queryApiSafeJson(`orgs/${orgSlug}/threat-feed?${queryParams}`, 'the Threat Feed data');
}

const require$2 = require$$5.createRequire((typeof document === 'undefined' ? require$$0.pathToFileURL(__filename).href : (_documentCurrentScript && _documentCurrentScript.tagName.toUpperCase() === 'SCRIPT' && _documentCurrentScript.src || new URL('cli.js', document.baseURI).href)));
async function outputThreatFeed(result, outputKind) {
  if (!result.ok) {
    process.exitCode = result.code ?? 1;
  }
  if (outputKind === 'json') {
    logger.logger.log(utils.serializeResultJson(result));
    return;
  }
  if (!result.ok) {
    logger.logger.fail(utils.failMsgWithBadge(result.message, result.cause));
    return;
  }
  if (!result.data?.results?.length) {
    logger.logger.warn('Did not receive any data to display.');
    return;
  }
  const formattedOutput = formatResults(result.data.results);
  const descriptions = result.data.results.map(d => d.description);

  // Note: this temporarily takes over the terminal (just like `man` does).
  const ScreenWidget = /*@__PURE__*/require$2('../external/blessed/lib/widgets/screen.js');
  const screen = new ScreenWidget({
    ...constants.default.blessedOptions
  });
  // Register these keys first so you can always exit, even when it gets stuck
  // If we don't do this and the code crashes, the user must hard-kill the
  // node process just to exit it. That's very bad UX.
  // eslint-disable-next-line n/no-process-exit
  screen.key(['escape', 'q', 'C-c'], () => process.exit(0));
  const TableWidget = /*@__PURE__*/require$2('../external/blessed-contrib/lib/widget/table.js');
  const detailsBoxHeight = 20; // bottom N rows for details box
  const tipsBoxHeight = 1; // 1 row for tips box

  const table = new TableWidget({
    keys: 'true',
    fg: 'white',
    selectedFg: 'white',
    selectedBg: 'magenta',
    interactive: 'true',
    label: 'Threat feed',
    width: '100%',
    top: 0,
    bottom: detailsBoxHeight + tipsBoxHeight,
    border: {
      type: 'line',
      fg: 'cyan'
    },
    columnWidth: [10, 30, 20, 18, 15, 200],
    // TODO: The truncation doesn't seem to work too well yet but when we add
    //       `pad` alignment fails, when we extend columnSpacing alignment fails.
    columnSpacing: 1,
    truncate: '_'
  });
  const BoxWidget = /*@__PURE__*/require$2('../external/blessed/lib/widgets/box.js');
  const tipsBox = new BoxWidget({
    bottom: detailsBoxHeight,
    // sits just above the details box
    height: tipsBoxHeight,
    width: '100%',
    style: {
      fg: 'yellow',
      bg: 'black'
    },
    tags: true,
    content: '↑/↓: Move    Enter: Select    q/ESC: Quit'
  });
  const detailsBox = new BoxWidget({
    bottom: 0,
    height: detailsBoxHeight,
    width: '100%',
    border: {
      type: 'line',
      fg: 'cyan'
    },
    label: 'Details',
    content: 'Use arrow keys to navigate. Press Enter to select a threat. Press q to exit.',
    style: {
      fg: 'white'
    }
  });
  table.setData({
    headers: [' Ecosystem', ' Name', '  Version', '  Threat type', '  Detected at', ' Details'],
    data: formattedOutput
  });

  // Initialize details box with the first selection if available
  if (formattedOutput.length > 0) {
    const selectedRow = formattedOutput[0];
    if (selectedRow) {
      detailsBox.setContent(formatDetailBox(selectedRow, descriptions, 0));
    }
  }

  // allow control the table with the keyboard
  table.focus();

  // Stacking order: table (top), tipsBox (middle), detailsBox (bottom)
  screen.append(table);
  screen.append(tipsBox);
  screen.append(detailsBox);

  // Update details box when selection changes
  table.rows.on('select item', () => {
    const selectedIndex = table.rows.selected;
    if (selectedIndex !== undefined && selectedIndex >= 0) {
      const selectedRow = formattedOutput[selectedIndex];
      if (selectedRow) {
        // Note: the spacing works around issues with the table; it refuses to pad!
        detailsBox.setContent(formatDetailBox(selectedRow, descriptions, selectedIndex));
        screen.render();
      }
    }
  });
  screen.render();
  screen.key(['return'], () => {
    const selectedIndex = table.rows.selected;
    screen.destroy();
    const selectedRow = formattedOutput[selectedIndex];
    logger.logger.log('Last selection:\n', selectedRow);
  });
}
function formatDetailBox(selectedRow, descriptions, selectedIndex) {
  return `Ecosystem:    ${selectedRow[0]?.trim()}\n` + `Name:         ${selectedRow[1]?.trim()}\n` + `Version:      ${selectedRow[2]?.trim()}\n` + `Threat type:  ${selectedRow[3]?.trim()}\n` + `Detected at:  ${selectedRow[4]?.trim()}\n` + `Details:      ${selectedRow[5]?.trim()}\n` + `Description:  ${descriptions[selectedIndex]?.trim()}`;
}
function formatResults(data) {
  return data.map(d => {
    const ecosystem = d.purl.split('pkg:')[1].split('/')[0];
    const name = d.purl.split('/')[1].split('@')[0];
    const version = d.purl.split('@')[1];
    const timeDiff = utils.msAtHome(d.createdAt);

    // Note: the spacing works around issues with the table; it refuses to pad!
    return [ecosystem, decodeURIComponent(name), ` ${version}`, ` ${d.threatType}`, ` ${timeDiff}`, d.locationHtmlUrl];
  });
}

async function handleThreatFeed({
  direction,
  ecosystem,
  filter,
  orgSlug,
  outputKind,
  page,
  perPage,
  pkg,
  version
}) {
  const data = await fetchThreatFeed({
    direction,
    ecosystem,
    filter,
    orgSlug,
    page,
    perPage,
    pkg,
    version
  });
  await outputThreatFeed(data, outputKind);
}

const CMD_NAME$1 = 'threat-feed';
const ECOSYSTEMS = new Set(['gem', 'golang', 'maven', constants.NPM, 'nuget', 'pypi']);
const TYPE_FILTERS = new Set(['anom', 'c', 'fp', 'joke', 'mal', 'secret', 'spy', 'tp', 'typo', 'u', 'vuln']);
const description$2 = '[Beta] View the threat-feed';
const hidden$1 = false;
const cmdThreatFeed = {
  description: description$2,
  hidden: hidden$1,
  run: run$3
};
async function run$3(argv, importMeta, {
  parentName
}) {
  const config = {
    commandName: CMD_NAME$1,
    description: description$2,
    hidden: hidden$1,
    flags: {
      ...flags.commonFlags,
      ...flags.outputFlags,
      direction: {
        type: 'string',
        default: 'desc',
        description: 'Order asc or desc by the createdAt attribute'
      },
      eco: {
        type: 'string',
        default: '',
        description: 'Only show threats for a particular ecosystem'
      },
      filter: {
        type: 'string',
        default: 'mal',
        description: 'Filter what type of threats to return'
      },
      interactive: {
        type: 'boolean',
        default: true,
        description: 'Allow for interactive elements, asking for input. Use --no-interactive to prevent any input questions, defaulting them to cancel/no.'
      },
      org: {
        type: 'string',
        description: 'Force override the organization slug, overrides the default org from config'
      },
      page: {
        type: 'string',
        default: '1',
        description: 'Page token'
      },
      perPage: {
        type: 'number',
        shortFlag: 'pp',
        default: 30,
        description: 'Number of items per page'
      },
      pkg: {
        type: 'string',
        default: '',
        description: 'Filter by this package name'
      },
      version: {
        type: 'string',
        default: '',
        description: 'Filter by this package version'
      }
    },
    help: (command, config) => `
    Usage
      $ ${command} [options] [ECOSYSTEM] [TYPE_FILTER]

    API Token Requirements
      ${utils.getFlagApiRequirementsOutput(`${parentName}:${CMD_NAME$1}`)}
      - Special access

    This feature requires a Threat Feed license. Please contact
    ${utils.mailtoLink('sales@socket.dev')} if you are interested in purchasing this access.

    Options
      ${utils.getFlagListOutput(config.flags)}

    Valid ecosystems:

      - gem
      - golang
      - maven
      - npm
      - nuget
      - pypi

    Valid type filters:

      - anom    Anomaly
      - c       Do not filter
      - fp      False Positives
      - joke    Joke / Fake
      - mal     Malware and Possible Malware [default]
      - secret  Secrets
      - spy     Telemetry
      - tp      False Positives and Unreviewed
      - typo    Typo-squat
      - u       Unreviewed
      - vuln    Vulnerability

    Note: if you filter by package name or version, it will do so for anything
          unless you also filter by that ecosystem and/or package name. When in
          doubt, look at the threat-feed and see the names in the name/version
          column. That's what you want to search for.

    You can put filters as args instead, we'll try to match the strings with the
    correct filter type but since this would not allow you to search for a package
    called "mal", you can also specify the filters through flags.

    First arg that matches a typo, eco, or version enum is used as such. First arg
    that matches none of them becomes the package name filter. Rest is ignored.

    Note: The version filter is a prefix search, pkg name is a substring search.

    Examples
      $ ${command}
      $ ${command} maven --json
      $ ${command} typo
      $ ${command} npm joke 1.0.0 --per-page=5 --page=2 --direction=asc
  `
  };
  const cli = utils.meowOrExit({
    argv,
    config,
    importMeta,
    parentName
  });
  const {
    eco,
    json,
    markdown,
    org: orgFlag,
    pkg,
    type: typef,
    version
  } = cli.flags;
  const dryRun = !!cli.flags['dryRun'];
  const interactive = !!cli.flags['interactive'];
  let ecoFilter = String(eco || '');
  let versionFilter = String(version || '');
  let typeFilter = String(typef || '');
  let nameFilter = String(pkg || '');
  const argSet = new Set(cli.input);
  cli.input.some(str => {
    if (ECOSYSTEMS.has(str)) {
      ecoFilter = str;
      argSet.delete(str);
      return true;
    }
  });
  cli.input.some(str => {
    if (/^v?\d+\.\d+\.\d+$/.test(str)) {
      versionFilter = str;
      argSet.delete(str);
      return true;
    }
  });
  cli.input.some(str => {
    if (TYPE_FILTERS.has(str)) {
      typeFilter = str;
      argSet.delete(str);
      return true;
    }
  });
  const haves = new Set([ecoFilter, versionFilter, typeFilter]);
  cli.input.some(str => {
    if (!haves.has(str)) {
      nameFilter = str;
      argSet.delete(str);
      return true;
    }
  });
  if (argSet.size) {
    logger.logger.info(`Warning: ignoring these excessive args: ${arrays.joinAnd(Array.from(argSet))}`);
  }
  const hasApiToken = utils.hasDefaultApiToken();
  const {
    0: orgSlug
  } = await utils.determineOrgSlug(String(orgFlag || ''), interactive, dryRun);
  const outputKind = utils.getOutputKind(json, markdown);
  const wasValidInput = utils.checkCommandInput(outputKind, {
    nook: true,
    test: !!orgSlug,
    message: 'Org name by default setting, --org, or auto-discovered',
    fail: 'missing'
  }, {
    nook: true,
    test: !json || !markdown,
    message: 'The json and markdown flags cannot be both set, pick one',
    fail: 'omit one'
  }, {
    nook: true,
    test: hasApiToken,
    message: 'This command requires a Socket API token for access',
    fail: 'try `socket login`'
  });
  if (!wasValidInput) {
    return;
  }
  if (dryRun) {
    logger.logger.log(constants.default.DRY_RUN_BAILING_NOW);
    return;
  }
  await handleThreatFeed({
    direction: String(cli.flags['direction'] || 'desc'),
    ecosystem: ecoFilter,
    filter: typeFilter,
    outputKind,
    orgSlug,
    page: String(cli.flags['page'] || '1'),
    perPage: Number(cli.flags['perPage']) || 30,
    pkg: nameFilter,
    version: versionFilter
  });
}

async function outputUninstallCompletion(result, targetName) {
  if (!result.ok) {
    process.exitCode = result.code ?? 1;
    logger.logger.fail(utils.failMsgWithBadge(result.message, result.cause));
    return;
  }
  logger.logger.log(result.message);
  logger.logger.log('');
  logger.logger.log('To remove the tab completion from the current shell (instance of bash) you');
  logger.logger.log('can run this command (due to a bash limitation NodeJS cannot do this):');
  logger.logger.log('');
  logger.logger.log(`    complete -r ${targetName}`);
  logger.logger.log('');
  logger.logger.log('Next time you open a terminal it should no longer be there, regardless.');
  logger.logger.log('');
  if (result.data.left.length) {
    logger.logger.log('Detected more Socket Alias completions left in bashrc. Run `socket uninstall <cmd>` to remove them too.');
    logger.logger.log('');
    result.data.left.forEach(str => {
      logger.logger.log(`  - \`${str}\``);
    });
    logger.logger.log('');
  }
}

async function teardownTabCompletion(targetName) {
  const result = utils.getBashrcDetails(targetName);
  if (!result.ok) {
    return result;
  }
  const {
    completionCommand,
    sourcingCommand,
    toAddToBashrc
  } = result.data;

  // Remove from ~/.bashrc if found
  const bashrc = constants.default.homePath ? path.join(constants.default.homePath, '.bashrc') : '';
  if (bashrc && fs$1.existsSync(bashrc)) {
    const content = fs$1.readFileSync(bashrc, 'utf8');
    if (content.includes(toAddToBashrc)) {
      const newContent = content
      // Try to remove the whole thing with comment first
      .replaceAll(toAddToBashrc, '')
      // Comment may have been edited away, try to remove the command at least
      .replaceAll(sourcingCommand, '').replaceAll(completionCommand, '');
      fs$1.writeFileSync(bashrc, newContent, 'utf8');
      return {
        ok: true,
        data: {
          action: 'removed',
          left: findRemainingCompletionSetups(newContent)
        },
        message: 'Removed completion from ~/.bashrc'
      };
    } else {
      const left = findRemainingCompletionSetups(content);
      return {
        ok: true,
        data: {
          action: 'missing',
          left
        },
        message: `Completion was not found in ~/.bashrc${left.length ? ' (you may need to manually edit your .bashrc to clean this up...)' : ''}`
      };
    }
  } else {
    return {
      ok: true,
      // Eh. I think this makes most sense.
      data: {
        action: 'not found',
        left: []
      },
      message: '~/.bashrc not found, skipping'
    };
  }
}
function findRemainingCompletionSetups(bashrc) {
  return bashrc.split('\n').map(s => s.trim()).filter(s => s.startsWith(utils.COMPLETION_CMD_PREFIX)).map(s => s.slice(utils.COMPLETION_CMD_PREFIX.length).trim());
}

async function handleUninstallCompletion(targetName) {
  const result = await teardownTabCompletion(targetName);
  await outputUninstallCompletion(result, targetName);
}

const config$1 = {
  commandName: 'completion',
  description: 'Uninstall bash completion for Socket CLI',
  hidden: false,
  flags: {
    ...flags.commonFlags
  },
  help: (command, config) => `
    Usage
      $ ${command} [options] [COMMAND_NAME=socket]

    Uninstalls bash tab completion for the Socket CLI. This will:
    1. Remove tab completion from your current shell for given command
    2. Remove the setup for given command from your ~/.bashrc

    The optional name is required if you installed tab completion for an alias
    other than the default "socket". This will NOT remove the command, only the
    tab completion that is registered for it in bash.

    Options
      ${utils.getFlagListOutput(config.flags)}

    Examples

      $ ${command}
      $ ${command} sd
  `
};
const cmdUninstallCompletion = {
  description: config$1.description,
  hidden: config$1.hidden,
  run: run$2
};
async function run$2(argv, importMeta, {
  parentName
}) {
  const cli = utils.meowOrExit({
    argv,
    config: config$1,
    parentName,
    importMeta
  });
  const dryRun = !!cli.flags['dryRun'];
  if (dryRun) {
    logger.logger.log(constants.default.DRY_RUN_BAILING_NOW);
    return;
  }
  const targetName = cli.input[0] || 'socket';
  await handleUninstallCompletion(String(targetName));
}

const description$1 = 'Uninstall Socket CLI tab completion';
const cmdUninstall = {
  description: description$1,
  hidden: false,
  async run(argv, importMeta, {
    parentName
  }) {
    await utils.meowWithSubcommands({
      argv,
      name: `${parentName} uninstall`,
      importMeta,
      subcommands: {
        completion: cmdUninstallCompletion
      }
    }, {
      description: description$1
    });
  }
};

function addSocketWrapper(file) {
  return fs$1.appendFile(file, 'alias npm="socket npm"\nalias npx="socket npx"\n', err => {
    if (err) {
      return new Error(`There was an error setting up the alias: ${err}`);
    }
    logger.logger.success(`The alias was added to ${file}. Running 'npm install' will now be wrapped in Socket's "safe npm" 🎉`);
    logger.logger.log(`  If you want to disable it at any time, run \`socket wrapper --disable\``);
    logger.logger.log('');
    logger.logger.info(`This will only be active in new terminal sessions going forward.`);
    logger.logger.log(`  You will need to restart your terminal or run this command to activate the alias in the current session:`);
    logger.logger.log('');
    logger.logger.log(`    source ${file}`);
    logger.logger.log('');
    logger.logger.log(`(You only need to do this once)`);
  });
}

function checkSocketWrapperSetup(file) {
  const fileContent = fs$1.readFileSync(file, 'utf8');
  const linesWithSocketAlias = fileContent.split('\n').filter(l => l === 'alias npm="socket npm"' || l === 'alias npx="socket npx"');
  if (linesWithSocketAlias.length) {
    logger.logger.log(`The Socket npm/npx wrapper is set up in your bash profile (${file}).`);
    logger.logger.log('');
    logger.logger.log(`If you haven't already since enabling; Restart your terminal or run this command to activate it in the current session:`);
    logger.logger.log('');
    logger.logger.log(`    source ${file}`);
    logger.logger.log('');
    return true;
  }
  return false;
}

async function postinstallWrapper() {
  const {
    bashRcPath,
    zshRcPath
  } = constants.default;
  const socketWrapperEnabled = fs$1.existsSync(bashRcPath) && checkSocketWrapperSetup(bashRcPath) || fs$1.existsSync(zshRcPath) && checkSocketWrapperSetup(zshRcPath);
  if (!socketWrapperEnabled) {
    await setupShadowNpm(`
The Socket CLI is now successfully installed! 🎉

To better protect yourself against supply-chain attacks, our Socket npm wrapper can warn you about malicious packages whenever you run 'npm install'.

Do you want to install the Socket npm wrapper (this will create an alias to the \`socket npm\` command)?
    `.trim());
  }

  // Attempt to update the existing tab completion
  let updatedTabCompletion = false;
  try {
    const details = utils.getBashrcDetails(''); // Note: command is not relevant, we just want the config path
    if (details.ok) {
      if (fs$1.existsSync(details.data.targetPath)) {
        // Replace the file with the one from this installation
        const result = updateInstalledTabCompletionScript(details.data.targetPath);
        if (result.ok) {
          // This will work no matter what alias(es) were registered since that
          // is controlled by bashrc and they all share the same tab script.
          logger.logger.success('Updated the installed Socket tab completion script');
          updatedTabCompletion = true;
        }
      }
    }
  } catch (e) {
    require$$9.debugFn('warn', 'Tab completion setup failed (non-fatal)');
    require$$9.debugDir('warn', e);
    // Ignore. Skip tab completion setup.
  }
  if (!updatedTabCompletion) {
    // Setting up tab completion requires bashrc modification. I'm not sure if
    // it's cool to just do that from an npm install...
    logger.logger.log('Run `socket install completion` to setup bash tab completion');
  }
}
async function setupShadowNpm(query) {
  logger.logger.log(`
 _____         _       _
|   __|___ ___| |_ ___| |_
|__   | . |  _| '_| -_|  _|
|_____|___|___|_,_|___|_|

`);
  if (await prompts.confirm({
    message: query,
    default: true
  })) {
    const {
      bashRcPath,
      zshRcPath
    } = constants.default;
    try {
      if (fs$1.existsSync(bashRcPath)) {
        addSocketWrapper(bashRcPath);
      }
      if (fs$1.existsSync(zshRcPath)) {
        addSocketWrapper(zshRcPath);
      }
    } catch (e) {
      throw new Error(`There was an issue setting up the alias: ${utils.getErrorCause(e)}`);
    }
  }
}

function removeSocketWrapper(filepath) {
  let content;
  try {
    content = fs$1.readFileSync(filepath, 'utf8');
  } catch (e) {
    logger.logger.fail(`There was an error removing the alias${e ? ':' : '.'}`);
    if (e) {
      logger.logger.error(e);
    }
    return;
  }
  const linesWithoutSocketAlias = content.split('\n').filter(l => l !== 'alias npm="socket npm"' && l !== 'alias npx="socket npx"');
  const updatedContent = linesWithoutSocketAlias.join('\n');
  try {
    fs$1.writeFileSync(filepath, updatedContent, 'utf8');
  } catch (e) {
    if (e) {
      logger.logger.error(e);
    }
    return;
  }
  logger.logger.success(`The alias was removed from ${filepath}. Running 'npm install' will now run the standard npm command in new terminals going forward.`);
  logger.logger.log('');
  logger.logger.info(`Note: We cannot deactivate the alias from current terminal sessions. You have to restart existing terminal sessions to finalize this step.`);
}

const config = {
  commandName: 'wrapper',
  description: 'Enable or disable the Socket npm/npx wrapper',
  hidden: false,
  flags: {
    ...flags.commonFlags
  },
  help: (command, config) => `
    Usage
      $ ${command} <"on" | "off">

    Options
      ${utils.getFlagListOutput(config.flags)}

    While enabled, the wrapper makes it so that when you call npm/npx on your
    machine, it will automatically actually run \`socket npm\` / \`socket npx\`
    instead.

    Examples
      $ ${command} on
      $ ${command} off
  `
};
const cmdWrapper = {
  description: config.description,
  hidden: config.hidden,
  run: run$1
};
async function run$1(argv, importMeta, {
  parentName
}) {
  // I don't think meow would mess with this but ...
  if (argv[0] === '--postinstall') {
    await postinstallWrapper();
    return;
  }
  const cli = utils.meowOrExit({
    argv,
    config,
    importMeta,
    parentName
  });

  // TODO: Implement json/md further.
  const {
    json,
    markdown
  } = cli.flags;
  const dryRun = !!cli.flags['dryRun'];
  let enable = false;
  let disable = false;
  const [arg] = cli.input;
  if (arg === 'on' || arg === 'enable' || arg === 'enabled') {
    enable = true;
    disable = false;
  } else if (arg === 'off' || arg === 'disable' || arg === 'disabled') {
    enable = false;
    disable = true;
  }
  const outputKind = utils.getOutputKind(json, markdown);
  const wasValidInput = utils.checkCommandInput(outputKind, {
    test: enable || disable,
    message: 'Must specify "on" or "off" argument',
    fail: 'missing'
  }, {
    nook: true,
    test: cli.input.length <= 1,
    message: 'expecting exactly one argument',
    fail: `got multiple`
  });
  if (!wasValidInput) {
    return;
  }
  if (dryRun) {
    logger.logger.log(constants.default.DRY_RUN_BAILING_NOW);
    return;
  }
  const {
    bashRcPath,
    zshRcPath
  } = constants.default;
  if (enable) {
    if (fs$1.existsSync(bashRcPath) && !checkSocketWrapperSetup(bashRcPath)) {
      addSocketWrapper(bashRcPath);
    }
    if (fs$1.existsSync(zshRcPath) && !checkSocketWrapperSetup(zshRcPath)) {
      addSocketWrapper(zshRcPath);
    }
  } else {
    if (fs$1.existsSync(bashRcPath)) {
      removeSocketWrapper(bashRcPath);
    }
    if (fs$1.existsSync(zshRcPath)) {
      removeSocketWrapper(zshRcPath);
    }
  }
  if (!fs$1.existsSync(bashRcPath) && !fs$1.existsSync(zshRcPath)) {
    logger.logger.fail('There was an issue setting up the alias in your bash profile');
  }
}

const require$1 = require$$5.createRequire((typeof document === 'undefined' ? require$$0.pathToFileURL(__filename).href : (_documentCurrentScript && _documentCurrentScript.tagName.toUpperCase() === 'SCRIPT' && _documentCurrentScript.src || new URL('cli.js', document.baseURI).href)));
const CMD_NAME = constants.YARN;
const description = 'Wraps yarn with Socket security scanning';
const hidden = true;
const cmdYarn = {
  description,
  hidden,
  run
};
async function run(argv, importMeta, context) {
  const {
    parentName
  } = {
    __proto__: null,
    ...context
  };
  const config = {
    commandName: CMD_NAME,
    description,
    hidden,
    flags: {
      ...flags.commonFlags
    },
    help: command => `
    Usage
      $ ${command} ...

    API Token Requirements
      ${utils.getFlagApiRequirementsOutput(`${parentName}:${CMD_NAME}`)}

    Note: Everything after "${constants.YARN}" is passed to the ${constants.YARN} command.
          Only the \`${constants.FLAG_DRY_RUN}\` and \`${constants.FLAG_HELP}\` flags are caught here.

    Use \`socket wrapper on\` to alias this command as \`${constants.YARN}\`.

    Examples
      $ ${command}
      $ ${command} install
      $ ${command} add package-name
      $ ${command} dlx package-name
    `
  };
  const cli = utils.meowOrExit({
    argv,
    config,
    importMeta,
    parentName
  });
  const dryRun = !!cli.flags['dryRun'];
  if (dryRun) {
    logger.logger.log(constants.default.DRY_RUN_BAILING_NOW);
    return;
  }
  const shadowYarnBin = /*@__PURE__*/require$1(constants.default.shadowYarnBinPath);
  process.exitCode = 1;

  // Filter Socket flags from argv.
  const filteredArgv = utils.filterFlags(argv, config.flags);
  const {
    spawnPromise
  } = await shadowYarnBin(filteredArgv, {
    stdio: 'inherit'
  });
  await spawnPromise;
  process.exitCode = 0;
}

const rootCommands = {
  analytics: cmdAnalytics,
  'audit-log': cmdAuditLog,
  ci: cmdCI,
  cdxgen: cmdManifestCdxgen,
  config: cmdConfig,
  dependencies: cmdOrganizationDependencies,
  fix: cmdFix,
  install: cmdInstall,
  json: cmdJson,
  license: cmdOrganizationPolicyLicense,
  login: cmdLogin,
  logout: cmdLogout,
  manifest: cmdManifest,
  npm: cmdNpm,
  npx: cmdNpx,
  pnpm: cmdPnpm,
  oops: cmdOops,
  optimize: cmdOptimize,
  organization: cmdOrganization,
  package: cmdPackage,
  patch: cmdPatch,
  'raw-npm': cmdRawNpm,
  'raw-npx': cmdRawNpx,
  repository: cmdRepository,
  scan: cmdScan,
  security: cmdOrganizationPolicySecurity,
  'threat-feed': cmdThreatFeed,
  uninstall: cmdUninstall,
  wrapper: cmdWrapper,
  yarn: cmdYarn
};
const rootAliases = {
  audit: {
    description: `${cmdAuditLog.description} (alias)`,
    hidden: false,
    argv: ['audit-log']
  },
  auditLog: {
    description: cmdAuditLog.description,
    hidden: true,
    argv: ['audit-log']
  },
  auditLogs: {
    description: cmdAuditLog.description,
    hidden: true,
    argv: ['audit-log']
  },
  ['audit-logs']: {
    description: cmdAuditLog.description,
    hidden: true,
    argv: ['audit-log']
  },
  deps: {
    description: `${cmdOrganizationDependencies.description} (alias)`,
    hidden: false,
    argv: ['dependencies']
  },
  feed: {
    description: `${cmdThreatFeed.description} (alias)`,
    hidden: false,
    argv: ['threat-feed']
  },
  org: {
    description: `${cmdOrganization.description} (alias)`,
    hidden: false,
    argv: ['organization']
  },
  orgs: {
    description: cmdOrganization.description,
    hidden: true,
    argv: ['organization']
  },
  organizations: {
    description: cmdOrganization.description,
    hidden: true,
    argv: ['organization']
  },
  organisation: {
    description: cmdOrganization.description,
    hidden: true,
    argv: ['organization']
  },
  organisations: {
    description: cmdOrganization.description,
    hidden: true,
    argv: ['organization']
  },
  pkg: {
    description: `${cmdPackage.description} (alias)`,
    hidden: false,
    argv: ['package']
  },
  repo: {
    description: `${cmdRepository.description} (alias)`,
    hidden: false,
    argv: ['repos']
  },
  repos: {
    description: cmdRepository.description,
    hidden: true,
    argv: ['repos']
  },
  repositories: {
    description: cmdRepository.description,
    hidden: true,
    argv: ['repos']
  }
};

const __filename$1 = require$$0.fileURLToPath((typeof document === 'undefined' ? require$$0.pathToFileURL(__filename).href : (_documentCurrentScript && _documentCurrentScript.tagName.toUpperCase() === 'SCRIPT' && _documentCurrentScript.src || new URL('cli.js', document.baseURI).href)));
void (async () => {
  const registryUrl = vendor.registryUrl();
  await vendor.updater({
    authInfo: vendor.registryAuthTokenExports(registryUrl, {
      recursive: true
    }),
    name: constants.default.SOCKET_CLI_BIN_NAME,
    registryUrl,
    ttl: 86_400_000 /* 24 hours in milliseconds */,
    version: constants.default.ENV.INLINED_SOCKET_CLI_VERSION,
    logCallback: (name, version, latest) => {
      logger.logger.log(`\n\n📦 Update available for ${vendor.yoctocolorsCjsExports.cyan(name)}: ${vendor.yoctocolorsCjsExports.gray(version)} → ${vendor.yoctocolorsCjsExports.green(latest)}`);
      logger.logger.log(`📝 ${utils.socketPackageLink('npm', name, `files/${latest}/CHANGELOG.md`, 'View changelog')}`);
    }
  });
  try {
    await utils.meowWithSubcommands({
      name: constants.default.SOCKET_CLI_BIN_NAME,
      argv: process.argv.slice(2),
      importMeta: {
        url: `${require$$0.pathToFileURL(__filename$1)}`
      },
      subcommands: rootCommands
    }, {
      aliases: rootAliases
    });
  } catch (e) {
    process.exitCode = 1;
    require$$9.debugFn('error', 'CLI uncaught error');
    require$$9.debugDir('error', e);
    let errorBody;
    let errorTitle;
    let errorMessage = '';
    if (e instanceof utils.AuthError) {
      errorTitle = 'Authentication error';
      errorMessage = e.message;
    } else if (e instanceof utils.InputError) {
      errorTitle = 'Invalid input';
      errorMessage = e.message;
      errorBody = e.body;
    } else if (e instanceof Error) {
      errorTitle = 'Unexpected error';
      errorMessage = vendor.messageWithCauses(e);
      errorBody = vendor.stackWithCauses(e);
    } else {
      errorTitle = 'Unexpected error with no details';
    }

    // Try to parse the flags, find out if --json is set.
    const isJson = (() => {
      const cli = vendor.meow({
        argv: process.argv.slice(2),
        // Prevent meow from potentially exiting early.
        autoHelp: false,
        autoVersion: false,
        flags: {},
        importMeta: {
          url: `${require$$0.pathToFileURL(__filename$1)}`
        }
      });
      return !!cli.flags['json'];
    })();
    if (isJson) {
      logger.logger.log(utils.serializeResultJson({
        ok: false,
        message: errorTitle,
        cause: errorMessage
      }));
    } else {
      // Add 2 newlines in stderr to bump below any spinner.
      logger.logger.error('\n');
      logger.logger.fail(utils.failMsgWithBadge(errorTitle, errorMessage));
      if (errorBody) {
        require$$9.debugDir('inspect', {
          errorBody
        });
      }
    }
    await utils.captureException(e);
  }
})();
//# debugId=7d7feb5c-caaa-4477-9563-76861e408418
//# sourceMappingURL=cli.js.map
